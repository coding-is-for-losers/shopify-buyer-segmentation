2018-07-30 11:52:42,427: Tracking: tracking
2018-07-30 11:52:42,431: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e5042b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e504a58>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e504d30>]}
2018-07-30 11:52:44,286: Loading dependency project from /usr/local/Cellar/dbt/0.10.1/libexec/lib/python3.6/site-packages/dbt/include
2018-07-30 11:52:44,342: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/shopify-cohort-analysis/dbt_modules
2018-07-30 11:52:44,349: Parsing get_column_values.sql
2018-07-30 11:52:44,372: Parsing get_url_parameter.sql
2018-07-30 11:52:44,381: Parsing split_part.sql
2018-07-30 11:52:44,392: Parsing table_exists.sql
2018-07-30 11:52:44,410: Parsing core.sql
2018-07-30 11:52:44,431: Parsing adapters/bigquery.sql
2018-07-30 11:52:44,447: Parsing adapters/common.sql
2018-07-30 11:52:44,488: Parsing adapters/redshift.sql
2018-07-30 11:52:44,524: Parsing adapters/snowflake.sql
2018-07-30 11:52:44,532: Parsing etc/bigquery.sql
2018-07-30 11:52:44,537: Parsing etc/datetime.sql
2018-07-30 11:52:44,592: Parsing etc/get_custom_schema.sql
2018-07-30 11:52:44,606: Parsing materializations/helpers.sql
2018-07-30 11:52:44,628: Parsing materializations/archive/archive.sql
2018-07-30 11:52:44,678: Parsing materializations/incremental/incremental.sql
2018-07-30 11:52:44,725: Parsing materializations/seed/bigquery.sql
2018-07-30 11:52:44,756: Parsing materializations/seed/seed.sql
2018-07-30 11:52:44,844: Parsing materializations/table/bigquery_table.sql
2018-07-30 11:52:44,896: Parsing materializations/table/table.sql
2018-07-30 11:52:44,938: Parsing materializations/view/bigquery_view.sql
2018-07-30 11:52:44,956: Parsing materializations/view/view.sql
2018-07-30 11:52:44,993: Parsing schema_tests/accepted_values.sql
2018-07-30 11:52:44,999: Parsing schema_tests/not_null.sql
2018-07-30 11:52:45,004: Parsing schema_tests/relationships.sql
2018-07-30 11:52:45,012: Parsing schema_tests/unique.sql
2018-07-30 11:52:45,051: Parsing model.shopify_cohort_analysis.all_dates
2018-07-30 11:52:45,054: Parsing model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 11:52:45,058: Parsing model.shopify_cohort_analysis.monthend_dates
2018-07-30 11:52:45,061: Parsing model.shopify_cohort_analysis.stores_proc
2018-07-30 11:52:45,064: Parsing model.shopify_cohort_analysis.ga_transactions
2018-07-30 11:52:45,080: Parsing model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 11:52:45,088: Parsing model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 11:52:45,097: Parsing model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 11:52:45,110: Parsing model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 11:52:45,118: Parsing model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 11:52:45,125: Parsing model.shopify_cohort_analysis.agg_customers
2018-07-30 11:52:45,128: Parsing model.shopify_cohort_analysis.agg_transactions
2018-07-30 11:52:45,132: Parsing model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 11:52:45,135: Parsing model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 11:52:45,137: Parsing model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 11:52:45,143: Parsing model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 11:52:45,151: Parsing model.shopify_cohort_analysis.customers_proc
2018-07-30 11:52:45,157: Parsing model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 11:52:45,161: Parsing model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 11:52:45,166: Parsing model.shopify_cohort_analysis.segment_proc_customers
2018-07-30 11:52:45,169: Parsing model.shopify_cohort_analysis.segment_stats_customers_agg
2018-07-30 11:52:45,180: Parsing model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 11:52:45,202: Found 22 models, 0 tests, 0 archives, 0 analyses, 62 macros, 0 operations, 0 seed files
2018-07-30 11:52:45,209: 
2018-07-30 11:52:45,217: Acquiring new bigquery connection "master".
2018-07-30 11:52:45,217: Opening a new connection (0 currently allocated)
2018-07-30 11:52:46,748: 11:52:46 | Concurrency: 4 threads (target='template')
2018-07-30 11:52:46,748: 11:52:46 | 
2018-07-30 11:52:46,869: 11:52:46 | 1 of 22 START table model template.monthend_dates.................... [RUN]
2018-07-30 11:52:46,870: Compiling model.shopify_cohort_analysis.monthend_dates
2018-07-30 11:52:46,869: 11:52:46 | 2 of 22 START table model template.all_dates......................... [RUN]
2018-07-30 11:52:46,870: 11:52:46 | 3 of 22 START table model template.mappings_ga_proc.................. [RUN]
2018-07-30 11:52:46,870: 11:52:46 | 4 of 22 START table model template.stores_proc....................... [RUN]
2018-07-30 11:52:46,877: Compiling model.shopify_cohort_analysis.all_dates
2018-07-30 11:52:46,878: Writing injected SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 11:52:46,878: Compiling model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 11:52:46,879: Compiling model.shopify_cohort_analysis.stores_proc
2018-07-30 11:52:46,883: Writing injected SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 11:52:46,889: Writing injected SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 11:52:46,900: Writing injected SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 11:52:46,902: Acquiring new bigquery connection "monthend_dates".
2018-07-30 11:52:46,906: Acquiring new bigquery connection "all_dates".
2018-07-30 11:52:46,906: Opening a new connection (1 currently allocated)
2018-07-30 11:52:46,910: Acquiring new bigquery connection "mappings_ga_proc".
2018-07-30 11:52:46,913: Opening a new connection (2 currently allocated)
2018-07-30 11:52:46,916: Acquiring new bigquery connection "stores_proc".
2018-07-30 11:52:46,920: Opening a new connection (3 currently allocated)
2018-07-30 11:52:46,930: Opening a new connection (4 currently allocated)
2018-07-30 11:52:47,462: Writing runtime SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 11:52:47,489: Writing runtime SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 11:52:47,513: Writing runtime SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 11:52:47,514: Fetching data for query all_dates:
create or replace table `template`.`all_dates`
  
  as (
    SELECT 
date_in_range,
unix_date(date_in_range) unix_date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
  );

    
2018-07-30 11:52:47,526: Writing runtime SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 11:52:47,530: Fetching data for query mappings_ga_proc:
create or replace table `template`.`mappings_ga_proc`
  
  as (
    select 
store,
account,
store_name,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client store,
account,
client_name store_name,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.mappings_ga` 

) 

WHERE lv = time_of_entry
group by store, account, store_name, source, medium, platform_n, channel_n, time_of_entry
  );

    
2018-07-30 11:52:47,541: Fetching data for query monthend_dates:
create or replace table `template`.`monthend_dates`
  
  as (
    SELECT
date_in_range,
date_in_range_bom,
date_in_range_bom_mom,
unix_date_in_range,
unix_date_in_range_bom,
unix_date(date_in_range_bom_mom) unix_date_in_range_bom_mom,
yyyymm,
date_in_range_yoy,
unix_date(date_in_range_yoy) unix_date_in_range_yoy

FROM
(
	SELECT 
	date_in_range,
	date_in_range_bom,
	date_sub(date_in_range_bom, INTERVAL 1 MONTH) date_in_range_bom_mom,
	date_sub(date_in_range, INTERVAL 1 YEAR) date_in_range_yoy,
	unix_date_in_range,
	unix_date(date_in_range_bom) unix_date_in_range_bom,
	yyyymm,
	first_value(date_in_range) over (partition by yyyymm order by date_in_range desc) monthend_date_in_range
	FROM
	( 
		SELECT 
		date_in_range,
		date_trunc( date_in_range, MONTH) date_in_range_bom,
		unix_date(date_in_range) unix_date_in_range,
		format_date("%Y-%m", date_in_range) AS yyyymm
		FROM UNNEST(
		    GENERATE_DATE_ARRAY(DATE('2016-01-31'), CURRENT_DATE(), INTERVAL 1 DAY)
		) AS date_in_range
	)
)
where date_in_range = monthend_date_in_range
  );

    
2018-07-30 11:52:47,547: Fetching data for query stores_proc:
create or replace table `template`.`stores_proc`
  
  as (
    select 
store,
store_name,
account,
platform,
max(time_of_entry) time_of_entry

from  ( 

SELECT  
client store,
client_name store_name,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.accounts` 
where client_name != ''

) 

WHERE lv = time_of_entry
group by store, store_name, account, platform
  );

    
2018-07-30 11:52:49,497: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e665dd8>]}
2018-07-30 11:52:49,691: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e698470>]}
2018-07-30 11:52:49,794: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e698438>]}
2018-07-30 11:52:49,798: 11:52:49 | 1 of 22 OK created table model template.monthend_dates............... [OK in 2.63s]
2018-07-30 11:52:49,977: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e651278>]}
2018-07-30 11:52:50,097: 11:52:50 | 4 of 22 OK created table model template.stores_proc.................. [OK in 2.81s]
2018-07-30 11:52:50,873: 11:52:50 | 2 of 22 OK created table model template.all_dates.................... [OK in 2.92s]
2018-07-30 11:52:52,087: 11:52:52 | 3 of 22 OK created table model template.mappings_ga_proc............. [OK in 3.10s]
2018-07-30 11:52:52,088: 11:52:52 | 5 of 22 START table model template.shopify_refunds_proc.............. [RUN]
2018-07-30 11:52:52,088: Compiling model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 11:52:52,088: 11:52:52 | 6 of 22 START table model template.shopify_discounts_proc............ [RUN]
2018-07-30 11:52:52,094: Compiling model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 11:52:52,101: Acquiring new bigquery connection "shopify_refunds_proc".
2018-07-30 11:52:52,088: 11:52:52 | 7 of 22 START table model template.shopify_customers_proc............ [RUN]
2018-07-30 11:52:52,101: Re-using an available connection from the pool.
2018-07-30 11:52:52,101: Compiling model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 11:52:52,114: Acquiring new bigquery connection "shopify_discounts_proc".
2018-07-30 11:52:52,128: Re-using an available connection from the pool.
2018-07-30 11:52:52,136: Fetching data for query shopify_discounts_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 11:52:52,114: Fetching data for query shopify_refunds_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 11:52:52,136: Acquiring new bigquery connection "shopify_customers_proc".
2018-07-30 11:52:52,145: Re-using an available connection from the pool.
2018-07-30 11:52:52,145: Fetching data for query shopify_customers_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 11:52:53,835: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 11:52:53,838: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 11:52:54,002: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 11:52:54,003: Fetching data for query shopify_customers_proc:
create or replace table `template`.`shopify_customers_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`





with customers as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	created_at,
	id,
	first_name,
	last_name,
	email,
	_sdc_sequence,
	first_value(_sdc_sequence) over (partition by id order by _sdc_sequence desc) lv
	FROM `growth-engines-pipeline.shopify_lucadanni.customers` 
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
id,
first_name,
last_name,
email
FROM customers a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence


  );

    
2018-07-30 11:52:54,009: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 11:52:54,012: Fetching data for query shopify_discounts_proc:
create or replace table `template`.`shopify_discounts_proc`
  
  as (
    



with orders as (

	
		SELECT
		'lucadanni' store_name,
		created_at,
		order_number,
		code discount_code,
		type discount_type,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(discount_codes)
		where source_name != 'shopify_draft_order'
	
	
	

)

SELECT
store_name,
order_number,
discount_code,
discount_type
FROM orders
where lv = _sdc_sequence


  );

    
2018-07-30 11:52:54,297: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 11:52:54,494: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 11:52:54,496: Fetching data for query shopify_refunds_proc:
create or replace table `template`.`shopify_refunds_proc`
  
  as (
    



with refunds as (

	
	SELECT
	'lucadanni' store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal,
	line_item.variant_id variant_id,
	line_item.id refund_id,
 	_sdc_sequence
	FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
	cross join unnest(refunds), unnest(refund_line_items)
  	where financial_status like '%refund%'
	
	

)

SELECT * 
FROM 
	(
    SELECT
    store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal refund_amount,
	variant_id,
	refund_id,
 	_sdc_sequence,
    first_value(_sdc_sequence) OVER (PARTITION BY order_number, line_item_id ORDER BY _sdc_sequence DESC) lv
    FROM refunds
   	) 
WHERE lv = _sdc_sequence


  );

    
2018-07-30 11:52:56,253: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e651d30>]}
2018-07-30 11:52:56,606: 11:52:56 | 6 of 22 OK created table model template.shopify_discounts_proc....... [OK in 4.16s]
2018-07-30 11:52:56,794: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e6bfbe0>]}
2018-07-30 11:52:57,120: 11:52:57 | 5 of 22 OK created table model template.shopify_refunds_proc......... [OK in 4.71s]
2018-07-30 11:52:58,705: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce29f98>]}
2018-07-30 11:52:59,119: 11:52:59 | 7 of 22 OK created table model template.shopify_customers_proc....... [OK in 6.60s]
2018-07-30 11:52:59,119: 11:52:59 | 8 of 22 START table model template.ga_transactions................... [RUN]
2018-07-30 11:52:59,120: Compiling model.shopify_cohort_analysis.ga_transactions
2018-07-30 11:52:59,120: 11:52:59 | 9 of 22 START table model template.agg_customers..................... [RUN]
2018-07-30 11:52:59,122: Compiling model.shopify_cohort_analysis.agg_customers
2018-07-30 11:52:59,129: Writing injected SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 11:52:59,120: 11:52:59 | 10 of 22 START table model template.shopify_products_proc............ [RUN]
2018-07-30 11:52:59,135: Compiling model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 11:52:59,145: Acquiring new bigquery connection "ga_transactions".
2018-07-30 11:52:59,149: Acquiring new bigquery connection "shopify_products_proc".
2018-07-30 11:52:59,149: Re-using an available connection from the pool.
2018-07-30 11:52:59,149: Fetching data for query ga_transactions:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Google Analytics'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 11:52:59,150: Re-using an available connection from the pool.
2018-07-30 11:52:59,151: Fetching data for query shopify_products_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 11:52:59,155: Acquiring new bigquery connection "agg_customers".
2018-07-30 11:52:59,156: Re-using an available connection from the pool.
2018-07-30 11:52:59,286: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 11:52:59,288: Fetching data for query agg_customers:
create or replace table `template`.`agg_customers`
  
  as (
    SELECT 
account,
store,
id,
created_at,
first_name,
last_name,
email,
split(email,'@')[SAFE_ORDINAL(2)] email_domain
FROM
`growth-engines-pipeline`.`template`.`shopify_customers_proc`
  );

    
2018-07-30 11:52:59,979: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 11:53:00,204: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 11:53:00,205: Fetching data for query shopify_products_proc:
create or replace table `template`.`shopify_products_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`





with products as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	product_name,
	lower(product_type) product_type,
	product_id,
	sku,
	id variant_id,
	cast(created_at as date) created_at,
	_sdc_sequence,
	first_value(_sdc_sequence) OVER (PARTITION BY product_id ORDER BY _sdc_sequence DESC) lv
	FROM (
		SELECT
		variants,
		product_type,
		title product_name,
		_sdc_sequence
		FROM `growth-engines-pipeline.shopify_lucadanni.products` 
		)
	cross join unnest(variants)
	
	

)

SELECT
b.account,
b.store,
b.platform,
max(product_type) product_type,
product_id,
variant_id,
sku,
created_at,
product_name
FROM products a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence
group by product_id, account, store, platform, sku, variant_id, created_at, product_name


  );

    
2018-07-30 11:53:01,006: Writing injected SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 11:53:01,302: Writing runtime SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 11:53:01,303: Fetching data for query ga_transactions:
create or replace table `template`.`ga_transactions`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`,`growth-engines-pipeline`.`template`.`mappings_ga_proc`




with ga_report as (

	    
	    	
		   	SELECT
		   	'yandy' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_yandy.report` 

		     UNION ALL 
	   
	    	
		   	SELECT
		   	'lucadanni' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_lucadanni.report` 

		    
	   

)


SELECT  
date,
b.store store,
c.source source,
c.medium medium,
a.campaign campaign,
concat(a.source, ' / ', a.medium) source_medium,  
case when c.platform is null then "Unmapped" else c.platform end as platform,
case when c.channel is null then "Unmapped" else c.channel end as channel,
url,
transactionid
FROM (

	SELECT 
	store_name,
	lookup_platform,
	date,
	transactionid,
	max(url) url,
	max(source) source,
	max(medium) medium,
	max(campaign) campaign
	FROM ga_report
	where lv = _sdc_sequence
	group by store_name, lookup_platform, date, transactionid

) a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name 
	AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`mappings_ga_proc` c
ON ( a.source = c.source
  AND a.medium = c.medium 
  AND a.store_name = c.store_name )


  );

    
2018-07-30 11:53:02,937: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc445f8>]}
2018-07-30 11:53:03,253: 11:53:03 | 10 of 22 OK created table model template.shopify_products_proc....... [OK in 3.80s]
2018-07-30 11:53:03,532: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc44470>]}
2018-07-30 11:53:03,864: 11:53:03 | 9 of 22 OK created table model template.agg_customers................ [OK in 4.41s]
2018-07-30 11:53:28,920: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b397e48>]}
2018-07-30 11:53:30,190: 11:53:30 | 8 of 22 OK created table model template.ga_transactions.............. [OK in 29.80s]
2018-07-30 11:53:30,191: 11:53:30 | 11 of 22 START table model template.shopify_orders_proc.............. [RUN]
2018-07-30 11:53:30,192: Compiling model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 11:53:30,210: Acquiring new bigquery connection "shopify_orders_proc".
2018-07-30 11:53:30,210: Re-using an available connection from the pool.
2018-07-30 11:53:30,211: Fetching data for query shopify_orders_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 11:53:31,319: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 11:53:31,520: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 11:53:31,521: Fetching data for query shopify_orders_proc:
create or replace table `template`.`shopify_orders_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`, `growth-engines-pipeline`.`template`.`shopify_discounts_proc`





with orders as (

	
	SELECT 
	store_name,
	lookup_platform,
	created_at,
	order_number,
	quantity,
	price, 
	total_order_price_undiscounted,
	total_discounts,
	total_order_shipping_price,
	total_order_price_incl_shipping,
	checkout_id,
	product_id, 
	landing_site,
	sku, 
	variant_title, 
	variant_id,
	line_item_id,
	customer_id,
	_sdc_sequence,
	lv
	FROM (

		SELECT
		'lucadanni' store_name,
		'Shopify' as lookup_platform,
		created_at,
		order_number,
		quantity,
		cast(pre_tax_price as float64) price, 
		total_line_items_price total_order_price_undiscounted,
		total_discounts,
		cast(discounted_price as float64) total_order_shipping_price,
		total_price_usd total_order_price_incl_shipping,
		checkout_id,
		product_id, 
		landing_site,
		sku, 
		variant_title, 
		variant_id,
		_id line_item_id,
		customer.id customer_id,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(line_items), unnest(shipping_lines)
		where source_name != 'shopify_draft_order'
	)
	
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
a.order_number,
a.quantity prelim_quantity,
c.quantity refund_quantity,
case when c.quantity is not null then a.quantity - c.quantity else a.quantity end as quantity,
price prelim_revenue, 
total_order_price_undiscounted,
total_discounts,
trim(lower(d.discount_code)) discount_code,
d.discount_type,
total_order_shipping_price,
total_order_price_incl_shipping,
refund_amount,
case when refund_amount is not null then price - refund_amount else price end as revenue,
a.checkout_id,
a.product_id, 
landing_site,
sku, 
variant_title, 
a.variant_id,
a.line_item_id,	
customer_id
FROM orders a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_refunds_proc` c
ON ( a.order_number = c.order_number
	AND a.line_item_id = c.line_item_id
	AND a.store_name = c.store_name )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_discounts_proc` d
ON ( a.order_number = d.order_number 
    AND a.store_name = d.store_name )  	
where a.lv = a._sdc_sequence


  );

    
2018-07-30 11:53:42,165: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce29f98>]}
2018-07-30 11:53:44,797: 11:53:44 | 11 of 22 OK created table model template.shopify_orders_proc......... [OK in 11.97s]
2018-07-30 11:53:44,798: 11:53:44 | 12 of 22 START table model template.transaction_by_order_number...... [RUN]
2018-07-30 11:53:44,799: Compiling model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 11:53:44,813: Writing injected SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 11:53:44,815: Acquiring new bigquery connection "transaction_by_order_number".
2018-07-30 11:53:44,816: Re-using an available connection from the pool.
2018-07-30 11:53:45,091: Writing runtime SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 11:53:45,092: Fetching data for query transaction_by_order_number:
create or replace table `template`.`transaction_by_order_number`
  
  as (
    SELECT
store,
cast(created_at as date) order_date,
order_number,
customer_id,
sum(quantity) quantity,
sum(revenue) revenue,
max(total_order_shipping_price) shipping_price
FROM
`growth-engines-pipeline`.`template`.`shopify_orders_proc`
GROUP BY store, order_date, order_number, customer_id
  );

    
2018-07-30 11:53:49,616: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b397e48>]}
2018-07-30 11:53:50,729: 11:53:50 | 12 of 22 OK created table model template.transaction_by_order_number. [OK in 4.82s]
2018-07-30 11:53:50,731: 11:53:50 | 13 of 22 START table model template.customers_by_transaction......... [RUN]
2018-07-30 11:53:50,732: Compiling model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 11:53:50,744: Writing injected SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 11:53:50,748: Acquiring new bigquery connection "customers_by_transaction".
2018-07-30 11:53:50,748: Re-using an available connection from the pool.
2018-07-30 11:53:50,892: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 11:53:50,892: Fetching data for query customers_by_transaction:
create or replace table `template`.`customers_by_transaction`
  
  as (
    SELECT
store,
customer_id,
order_number,
order_date,
recent_order_date,
first_order_date,
case when first_order_number = order_number then 'New'
	when date_diff(order_date, recent_order_date, DAY) <= 365 then 'Repeat'
	when date_diff(order_date, recent_order_date, DAY) > 365 then 'Reactivated'
 else '' end as order_type,
quantity,
revenue,
1 as orders,
first_order_revenue,
lifetime_revenue
FROM

(

	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	quantity,
	revenue,
	lag(order_date) over w1 recent_order_date,
	first_value(order_date) over w1 first_order_date,
	first_value(order_number) over w1 first_order_number,
	first_value(revenue) over w1 first_order_revenue,
	sum(revenue) over w2 lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`transaction_by_order_number`
	WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc),
	w2 as (PARTITION BY store, customer_id)
)
  );

    
2018-07-30 11:53:54,832: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e6511d0>]}
2018-07-30 11:53:55,393: 11:53:55 | 13 of 22 OK created table model template.customers_by_transaction.... [OK in 4.10s]
2018-07-30 11:53:55,394: 11:53:55 | 14 of 22 START table model template.agg_transactions................. [RUN]
2018-07-30 11:53:55,394: Compiling model.shopify_cohort_analysis.agg_transactions
2018-07-30 11:53:55,404: Writing injected SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 11:53:55,406: Acquiring new bigquery connection "agg_transactions".
2018-07-30 11:53:55,406: Re-using an available connection from the pool.
2018-07-30 11:53:55,536: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 11:53:55,537: Fetching data for query agg_transactions:
create or replace table `template`.`agg_transactions`
  
  as (
    with ga_transaction as (

	SELECT
	date, 
	store,
	transactionid,
	channel,
	platform,
	url,
	campaign
	FROM `growth-engines-pipeline`.`template`.`ga_transactions`
),

customers_by_transaction as (
	
	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	first_order_date,
	recent_order_date,
	order_type,
	quantity,
	revenue,
	orders,
	first_order_revenue,
	lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`customers_by_transaction`
)

SELECT
store,
customer_id,
order_number,
transactionid,
order_date,
first_order_date,
format_date("%Y-%m", first_order_date) AS first_order_month,
order_type,
first_order_revenue,
lifetime_revenue,
first_value(channel) over w1 as first_order_channel,
first_value(platform) over w1 as first_order_platform,
channel,
platform,
url,
campaign,
quantity,
revenue,
orders
FROM (

	SELECT
	a.store,
	a.customer_id,
	a.order_number,
	b.transactionid,
	a.order_date, 
	a.first_order_date, 
	a.order_type,
	a.first_order_revenue,
	a.lifetime_revenue,
	b.channel,
	b.platform,
	b.url,
	b.campaign,
	a.quantity,
	a.revenue,
	a.orders
	FROM customers_by_transaction a
	LEFT JOIN ga_transaction b
	ON (
	    a.store = b.store AND
	    a.order_number = b.transactionid
	)	
)
WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc)
  );

    
2018-07-30 11:54:05,341: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b397e48>]}
2018-07-30 11:54:05,653: 11:54:05 | 14 of 22 OK created table model template.agg_transactions............ [OK in 9.95s]
2018-07-30 11:54:05,653: 11:54:05 | 15 of 22 START table model template.customers_proc_yoy............... [RUN]
2018-07-30 11:54:05,654: 11:54:05 | 16 of 22 START table model template.customers_proc_qoq............... [RUN]
2018-07-30 11:54:05,654: Compiling model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 11:54:05,654: 11:54:05 | 17 of 22 START table model template.monthly_cohort_stats............. [RUN]
2018-07-30 11:54:05,654: Compiling model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 11:54:05,662: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 11:54:05,663: Compiling model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 11:54:05,672: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 11:54:05,679: Writing injected SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 11:54:05,682: Acquiring new bigquery connection "customers_proc_yoy".
2018-07-30 11:54:05,684: Acquiring new bigquery connection "customers_proc_qoq".
2018-07-30 11:54:05,684: Re-using an available connection from the pool.
2018-07-30 11:54:05,685: Re-using an available connection from the pool.
2018-07-30 11:54:05,687: Acquiring new bigquery connection "monthly_cohort_stats".
2018-07-30 11:54:05,689: Re-using an available connection from the pool.
2018-07-30 11:54:05,915: Writing runtime SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 11:54:05,921: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 11:54:05,921: Fetching data for query monthly_cohort_stats:
create or replace table `template`.`monthly_cohort_stats`
  
  as (
    WITH transactions AS (

  SELECT 
  store, 
  order_number,
  order_date,
  order_type,
  first_order_month,
  unix_date(order_date) d, 
  customer_id, 
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (

  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT 
date_in_range date,
store, 
order_type,
first_order_channel,
first_order_platform,
first_order_month,
channel,
platform,
url,
campaign,
count(distinct(customer_id)) buyers,
sum(orders) orders,
sum(quantity) quantity,
sum(revenue) revenue
FROM daterange
JOIN transactions
ON transactions.d >= daterange.unix_date_in_range_bom 
AND transactions.d <= daterange.unix_date_in_range
GROUP BY month, store, order_type, 
first_order_channel, first_order_platform, first_order_month, channel, platform, url, campaign
  );

    
2018-07-30 11:54:05,925: Fetching data for query customers_proc_qoq:
create or replace table `template`.`customers_proc_qoq`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 90 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 90 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 90 window_end_unix_date, 
    unix_date_in_range - 180 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 180 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 90 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 11:54:06,296: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 11:54:06,304: Fetching data for query customers_proc_yoy:
create or replace table `template`.`customers_proc_yoy`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 365 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 365 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 365 window_end_unix_date, 
    unix_date_in_range - 730 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 730 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 365 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 11:54:06,504: Bad request while running:
create dataset
2018-07-30 11:54:06,505: 400 GET https://www.googleapis.com/bigquery/v2/projects/growth-engines-pipeline/queries/6cfada23-2a53-4ba8-8466-60c3f4ed9939?maxResults=0: Unrecognized name: month at [50:10]
2018-07-30 11:54:06,505: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e6667b8>]}
2018-07-30 11:54:07,598: 11:54:07 | 17 of 22 ERROR creating table model template.monthly_cohort_stats.... [ERROR in 0.84s]
2018-07-30 11:54:18,873: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e681860>]}
2018-07-30 11:54:19,367: 11:54:19 | 16 of 22 OK created table model template.customers_proc_qoq.......... [OK in 13.22s]
2018-07-30 11:54:32,407: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e6511d0>]}
2018-07-30 11:54:32,987: 11:54:32 | 15 of 22 OK created table model template.customers_proc_yoy.......... [OK in 26.75s]
2018-07-30 11:54:32,989: 11:54:32 | 18 of 22 START table model template.customers_proc................... [RUN]
2018-07-30 11:54:32,990: Compiling model.shopify_cohort_analysis.customers_proc
2018-07-30 11:54:33,012: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 11:54:33,017: Acquiring new bigquery connection "customers_proc".
2018-07-30 11:54:33,018: Re-using an available connection from the pool.
2018-07-30 11:54:33,199: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 11:54:33,200: Fetching data for query customers_proc:
create or replace table `template`.`customers_proc`
  
  as (
    SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_qoq`

UNION ALL

SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_yoy`
  );

    
2018-07-30 11:55:00,654: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b397e48>]}
2018-07-30 11:55:01,961: 11:55:01 | 18 of 22 OK created table model template.customers_proc.............. [OK in 27.66s]
2018-07-30 11:55:01,963: 11:55:01 | 19 of 22 START table model template.segment_proc_customers........... [RUN]
2018-07-30 11:55:01,964: Compiling model.shopify_cohort_analysis.segment_proc_customers
2018-07-30 11:55:01,977: Writing injected SQL for node "model.shopify_cohort_analysis.segment_proc_customers"
2018-07-30 11:55:01,979: Acquiring new bigquery connection "segment_proc_customers".
2018-07-30 11:55:01,979: Re-using an available connection from the pool.
2018-07-30 11:55:02,162: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_proc_customers"
2018-07-30 11:55:02,163: Fetching data for query segment_proc_customers:
create or replace table `template`.`segment_proc_customers`
  
  as (
    SELECT
store,
period,
customer_id,
date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct,
case when first_order_unix_date >= window_start_unix_date then 'New'
	else 'Existing' end as newness_segment,
case when revenue >= revenue_90pct then 'Whale'
	when revenue <= revenue_10pct then 'Minnow'
	else 'Bristlemouth' end as revenue_segment,
case when frequency = 1 then '1'
	when frequency = 2 then '2'
	when frequency > 2 then '3+'
	else null end as frequency_segment
FROM `growth-engines-pipeline`.`template`.`customers_proc`
  );

    
2018-07-30 11:55:29,821: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e6511d0>]}
2018-07-30 11:55:30,157: 11:55:30 | 19 of 22 OK created table model template.segment_proc_customers...... [OK in 27.86s]
2018-07-30 11:55:30,157: 11:55:30 | 20 of 22 START table model template.segment_stats_customers_agg...... [RUN]
2018-07-30 11:55:30,158: Compiling model.shopify_cohort_analysis.segment_stats_customers_agg
2018-07-30 11:55:30,166: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_customers_agg"
2018-07-30 11:55:30,171: Acquiring new bigquery connection "segment_stats_customers_agg".
2018-07-30 11:55:30,171: Re-using an available connection from the pool.
2018-07-30 11:55:30,298: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_customers_agg"
2018-07-30 11:55:30,299: Fetching data for query segment_stats_customers_agg:
create or replace table `template`.`segment_stats_customers_agg`
  
  as (
    WITH ty as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Year'

),

this_month_1yr as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Previous Year'

),

this_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,	
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Quarter'

),

last_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev		
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Previous Quarter'

)

SELECT
store,
period,
date, 
customer_id,
1 as buyers,
first_order_channel,
first_order_platform,	
case when max(revenue_segment) != '' then max(revenue_segment) 
	when max(revenue_segment_prev) != '' then 'Dormant'
	else '' end as revenue_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(revenue_segment_prev) end as revenue_segment_prev,
case when max(frequency_segment) != '' then max(frequency_segment) 
	when max(frequency_segment_prev) != '' then 'Dormant'
	else '' end as frequency_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(frequency_segment_prev) end as frequency_segment_prev,
ifnull(sum(recency), 0) recency,
ifnull(sum(frequency), 0) frequency,
ifnull(sum(revenue), 0) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else 0 end as aov,
ifnull(sum(recency_prev), 0) recency_prev,
ifnull(sum(frequency_prev), 0) frequency_prev,
ifnull(sum(revenue_prev), 0) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else 0 end as aov_prev
FROM
(
	SELECT * FROM ty
	UNION ALL
	SELECT * FROM this_month_1yr
	UNION ALL
	SELECT * FROM this_quarter
	UNION ALL
	SELECT * FROM last_quarter

)
GROUP BY store, period, date, customer_id, first_order_channel, first_order_platform
  );

    
2018-07-30 11:56:04,270: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b397e48>]}
2018-07-30 11:56:05,590: 11:56:05 | 20 of 22 OK created table model template.segment_stats_customers_agg. [OK in 34.11s]
2018-07-30 11:56:05,592: 11:56:05 | 21 of 22 START table model template.buyer_segment_stats.............. [RUN]
2018-07-30 11:56:05,593: Compiling model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 11:56:05,612: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 11:56:05,615: Acquiring new bigquery connection "buyer_segment_stats".
2018-07-30 11:56:05,615: Re-using an available connection from the pool.
2018-07-30 11:56:05,731: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 11:56:05,732: Fetching data for query buyer_segment_stats:
create or replace table `template`.`buyer_segment_stats`
  
  as (
    SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type
  );

    
2018-07-30 11:56:09,624: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e6511d0>]}
2018-07-30 11:56:10,757: 11:56:10 | 21 of 22 OK created table model template.buyer_segment_stats......... [OK in 4.03s]
2018-07-30 11:56:10,761: 11:56:10 | 22 of 22 START table model template.buyer_segment_lists.............. [RUN]
2018-07-30 11:56:10,761: Compiling model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 11:56:10,770: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 11:56:10,774: Acquiring new bigquery connection "buyer_segment_lists".
2018-07-30 11:56:10,774: Re-using an available connection from the pool.
2018-07-30 11:56:11,070: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 11:56:11,076: Fetching data for query buyer_segment_lists:
create or replace table `template`.`buyer_segment_lists`
  
  as (
    SELECT
a.store,
period,
date,
customer_id,
b.first_name,
b.last_name,
b.email,
recency,
frequency,
revenue,
aov,
revenue_segment,
frequency_segment
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg` a
LEFT JOIN `growth-engines-pipeline`.`template`.`agg_customers` b
ON (
	a.store = b.store AND
	a.customer_id = b.id
)
where ( revenue_segment != '' or frequency_segment != '' )
  );

    
2018-07-30 11:56:51,037: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3be4358-a4ee-4241-997b-c3aa09735d90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b397e48>]}
2018-07-30 11:56:51,360: 11:56:51 | 22 of 22 OK created table model template.buyer_segment_lists......... [OK in 40.28s]
2018-07-30 11:56:51,454: 11:56:51 | 
2018-07-30 11:56:51,454: 11:56:51 | Finished running 22 table models in 246.24s.
2018-07-30 11:56:51,455: Connection 'master' was left open.
2018-07-30 11:56:51,455: 
2018-07-30 11:56:51,455: Completed with 1 errors:
2018-07-30 11:56:51,455: 
2018-07-30 11:56:51,455: Database Error in model monthly_cohort_stats (models/math/cohort-analysis/monthly_cohort_stats.sql)
2018-07-30 11:56:51,456:   Unrecognized name: month at [50:10]
2018-07-30 11:56:51,456:   compiled SQL at target/run/shopify_cohort_analysis/math/cohort-analysis/monthly_cohort_stats.sql
2018-07-30 11:56:51,456: 
Done. PASS=21 ERROR=1 SKIP=0 TOTAL=22
2018-07-30 11:56:51,456: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b394e48>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b3630f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b363080>]}
2018-07-30 11:56:51,754: Flushing usage events
2018-07-30 11:56:52,201: sys:1: ResourceWarning: unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50097), raddr=('172.217.1.205', 443)>

2018-07-30 11:56:52,202: sys:1: ResourceWarning: unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50096), raddr=('172.217.3.10', 443)>

2018-07-30 11:56:52,202: sys:1: ResourceWarning: unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50095), raddr=('172.217.1.205', 443)>

2018-07-30 11:56:52,203: sys:1: ResourceWarning: unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50098), raddr=('172.217.1.205', 443)>

2018-07-30 11:56:52,203: sys:1: ResourceWarning: unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50099), raddr=('172.217.1.205', 443)>

2018-07-30 11:56:52,203: sys:1: ResourceWarning: unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50100), raddr=('172.217.1.205', 443)>

2018-07-30 11:56:52,204: sys:1: ResourceWarning: unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50102), raddr=('172.217.12.10', 443)>

2018-07-30 11:56:52,204: sys:1: ResourceWarning: unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50101), raddr=('172.217.12.10', 443)>

2018-07-30 11:56:52,205: sys:1: ResourceWarning: unclosed <socket.socket fd=22, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50103), raddr=('172.217.12.10', 443)>

2018-07-30 11:56:52,205: sys:1: ResourceWarning: unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50104), raddr=('172.217.12.10', 443)>

2018-07-30 12:03:17,996: Tracking: tracking
2018-07-30 12:03:17,998: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082502b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108250f28>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108250128>]}
2018-07-30 12:03:20,323: Loading dependency project from /usr/local/Cellar/dbt/0.10.1/libexec/lib/python3.6/site-packages/dbt/include
2018-07-30 12:03:20,377: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/shopify-cohort-analysis/dbt_modules
2018-07-30 12:03:20,384: Parsing get_column_values.sql
2018-07-30 12:03:20,418: Parsing get_url_parameter.sql
2018-07-30 12:03:20,430: Parsing split_part.sql
2018-07-30 12:03:20,449: Parsing table_exists.sql
2018-07-30 12:03:20,474: Parsing core.sql
2018-07-30 12:03:20,522: Parsing adapters/bigquery.sql
2018-07-30 12:03:20,533: Parsing adapters/common.sql
2018-07-30 12:03:20,602: Parsing adapters/redshift.sql
2018-07-30 12:03:20,638: Parsing adapters/snowflake.sql
2018-07-30 12:03:20,648: Parsing etc/bigquery.sql
2018-07-30 12:03:20,652: Parsing etc/datetime.sql
2018-07-30 12:03:20,726: Parsing etc/get_custom_schema.sql
2018-07-30 12:03:20,743: Parsing materializations/helpers.sql
2018-07-30 12:03:20,780: Parsing materializations/archive/archive.sql
2018-07-30 12:03:20,934: Parsing materializations/incremental/incremental.sql
2018-07-30 12:03:20,981: Parsing materializations/seed/bigquery.sql
2018-07-30 12:03:20,995: Parsing materializations/seed/seed.sql
2018-07-30 12:03:21,064: Parsing materializations/table/bigquery_table.sql
2018-07-30 12:03:21,115: Parsing materializations/table/table.sql
2018-07-30 12:03:21,163: Parsing materializations/view/bigquery_view.sql
2018-07-30 12:03:21,215: Parsing materializations/view/view.sql
2018-07-30 12:03:21,262: Parsing schema_tests/accepted_values.sql
2018-07-30 12:03:21,274: Parsing schema_tests/not_null.sql
2018-07-30 12:03:21,280: Parsing schema_tests/relationships.sql
2018-07-30 12:03:21,285: Parsing schema_tests/unique.sql
2018-07-30 12:03:21,318: Parsing model.shopify_cohort_analysis.all_dates
2018-07-30 12:03:21,322: Parsing model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 12:03:21,326: Parsing model.shopify_cohort_analysis.monthend_dates
2018-07-30 12:03:21,329: Parsing model.shopify_cohort_analysis.stores_proc
2018-07-30 12:03:21,332: Parsing model.shopify_cohort_analysis.ga_transactions
2018-07-30 12:03:21,348: Parsing model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 12:03:21,360: Parsing model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 12:03:21,368: Parsing model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 12:03:21,384: Parsing model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 12:03:21,398: Parsing model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 12:03:21,414: Parsing model.shopify_cohort_analysis.agg_customers
2018-07-30 12:03:21,418: Parsing model.shopify_cohort_analysis.agg_transactions
2018-07-30 12:03:21,425: Parsing model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 12:03:21,429: Parsing model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 12:03:21,433: Parsing model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 12:03:21,439: Parsing model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 12:03:21,451: Parsing model.shopify_cohort_analysis.customers_proc
2018-07-30 12:03:21,457: Parsing model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 12:03:21,462: Parsing model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 12:03:21,468: Parsing model.shopify_cohort_analysis.segment_proc_customers
2018-07-30 12:03:21,474: Parsing model.shopify_cohort_analysis.segment_stats_customers_agg
2018-07-30 12:03:21,482: Parsing model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 12:03:21,517: Found 22 models, 0 tests, 0 archives, 0 analyses, 62 macros, 0 operations, 0 seed files
2018-07-30 12:03:21,546: 
2018-07-30 12:03:21,634: Acquiring new bigquery connection "master".
2018-07-30 12:03:21,635: Opening a new connection (0 currently allocated)
2018-07-30 12:03:24,349: 12:03:24 | Concurrency: 4 threads (target='template')
2018-07-30 12:03:24,349: 12:03:24 | 
2018-07-30 12:03:24,461: 12:03:24 | 1 of 22 START table model template.monthend_dates.................... [RUN]
2018-07-30 12:03:24,462: Compiling model.shopify_cohort_analysis.monthend_dates
2018-07-30 12:03:24,462: 12:03:24 | 2 of 22 START table model template.all_dates......................... [RUN]
2018-07-30 12:03:24,469: Compiling model.shopify_cohort_analysis.all_dates
2018-07-30 12:03:24,462: 12:03:24 | 3 of 22 START table model template.mappings_ga_proc.................. [RUN]
2018-07-30 12:03:24,485: Compiling model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 12:03:24,470: Writing injected SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 12:03:24,484: Writing injected SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 12:03:24,462: 12:03:24 | 4 of 22 START table model template.stores_proc....................... [RUN]
2018-07-30 12:03:24,499: Writing injected SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 12:03:24,500: Compiling model.shopify_cohort_analysis.stores_proc
2018-07-30 12:03:24,516: Acquiring new bigquery connection "mappings_ga_proc".
2018-07-30 12:03:24,516: Opening a new connection (1 currently allocated)
2018-07-30 12:03:24,526: Writing injected SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 12:03:24,531: Acquiring new bigquery connection "monthend_dates".
2018-07-30 12:03:24,532: Acquiring new bigquery connection "all_dates".
2018-07-30 12:03:24,534: Opening a new connection (2 currently allocated)
2018-07-30 12:03:24,538: Acquiring new bigquery connection "stores_proc".
2018-07-30 12:03:24,543: Opening a new connection (3 currently allocated)
2018-07-30 12:03:24,546: Opening a new connection (4 currently allocated)
2018-07-30 12:03:26,092: Writing runtime SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 12:03:26,102: Writing runtime SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 12:03:26,103: Fetching data for query all_dates:
create or replace table `template`.`all_dates`
  
  as (
    SELECT 
date_in_range,
unix_date(date_in_range) unix_date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
  );

    
2018-07-30 12:03:26,107: Fetching data for query monthend_dates:
create or replace table `template`.`monthend_dates`
  
  as (
    SELECT
date_in_range,
date_in_range_bom,
date_in_range_bom_mom,
unix_date_in_range,
unix_date_in_range_bom,
unix_date(date_in_range_bom_mom) unix_date_in_range_bom_mom,
yyyymm,
date_in_range_yoy,
unix_date(date_in_range_yoy) unix_date_in_range_yoy

FROM
(
	SELECT 
	date_in_range,
	date_in_range_bom,
	date_sub(date_in_range_bom, INTERVAL 1 MONTH) date_in_range_bom_mom,
	date_sub(date_in_range, INTERVAL 1 YEAR) date_in_range_yoy,
	unix_date_in_range,
	unix_date(date_in_range_bom) unix_date_in_range_bom,
	yyyymm,
	first_value(date_in_range) over (partition by yyyymm order by date_in_range desc) monthend_date_in_range
	FROM
	( 
		SELECT 
		date_in_range,
		date_trunc( date_in_range, MONTH) date_in_range_bom,
		unix_date(date_in_range) unix_date_in_range,
		format_date("%Y-%m", date_in_range) AS yyyymm
		FROM UNNEST(
		    GENERATE_DATE_ARRAY(DATE('2016-01-31'), CURRENT_DATE(), INTERVAL 1 DAY)
		) AS date_in_range
	)
)
where date_in_range = monthend_date_in_range
  );

    
2018-07-30 12:03:26,396: Writing runtime SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 12:03:26,397: Fetching data for query stores_proc:
create or replace table `template`.`stores_proc`
  
  as (
    select 
store,
store_name,
account,
platform,
max(time_of_entry) time_of_entry

from  ( 

SELECT  
client store,
client_name store_name,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.accounts` 
where client_name != ''

) 

WHERE lv = time_of_entry
group by store, store_name, account, platform
  );

    
2018-07-30 12:03:26,697: Writing runtime SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 12:03:26,697: Fetching data for query mappings_ga_proc:
create or replace table `template`.`mappings_ga_proc`
  
  as (
    select 
store,
account,
store_name,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client store,
account,
client_name store_name,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.mappings_ga` 

) 

WHERE lv = time_of_entry
group by store, account, store_name, source, medium, platform_n, channel_n, time_of_entry
  );

    
2018-07-30 12:03:28,006: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105884400>]}
2018-07-30 12:03:28,010: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10583f358>]}
2018-07-30 12:03:28,560: 12:03:28 | 1 of 22 OK created table model template.monthend_dates............... [OK in 3.54s]
2018-07-30 12:03:28,795: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105884240>]}
2018-07-30 12:03:28,827: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10583c4a8>]}
2018-07-30 12:03:29,000: 12:03:29 | 2 of 22 OK created table model template.all_dates.................... [OK in 3.54s]
2018-07-30 12:03:29,318: 12:03:29 | 3 of 22 OK created table model template.mappings_ga_proc............. [OK in 4.31s]
2018-07-30 12:03:29,630: 12:03:29 | 4 of 22 OK created table model template.stores_proc.................. [OK in 4.33s]
2018-07-30 12:03:29,630: 12:03:29 | 5 of 22 START table model template.shopify_refunds_proc.............. [RUN]
2018-07-30 12:03:29,631: 12:03:29 | 6 of 22 START table model template.shopify_customers_proc............ [RUN]
2018-07-30 12:03:29,631: Compiling model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 12:03:29,631: 12:03:29 | 7 of 22 START table model template.shopify_discounts_proc............ [RUN]
2018-07-30 12:03:29,631: Compiling model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 12:03:29,634: Compiling model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 12:03:29,657: Acquiring new bigquery connection "shopify_customers_proc".
2018-07-30 12:03:29,659: Acquiring new bigquery connection "shopify_discounts_proc".
2018-07-30 12:03:29,664: Re-using an available connection from the pool.
2018-07-30 12:03:29,668: Acquiring new bigquery connection "shopify_refunds_proc".
2018-07-30 12:03:29,668: Fetching data for query shopify_customers_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:03:29,668: Re-using an available connection from the pool.
2018-07-30 12:03:29,669: Fetching data for query shopify_discounts_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:03:29,677: Re-using an available connection from the pool.
2018-07-30 12:03:29,677: Fetching data for query shopify_refunds_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:03:31,734: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 12:03:31,992: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 12:03:32,115: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 12:03:32,142: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 12:03:32,142: Fetching data for query shopify_discounts_proc:
create or replace table `template`.`shopify_discounts_proc`
  
  as (
    



with orders as (

	
		SELECT
		'lucadanni' store_name,
		created_at,
		order_number,
		code discount_code,
		type discount_type,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(discount_codes)
		where source_name != 'shopify_draft_order'
	
	
	

)

SELECT
store_name,
order_number,
discount_code,
discount_type
FROM orders
where lv = _sdc_sequence


  );

    
2018-07-30 12:03:32,276: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 12:03:32,277: Fetching data for query shopify_refunds_proc:
create or replace table `template`.`shopify_refunds_proc`
  
  as (
    



with refunds as (

	
	SELECT
	'lucadanni' store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal,
	line_item.variant_id variant_id,
	line_item.id refund_id,
 	_sdc_sequence
	FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
	cross join unnest(refunds), unnest(refund_line_items)
  	where financial_status like '%refund%'
	
	

)

SELECT * 
FROM 
	(
    SELECT
    store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal refund_amount,
	variant_id,
	refund_id,
 	_sdc_sequence,
    first_value(_sdc_sequence) OVER (PARTITION BY order_number, line_item_id ORDER BY _sdc_sequence DESC) lv
    FROM refunds
   	) 
WHERE lv = _sdc_sequence


  );

    
2018-07-30 12:03:32,326: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 12:03:32,327: Fetching data for query shopify_customers_proc:
create or replace table `template`.`shopify_customers_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`





with customers as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	created_at,
	id,
	first_name,
	last_name,
	email,
	_sdc_sequence,
	first_value(_sdc_sequence) over (partition by id order by _sdc_sequence desc) lv
	FROM `growth-engines-pipeline.shopify_lucadanni.customers` 
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
id,
first_name,
last_name,
email
FROM customers a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence


  );

    
2018-07-30 12:03:36,463: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1083bb400>]}
2018-07-30 12:03:38,366: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058dc2e8>]}
2018-07-30 12:03:38,606: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10583f358>]}
2018-07-30 12:03:39,763: 12:03:39 | 5 of 22 OK created table model template.shopify_refunds_proc......... [OK in 6.83s]
2018-07-30 12:03:40,199: 12:03:40 | 7 of 22 OK created table model template.shopify_discounts_proc....... [OK in 8.73s]
2018-07-30 12:03:40,564: 12:03:40 | 6 of 22 OK created table model template.shopify_customers_proc....... [OK in 8.97s]
2018-07-30 12:03:40,565: 12:03:40 | 8 of 22 START table model template.agg_customers..................... [RUN]
2018-07-30 12:03:40,565: Compiling model.shopify_cohort_analysis.agg_customers
2018-07-30 12:03:40,565: 12:03:40 | 9 of 22 START table model template.ga_transactions................... [RUN]
2018-07-30 12:03:40,580: Compiling model.shopify_cohort_analysis.ga_transactions
2018-07-30 12:03:40,586: Writing injected SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 12:03:40,565: 12:03:40 | 10 of 22 START table model template.shopify_products_proc............ [RUN]
2018-07-30 12:03:40,603: Compiling model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 12:03:40,608: Acquiring new bigquery connection "ga_transactions".
2018-07-30 12:03:40,620: Re-using an available connection from the pool.
2018-07-30 12:03:40,621: Fetching data for query ga_transactions:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Google Analytics'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:03:40,644: Acquiring new bigquery connection "shopify_products_proc".
2018-07-30 12:03:40,647: Acquiring new bigquery connection "agg_customers".
2018-07-30 12:03:40,647: Re-using an available connection from the pool.
2018-07-30 12:03:40,647: Fetching data for query shopify_products_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:03:40,657: Re-using an available connection from the pool.
2018-07-30 12:03:40,901: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 12:03:40,903: Fetching data for query agg_customers:
create or replace table `template`.`agg_customers`
  
  as (
    SELECT 
account,
store,
id,
created_at,
first_name,
last_name,
email,
split(email,'@')[SAFE_ORDINAL(2)] email_domain
FROM
`growth-engines-pipeline`.`template`.`shopify_customers_proc`
  );

    
2018-07-30 12:03:41,597: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 12:03:41,865: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 12:03:41,865: Fetching data for query shopify_products_proc:
create or replace table `template`.`shopify_products_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`





with products as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	product_name,
	lower(product_type) product_type,
	product_id,
	sku,
	id variant_id,
	cast(created_at as date) created_at,
	_sdc_sequence,
	first_value(_sdc_sequence) OVER (PARTITION BY product_id ORDER BY _sdc_sequence DESC) lv
	FROM (
		SELECT
		variants,
		product_type,
		title product_name,
		_sdc_sequence
		FROM `growth-engines-pipeline.shopify_lucadanni.products` 
		)
	cross join unnest(variants)
	
	

)

SELECT
b.account,
b.store,
b.platform,
max(product_type) product_type,
product_id,
variant_id,
sku,
created_at,
product_name
FROM products a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence
group by product_id, account, store, platform, sku, variant_id, created_at, product_name


  );

    
2018-07-30 12:03:43,220: Writing injected SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 12:03:43,432: Writing runtime SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 12:03:43,433: Fetching data for query ga_transactions:
create or replace table `template`.`ga_transactions`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`,`growth-engines-pipeline`.`template`.`mappings_ga_proc`




with ga_report as (

	    
	    	
		   	SELECT
		   	'yandy' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_yandy.report` 

		     UNION ALL 
	   
	    	
		   	SELECT
		   	'lucadanni' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_lucadanni.report` 

		    
	   

)


SELECT  
date,
b.store store,
c.source source,
c.medium medium,
a.campaign campaign,
concat(a.source, ' / ', a.medium) source_medium,  
case when c.platform is null then "Unmapped" else c.platform end as platform,
case when c.channel is null then "Unmapped" else c.channel end as channel,
url,
transactionid
FROM (

	SELECT 
	store_name,
	lookup_platform,
	date,
	transactionid,
	max(url) url,
	max(source) source,
	max(medium) medium,
	max(campaign) campaign
	FROM ga_report
	where lv = _sdc_sequence
	group by store_name, lookup_platform, date, transactionid

) a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name 
	AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`mappings_ga_proc` c
ON ( a.source = c.source
  AND a.medium = c.medium 
  AND a.store_name = c.store_name )


  );

    
2018-07-30 12:03:44,948: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10838a2b0>]}
2018-07-30 12:03:45,268: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10583c4a8>]}
2018-07-30 12:03:48,239: 12:03:48 | 10 of 22 OK created table model template.shopify_products_proc....... [OK in 4.34s]
2018-07-30 12:03:49,274: 12:03:49 | 8 of 22 OK created table model template.agg_customers................ [OK in 4.70s]
2018-07-30 12:04:08,291: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10584e898>]}
2018-07-30 12:04:09,359: 12:04:09 | 9 of 22 OK created table model template.ga_transactions.............. [OK in 27.71s]
2018-07-30 12:04:09,360: 12:04:09 | 11 of 22 START table model template.shopify_orders_proc.............. [RUN]
2018-07-30 12:04:09,360: Compiling model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 12:04:09,380: Acquiring new bigquery connection "shopify_orders_proc".
2018-07-30 12:04:09,380: Re-using an available connection from the pool.
2018-07-30 12:04:09,380: Fetching data for query shopify_orders_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:04:10,386: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 12:04:10,692: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 12:04:10,693: Fetching data for query shopify_orders_proc:
create or replace table `template`.`shopify_orders_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`, `growth-engines-pipeline`.`template`.`shopify_discounts_proc`





with orders as (

	
	SELECT 
	store_name,
	lookup_platform,
	created_at,
	order_number,
	quantity,
	price, 
	total_order_price_undiscounted,
	total_discounts,
	total_order_shipping_price,
	total_order_price_incl_shipping,
	checkout_id,
	product_id, 
	landing_site,
	sku, 
	variant_title, 
	variant_id,
	line_item_id,
	customer_id,
	_sdc_sequence,
	lv
	FROM (

		SELECT
		'lucadanni' store_name,
		'Shopify' as lookup_platform,
		created_at,
		order_number,
		quantity,
		cast(pre_tax_price as float64) price, 
		total_line_items_price total_order_price_undiscounted,
		total_discounts,
		cast(discounted_price as float64) total_order_shipping_price,
		total_price_usd total_order_price_incl_shipping,
		checkout_id,
		product_id, 
		landing_site,
		sku, 
		variant_title, 
		variant_id,
		_id line_item_id,
		customer.id customer_id,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(line_items), unnest(shipping_lines)
		where source_name != 'shopify_draft_order'
	)
	
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
a.order_number,
a.quantity prelim_quantity,
c.quantity refund_quantity,
case when c.quantity is not null then a.quantity - c.quantity else a.quantity end as quantity,
price prelim_revenue, 
total_order_price_undiscounted,
total_discounts,
trim(lower(d.discount_code)) discount_code,
d.discount_type,
total_order_shipping_price,
total_order_price_incl_shipping,
refund_amount,
case when refund_amount is not null then price - refund_amount else price end as revenue,
a.checkout_id,
a.product_id, 
landing_site,
sku, 
variant_title, 
a.variant_id,
a.line_item_id,	
customer_id
FROM orders a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_refunds_proc` c
ON ( a.order_number = c.order_number
	AND a.line_item_id = c.line_item_id
	AND a.store_name = c.store_name )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_discounts_proc` d
ON ( a.order_number = d.order_number 
    AND a.store_name = d.store_name )  	
where a.lv = a._sdc_sequence


  );

    
2018-07-30 12:04:19,141: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10583f358>]}
2018-07-30 12:04:19,696: 12:04:19 | 11 of 22 OK created table model template.shopify_orders_proc......... [OK in 9.78s]
2018-07-30 12:04:19,697: 12:04:19 | 12 of 22 START table model template.transaction_by_order_number...... [RUN]
2018-07-30 12:04:19,697: Compiling model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 12:04:19,703: Writing injected SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 12:04:19,704: Acquiring new bigquery connection "transaction_by_order_number".
2018-07-30 12:04:19,704: Re-using an available connection from the pool.
2018-07-30 12:04:19,864: Writing runtime SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 12:04:19,865: Fetching data for query transaction_by_order_number:
create or replace table `template`.`transaction_by_order_number`
  
  as (
    SELECT
store,
cast(created_at as date) order_date,
order_number,
customer_id,
sum(quantity) quantity,
sum(revenue) revenue,
max(total_order_shipping_price) shipping_price
FROM
`growth-engines-pipeline`.`template`.`shopify_orders_proc`
GROUP BY store, order_date, order_number, customer_id
  );

    
2018-07-30 12:04:24,955: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105895e48>]}
2018-07-30 12:04:26,964: 12:04:26 | 12 of 22 OK created table model template.transaction_by_order_number. [OK in 5.26s]
2018-07-30 12:04:26,965: 12:04:26 | 13 of 22 START table model template.customers_by_transaction......... [RUN]
2018-07-30 12:04:26,965: Compiling model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 12:04:26,972: Writing injected SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 12:04:26,977: Acquiring new bigquery connection "customers_by_transaction".
2018-07-30 12:04:26,977: Re-using an available connection from the pool.
2018-07-30 12:04:27,268: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 12:04:27,268: Fetching data for query customers_by_transaction:
create or replace table `template`.`customers_by_transaction`
  
  as (
    SELECT
store,
customer_id,
order_number,
order_date,
recent_order_date,
first_order_date,
case when first_order_number = order_number then 'New'
	when date_diff(order_date, recent_order_date, DAY) <= 365 then 'Repeat'
	when date_diff(order_date, recent_order_date, DAY) > 365 then 'Reactivated'
 else '' end as order_type,
quantity,
revenue,
1 as orders,
first_order_revenue,
lifetime_revenue
FROM

(

	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	quantity,
	revenue,
	lag(order_date) over w1 recent_order_date,
	first_value(order_date) over w1 first_order_date,
	first_value(order_number) over w1 first_order_number,
	first_value(revenue) over w1 first_order_revenue,
	sum(revenue) over w2 lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`transaction_by_order_number`
	WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc),
	w2 as (PARTITION BY store, customer_id)
)
  );

    
2018-07-30 12:04:31,262: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10583f358>]}
2018-07-30 12:04:33,461: 12:04:33 | 13 of 22 OK created table model template.customers_by_transaction.... [OK in 4.30s]
2018-07-30 12:04:33,465: 12:04:33 | 14 of 22 START table model template.agg_transactions................. [RUN]
2018-07-30 12:04:33,466: Compiling model.shopify_cohort_analysis.agg_transactions
2018-07-30 12:04:33,474: Writing injected SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 12:04:33,477: Acquiring new bigquery connection "agg_transactions".
2018-07-30 12:04:33,477: Re-using an available connection from the pool.
2018-07-30 12:04:33,818: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 12:04:33,819: Fetching data for query agg_transactions:
create or replace table `template`.`agg_transactions`
  
  as (
    with ga_transaction as (

	SELECT
	date, 
	store,
	transactionid,
	channel,
	platform,
	url,
	campaign
	FROM `growth-engines-pipeline`.`template`.`ga_transactions`
),

customers_by_transaction as (
	
	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	first_order_date,
	recent_order_date,
	order_type,
	quantity,
	revenue,
	orders,
	first_order_revenue,
	lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`customers_by_transaction`
)

SELECT
store,
customer_id,
order_number,
transactionid,
order_date,
first_order_date,
format_date("%Y-%m", first_order_date) AS first_order_month,
order_type,
first_order_revenue,
lifetime_revenue,
first_value(channel) over w1 as first_order_channel,
first_value(platform) over w1 as first_order_platform,
channel,
platform,
url,
campaign,
quantity,
revenue,
orders
FROM (

	SELECT
	a.store,
	a.customer_id,
	a.order_number,
	b.transactionid,
	a.order_date, 
	a.first_order_date, 
	a.order_type,
	a.first_order_revenue,
	a.lifetime_revenue,
	b.channel,
	b.platform,
	b.url,
	b.campaign,
	a.quantity,
	a.revenue,
	a.orders
	FROM customers_by_transaction a
	LEFT JOIN ga_transaction b
	ON (
	    a.store = b.store AND
	    a.order_number = b.transactionid
	)	
)
WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc)
  );

    
2018-07-30 12:04:42,974: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105895e48>]}
2018-07-30 12:04:44,110: 12:04:44 | 14 of 22 OK created table model template.agg_transactions............ [OK in 9.51s]
2018-07-30 12:04:44,111: 12:04:44 | 15 of 22 START table model template.monthly_cohort_stats............. [RUN]
2018-07-30 12:04:44,111: Compiling model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 12:04:44,117: 12:04:44 | 16 of 22 START table model template.customers_proc_qoq............... [RUN]
2018-07-30 12:04:44,117: Compiling model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 12:04:44,123: 12:04:44 | 17 of 22 START table model template.customers_proc_yoy............... [RUN]
2018-07-30 12:04:44,132: Compiling model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 12:04:44,134: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 12:04:44,138: Writing injected SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 12:04:44,152: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 12:04:44,161: Acquiring new bigquery connection "customers_proc_yoy".
2018-07-30 12:04:44,161: Re-using an available connection from the pool.
2018-07-30 12:04:44,155: Acquiring new bigquery connection "customers_proc_qoq".
2018-07-30 12:04:44,169: Acquiring new bigquery connection "monthly_cohort_stats".
2018-07-30 12:04:44,197: Re-using an available connection from the pool.
2018-07-30 12:04:44,199: Re-using an available connection from the pool.
2018-07-30 12:04:44,463: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 12:04:44,464: Fetching data for query customers_proc_yoy:
create or replace table `template`.`customers_proc_yoy`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 365 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 365 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 365 window_end_unix_date, 
    unix_date_in_range - 730 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 730 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 365 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 12:04:44,559: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 12:04:44,560: Fetching data for query customers_proc_qoq:
create or replace table `template`.`customers_proc_qoq`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 90 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 90 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 90 window_end_unix_date, 
    unix_date_in_range - 180 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 180 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 90 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 12:04:45,671: Writing runtime SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 12:04:45,672: Fetching data for query monthly_cohort_stats:
create or replace table `template`.`monthly_cohort_stats`
  
  as (
    WITH transactions AS (

  SELECT 
  store, 
  order_number,
  order_date,
  order_type,
  first_order_month,
  unix_date(order_date) d, 
  customer_id, 
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (

  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT 
date_in_range date,
store, 
order_type,
first_order_channel,
first_order_platform,
first_order_month,
channel,
platform,
url,
campaign,
count(distinct(customer_id)) buyers,
sum(orders) orders,
sum(quantity) quantity,
sum(revenue) revenue
FROM daterange
JOIN transactions
ON transactions.d >= daterange.unix_date_in_range_bom 
AND transactions.d <= daterange.unix_date_in_range
GROUP BY date, store, order_type, 
first_order_channel, first_order_platform, first_order_month, channel, platform, url, campaign
  );

    
2018-07-30 12:04:50,512: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10583f358>]}
2018-07-30 12:04:52,602: 12:04:52 | 15 of 22 OK created table model template.monthly_cohort_stats........ [OK in 6.40s]
2018-07-30 12:04:58,096: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105853cc0>]}
2018-07-30 12:04:58,400: 12:04:58 | 16 of 22 OK created table model template.customers_proc_qoq.......... [OK in 13.98s]
2018-07-30 12:05:08,233: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058d4710>]}
2018-07-30 12:05:08,559: 12:05:08 | 17 of 22 OK created table model template.customers_proc_yoy.......... [OK in 24.10s]
2018-07-30 12:05:08,560: 12:05:08 | 18 of 22 START table model template.customers_proc................... [RUN]
2018-07-30 12:05:08,563: Compiling model.shopify_cohort_analysis.customers_proc
2018-07-30 12:05:08,594: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 12:05:08,602: Acquiring new bigquery connection "customers_proc".
2018-07-30 12:05:08,602: Re-using an available connection from the pool.
2018-07-30 12:05:08,772: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 12:05:08,773: Fetching data for query customers_proc:
create or replace table `template`.`customers_proc`
  
  as (
    SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_qoq`

UNION ALL

SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_yoy`
  );

    
2018-07-30 12:05:35,906: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105895e48>]}
2018-07-30 12:05:37,313: 12:05:37 | 18 of 22 OK created table model template.customers_proc.............. [OK in 27.34s]
2018-07-30 12:05:37,318: 12:05:37 | 19 of 22 START table model template.segment_proc_customers........... [RUN]
2018-07-30 12:05:37,318: Compiling model.shopify_cohort_analysis.segment_proc_customers
2018-07-30 12:05:37,351: Writing injected SQL for node "model.shopify_cohort_analysis.segment_proc_customers"
2018-07-30 12:05:37,360: Acquiring new bigquery connection "segment_proc_customers".
2018-07-30 12:05:37,360: Re-using an available connection from the pool.
2018-07-30 12:05:37,591: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_proc_customers"
2018-07-30 12:05:37,592: Fetching data for query segment_proc_customers:
create or replace table `template`.`segment_proc_customers`
  
  as (
    SELECT
store,
period,
customer_id,
date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct,
case when first_order_unix_date >= window_start_unix_date then 'New'
	else 'Existing' end as newness_segment,
case when revenue >= revenue_90pct then 'Whale'
	when revenue <= revenue_10pct then 'Minnow'
	else 'Bristlemouth' end as revenue_segment,
case when frequency = 1 then '1'
	when frequency = 2 then '2'
	when frequency > 2 then '3+'
	else null end as frequency_segment
FROM `growth-engines-pipeline`.`template`.`customers_proc`
  );

    
2018-07-30 12:06:09,937: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105867c88>]}
2018-07-30 12:06:10,271: 12:06:10 | 19 of 22 OK created table model template.segment_proc_customers...... [OK in 32.62s]
2018-07-30 12:06:10,272: 12:06:10 | 20 of 22 START table model template.segment_stats_customers_agg...... [RUN]
2018-07-30 12:06:10,273: Compiling model.shopify_cohort_analysis.segment_stats_customers_agg
2018-07-30 12:06:10,291: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_customers_agg"
2018-07-30 12:06:10,295: Acquiring new bigquery connection "segment_stats_customers_agg".
2018-07-30 12:06:10,295: Re-using an available connection from the pool.
2018-07-30 12:06:10,431: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_customers_agg"
2018-07-30 12:06:10,431: Fetching data for query segment_stats_customers_agg:
create or replace table `template`.`segment_stats_customers_agg`
  
  as (
    WITH ty as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Year'

),

this_month_1yr as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Previous Year'

),

this_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,	
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Quarter'

),

last_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev		
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Previous Quarter'

)

SELECT
store,
period,
date, 
customer_id,
1 as buyers,
first_order_channel,
first_order_platform,	
case when max(revenue_segment) != '' then max(revenue_segment) 
	when max(revenue_segment_prev) != '' then 'Dormant'
	else '' end as revenue_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(revenue_segment_prev) end as revenue_segment_prev,
case when max(frequency_segment) != '' then max(frequency_segment) 
	when max(frequency_segment_prev) != '' then 'Dormant'
	else '' end as frequency_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(frequency_segment_prev) end as frequency_segment_prev,
ifnull(sum(recency), 0) recency,
ifnull(sum(frequency), 0) frequency,
ifnull(sum(revenue), 0) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else 0 end as aov,
ifnull(sum(recency_prev), 0) recency_prev,
ifnull(sum(frequency_prev), 0) frequency_prev,
ifnull(sum(revenue_prev), 0) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else 0 end as aov_prev
FROM
(
	SELECT * FROM ty
	UNION ALL
	SELECT * FROM this_month_1yr
	UNION ALL
	SELECT * FROM this_quarter
	UNION ALL
	SELECT * FROM last_quarter

)
GROUP BY store, period, date, customer_id, first_order_channel, first_order_platform
  );

    
2018-07-30 12:06:57,135: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105895e48>]}
2018-07-30 12:06:58,082: 12:06:58 | 20 of 22 OK created table model template.segment_stats_customers_agg. [OK in 46.86s]
2018-07-30 12:06:58,087: 12:06:58 | 21 of 22 START table model template.buyer_segment_stats.............. [RUN]
2018-07-30 12:06:58,087: Compiling model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 12:06:58,124: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 12:06:58,132: Acquiring new bigquery connection "buyer_segment_stats".
2018-07-30 12:06:58,132: Re-using an available connection from the pool.
2018-07-30 12:06:58,672: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 12:06:58,673: Fetching data for query buyer_segment_stats:
create or replace table `template`.`buyer_segment_stats`
  
  as (
    SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type
  );

    
2018-07-30 12:07:04,275: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1083501d0>]}
2018-07-30 12:07:04,836: 12:07:04 | 21 of 22 OK created table model template.buyer_segment_stats......... [OK in 6.19s]
2018-07-30 12:07:04,837: 12:07:04 | 22 of 22 START table model template.buyer_segment_lists.............. [RUN]
2018-07-30 12:07:04,838: Compiling model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 12:07:04,861: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 12:07:04,864: Acquiring new bigquery connection "buyer_segment_lists".
2018-07-30 12:07:04,865: Re-using an available connection from the pool.
2018-07-30 12:07:05,478: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 12:07:05,479: Fetching data for query buyer_segment_lists:
create or replace table `template`.`buyer_segment_lists`
  
  as (
    SELECT
a.store,
period,
date,
customer_id,
b.first_name,
b.last_name,
b.email,
recency,
frequency,
revenue,
aov,
revenue_segment,
frequency_segment
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg` a
LEFT JOIN `growth-engines-pipeline`.`template`.`agg_customers` b
ON (
	a.store = b.store AND
	a.customer_id = b.id
)
where ( revenue_segment != '' or frequency_segment != '' )
  );

    
2018-07-30 12:07:39,618: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9529d450-5926-4a4f-8c21-10f69765eb71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105895e48>]}
2018-07-30 12:07:40,004: 12:07:40 | 22 of 22 OK created table model template.buyer_segment_lists......... [OK in 34.78s]
2018-07-30 12:07:40,098: 12:07:40 | 
2018-07-30 12:07:40,098: 12:07:40 | Finished running 22 table models in 258.55s.
2018-07-30 12:07:40,099: Connection 'master' was left open.
2018-07-30 12:07:40,099: 
2018-07-30 12:07:40,100: Completed successfully
2018-07-30 12:07:40,100: 
Done. PASS=22 ERROR=0 SKIP=0 TOTAL=22
2018-07-30 12:07:40,101: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10831c1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10831c780>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1083504e0>]}
2018-07-30 12:07:40,484: Flushing usage events
2018-07-30 12:07:41,066: sys:1: ResourceWarning: unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50221), raddr=('172.217.1.205', 443)>

2018-07-30 12:07:41,068: sys:1: ResourceWarning: unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50220), raddr=('172.217.1.202', 443)>

2018-07-30 12:07:41,068: sys:1: ResourceWarning: unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50218), raddr=('172.217.1.205', 443)>

2018-07-30 12:07:41,069: sys:1: ResourceWarning: unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50222), raddr=('172.217.1.205', 443)>

2018-07-30 12:07:41,077: sys:1: ResourceWarning: unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50226), raddr=('172.217.2.10', 443)>

2018-07-30 12:07:41,079: sys:1: ResourceWarning: unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50223), raddr=('172.217.1.205', 443)>

2018-07-30 12:07:41,079: sys:1: ResourceWarning: unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50224), raddr=('172.217.1.205', 443)>

2018-07-30 12:07:41,080: sys:1: ResourceWarning: unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50227), raddr=('172.217.2.10', 443)>

2018-07-30 12:07:41,080: sys:1: ResourceWarning: unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50225), raddr=('172.217.2.10', 443)>

2018-07-30 12:07:41,081: sys:1: ResourceWarning: unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50228), raddr=('172.217.2.10', 443)>

2018-07-30 12:28:00,115: Tracking: tracking
2018-07-30 12:28:00,117: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108524e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108524278>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108524ef0>]}
2018-07-30 12:28:01,092: Loading dependency project from /usr/local/Cellar/dbt/0.10.1/libexec/lib/python3.6/site-packages/dbt/include
2018-07-30 12:28:01,120: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/shopify-cohort-analysis/dbt_modules
2018-07-30 12:28:01,127: Parsing get_column_values.sql
2018-07-30 12:28:01,148: Parsing get_url_parameter.sql
2018-07-30 12:28:01,154: Parsing split_part.sql
2018-07-30 12:28:01,162: Parsing table_exists.sql
2018-07-30 12:28:01,174: Parsing core.sql
2018-07-30 12:28:01,189: Parsing adapters/bigquery.sql
2018-07-30 12:28:01,198: Parsing adapters/common.sql
2018-07-30 12:28:01,225: Parsing adapters/redshift.sql
2018-07-30 12:28:01,246: Parsing adapters/snowflake.sql
2018-07-30 12:28:01,252: Parsing etc/bigquery.sql
2018-07-30 12:28:01,257: Parsing etc/datetime.sql
2018-07-30 12:28:01,286: Parsing etc/get_custom_schema.sql
2018-07-30 12:28:01,294: Parsing materializations/helpers.sql
2018-07-30 12:28:01,316: Parsing materializations/archive/archive.sql
2018-07-30 12:28:01,364: Parsing materializations/incremental/incremental.sql
2018-07-30 12:28:01,400: Parsing materializations/seed/bigquery.sql
2018-07-30 12:28:01,408: Parsing materializations/seed/seed.sql
2018-07-30 12:28:01,466: Parsing materializations/table/bigquery_table.sql
2018-07-30 12:28:01,509: Parsing materializations/table/table.sql
2018-07-30 12:28:01,543: Parsing materializations/view/bigquery_view.sql
2018-07-30 12:28:01,565: Parsing materializations/view/view.sql
2018-07-30 12:28:01,591: Parsing schema_tests/accepted_values.sql
2018-07-30 12:28:01,599: Parsing schema_tests/not_null.sql
2018-07-30 12:28:01,603: Parsing schema_tests/relationships.sql
2018-07-30 12:28:01,608: Parsing schema_tests/unique.sql
2018-07-30 12:28:01,635: Parsing model.shopify_cohort_analysis.all_dates
2018-07-30 12:28:01,637: Parsing model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 12:28:01,640: Parsing model.shopify_cohort_analysis.monthend_dates
2018-07-30 12:28:01,642: Parsing model.shopify_cohort_analysis.stores_proc
2018-07-30 12:28:01,645: Parsing model.shopify_cohort_analysis.ga_transactions
2018-07-30 12:28:01,655: Parsing model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 12:28:01,663: Parsing model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 12:28:01,669: Parsing model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 12:28:01,680: Parsing model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 12:28:01,689: Parsing model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 12:28:01,696: Parsing model.shopify_cohort_analysis.agg_customers
2018-07-30 12:28:01,700: Parsing model.shopify_cohort_analysis.agg_transactions
2018-07-30 12:28:01,705: Parsing model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 12:28:01,711: Parsing model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 12:28:01,716: Parsing model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 12:28:01,720: Parsing model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 12:28:01,731: Parsing model.shopify_cohort_analysis.customers_proc
2018-07-30 12:28:01,735: Parsing model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 12:28:01,740: Parsing model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 12:28:01,747: Parsing model.shopify_cohort_analysis.segment_proc_customers
2018-07-30 12:28:01,750: Parsing model.shopify_cohort_analysis.segment_stats_customers_agg
2018-07-30 12:28:01,756: Parsing model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 12:28:01,779: Found 22 models, 0 tests, 0 archives, 0 analyses, 62 macros, 0 operations, 0 seed files
2018-07-30 12:28:01,788: 
2018-07-30 12:28:01,800: Acquiring new bigquery connection "master".
2018-07-30 12:28:01,800: Opening a new connection (0 currently allocated)
2018-07-30 12:28:03,250: 12:28:03 | Concurrency: 4 threads (target='template')
2018-07-30 12:28:03,250: 12:28:03 | 
2018-07-30 12:28:03,387: 12:28:03 | 1 of 22 START table model template.mappings_ga_proc.................. [RUN]
2018-07-30 12:28:03,388: Compiling model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 12:28:03,388: 12:28:03 | 2 of 22 START table model template.stores_proc....................... [RUN]
2018-07-30 12:28:03,395: Compiling model.shopify_cohort_analysis.stores_proc
2018-07-30 12:28:03,400: Writing injected SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 12:28:03,388: 12:28:03 | 3 of 22 START table model template.all_dates......................... [RUN]
2018-07-30 12:28:03,410: Writing injected SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 12:28:03,388: 12:28:03 | 4 of 22 START table model template.monthend_dates.................... [RUN]
2018-07-30 12:28:03,411: Compiling model.shopify_cohort_analysis.monthend_dates
2018-07-30 12:28:03,411: Compiling model.shopify_cohort_analysis.all_dates
2018-07-30 12:28:03,420: Writing injected SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 12:28:03,429: Acquiring new bigquery connection "stores_proc".
2018-07-30 12:28:03,432: Writing injected SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 12:28:03,435: Acquiring new bigquery connection "all_dates".
2018-07-30 12:28:03,437: Acquiring new bigquery connection "mappings_ga_proc".
2018-07-30 12:28:03,439: Acquiring new bigquery connection "monthend_dates".
2018-07-30 12:28:03,439: Opening a new connection (1 currently allocated)
2018-07-30 12:28:03,441: Opening a new connection (2 currently allocated)
2018-07-30 12:28:03,450: Opening a new connection (3 currently allocated)
2018-07-30 12:28:03,453: Opening a new connection (4 currently allocated)
2018-07-30 12:28:03,963: Writing runtime SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 12:28:03,964: Fetching data for query stores_proc:
create or replace table `template`.`stores_proc`
  
  as (
    select 
store,
store_name,
account,
platform,
max(time_of_entry) time_of_entry

from  ( 

SELECT  
client store,
client_name store_name,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.accounts` 
where client_name != ''

) 

WHERE lv = time_of_entry
group by store, store_name, account, platform
  );

    
2018-07-30 12:28:04,014: Writing runtime SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 12:28:04,015: Fetching data for query all_dates:
create or replace table `template`.`all_dates`
  
  as (
    SELECT 
date_in_range,
unix_date(date_in_range) unix_date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
  );

    
2018-07-30 12:28:04,263: Writing runtime SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 12:28:04,264: Fetching data for query mappings_ga_proc:
create or replace table `template`.`mappings_ga_proc`
  
  as (
    select 
store,
account,
store_name,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client store,
account,
client_name store_name,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.mappings_ga` 

) 

WHERE lv = time_of_entry
group by store, account, store_name, source, medium, platform_n, channel_n, time_of_entry
  );

    
2018-07-30 12:28:04,301: Writing runtime SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 12:28:04,302: Fetching data for query monthend_dates:
create or replace table `template`.`monthend_dates`
  
  as (
    SELECT
date_in_range,
date_in_range_bom,
date_in_range_bom_mom,
unix_date_in_range,
unix_date_in_range_bom,
unix_date(date_in_range_bom_mom) unix_date_in_range_bom_mom,
yyyymm,
date_in_range_yoy,
unix_date(date_in_range_yoy) unix_date_in_range_yoy

FROM
(
	SELECT 
	date_in_range,
	date_in_range_bom,
	date_sub(date_in_range_bom, INTERVAL 1 MONTH) date_in_range_bom_mom,
	date_sub(date_in_range, INTERVAL 1 YEAR) date_in_range_yoy,
	unix_date_in_range,
	unix_date(date_in_range_bom) unix_date_in_range_bom,
	yyyymm,
	first_value(date_in_range) over (partition by yyyymm order by date_in_range desc) monthend_date_in_range
	FROM
	( 
		SELECT 
		date_in_range,
		date_trunc( date_in_range, MONTH) date_in_range_bom,
		unix_date(date_in_range) unix_date_in_range,
		format_date("%Y-%m", date_in_range) AS yyyymm
		FROM UNNEST(
		    GENERATE_DATE_ARRAY(DATE('2016-01-31'), CURRENT_DATE(), INTERVAL 1 DAY)
		) AS date_in_range
	)
)
where date_in_range = monthend_date_in_range
  );

    
2018-07-30 12:28:06,520: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088067b8>]}
2018-07-30 12:28:06,808: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10873c438>]}
2018-07-30 12:28:06,986: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10873c470>]}
2018-07-30 12:28:07,294: 12:28:07 | 1 of 22 OK created table model template.mappings_ga_proc............. [OK in 3.13s]
2018-07-30 12:28:07,853: 12:28:07 | 2 of 22 OK created table model template.stores_proc.................. [OK in 3.41s]
2018-07-30 12:28:08,045: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108626710>]}
2018-07-30 12:28:08,168: 12:28:08 | 4 of 22 OK created table model template.monthend_dates............... [OK in 3.57s]
2018-07-30 12:28:08,690: 12:28:08 | 3 of 22 OK created table model template.all_dates.................... [OK in 4.63s]
2018-07-30 12:28:08,691: 12:28:08 | 5 of 22 START table model template.shopify_refunds_proc.............. [RUN]
2018-07-30 12:28:08,691: Compiling model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 12:28:08,695: 12:28:08 | 6 of 22 START table model template.shopify_customers_proc............ [RUN]
2018-07-30 12:28:08,696: Compiling model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 12:28:08,696: 12:28:08 | 7 of 22 START table model template.shopify_discounts_proc............ [RUN]
2018-07-30 12:28:08,707: Compiling model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 12:28:08,717: Acquiring new bigquery connection "shopify_refunds_proc".
2018-07-30 12:28:08,729: Acquiring new bigquery connection "shopify_customers_proc".
2018-07-30 12:28:08,738: Acquiring new bigquery connection "shopify_discounts_proc".
2018-07-30 12:28:08,738: Re-using an available connection from the pool.
2018-07-30 12:28:08,738: Fetching data for query shopify_refunds_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:28:08,741: Re-using an available connection from the pool.
2018-07-30 12:28:08,741: Fetching data for query shopify_customers_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:28:08,742: Re-using an available connection from the pool.
2018-07-30 12:28:08,747: Fetching data for query shopify_discounts_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:28:10,256: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 12:28:10,281: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 12:28:10,429: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 12:28:10,431: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 12:28:10,432: Fetching data for query shopify_customers_proc:
create or replace table `template`.`shopify_customers_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`





with customers as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	created_at,
	id,
	first_name,
	last_name,
	email,
	_sdc_sequence,
	first_value(_sdc_sequence) over (partition by id order by _sdc_sequence desc) lv
	FROM `growth-engines-pipeline.shopify_lucadanni.customers` 
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
id,
first_name,
last_name,
email
FROM customers a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence


  );

    
2018-07-30 12:28:10,432: Fetching data for query shopify_refunds_proc:
create or replace table `template`.`shopify_refunds_proc`
  
  as (
    



with refunds as (

	
	SELECT
	'lucadanni' store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal,
	line_item.variant_id variant_id,
	line_item.id refund_id,
 	_sdc_sequence
	FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
	cross join unnest(refunds), unnest(refund_line_items)
  	where financial_status like '%refund%'
	
	

)

SELECT * 
FROM 
	(
    SELECT
    store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal refund_amount,
	variant_id,
	refund_id,
 	_sdc_sequence,
    first_value(_sdc_sequence) OVER (PARTITION BY order_number, line_item_id ORDER BY _sdc_sequence DESC) lv
    FROM refunds
   	) 
WHERE lv = _sdc_sequence


  );

    
2018-07-30 12:28:10,794: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 12:28:10,957: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 12:28:10,958: Fetching data for query shopify_discounts_proc:
create or replace table `template`.`shopify_discounts_proc`
  
  as (
    



with orders as (

	
		SELECT
		'lucadanni' store_name,
		created_at,
		order_number,
		code discount_code,
		type discount_type,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(discount_codes)
		where source_name != 'shopify_draft_order'
	
	
	

)

SELECT
store_name,
order_number,
discount_code,
discount_type
FROM orders
where lv = _sdc_sequence


  );

    
2018-07-30 12:28:12,569: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108746748>]}
2018-07-30 12:28:12,824: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108813e10>]}
2018-07-30 12:28:12,872: 12:28:12 | 5 of 22 OK created table model template.shopify_refunds_proc......... [OK in 3.88s]
2018-07-30 12:28:13,198: 12:28:13 | 7 of 22 OK created table model template.shopify_discounts_proc....... [OK in 4.12s]
2018-07-30 12:28:14,859: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108787ba8>]}
2018-07-30 12:28:17,122: 12:28:17 | 6 of 22 OK created table model template.shopify_customers_proc....... [OK in 6.16s]
2018-07-30 12:28:17,125: 12:28:17 | 8 of 22 START table model template.ga_transactions................... [RUN]
2018-07-30 12:28:17,126: 12:28:17 | 9 of 22 START table model template.shopify_products_proc............. [RUN]
2018-07-30 12:28:17,126: Compiling model.shopify_cohort_analysis.ga_transactions
2018-07-30 12:28:17,126: 12:28:17 | 10 of 22 START table model template.agg_customers.................... [RUN]
2018-07-30 12:28:17,126: Compiling model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 12:28:17,138: Compiling model.shopify_cohort_analysis.agg_customers
2018-07-30 12:28:17,146: Acquiring new bigquery connection "ga_transactions".
2018-07-30 12:28:17,161: Writing injected SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 12:28:17,168: Re-using an available connection from the pool.
2018-07-30 12:28:17,186: Acquiring new bigquery connection "shopify_products_proc".
2018-07-30 12:28:17,186: Fetching data for query ga_transactions:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Google Analytics'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:28:17,187: Re-using an available connection from the pool.
2018-07-30 12:28:17,188: Fetching data for query shopify_products_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:28:17,190: Acquiring new bigquery connection "agg_customers".
2018-07-30 12:28:17,190: Re-using an available connection from the pool.
2018-07-30 12:28:17,478: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 12:28:17,480: Fetching data for query agg_customers:
create or replace table `template`.`agg_customers`
  
  as (
    SELECT 
account,
store,
id,
created_at,
first_name,
last_name,
email,
split(email,'@')[SAFE_ORDINAL(2)] email_domain
FROM
`growth-engines-pipeline`.`template`.`shopify_customers_proc`
  );

    
2018-07-30 12:28:18,217: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 12:28:18,379: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 12:28:18,380: Fetching data for query shopify_products_proc:
create or replace table `template`.`shopify_products_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`





with products as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	product_name,
	lower(product_type) product_type,
	product_id,
	sku,
	id variant_id,
	cast(created_at as date) created_at,
	_sdc_sequence,
	first_value(_sdc_sequence) OVER (PARTITION BY product_id ORDER BY _sdc_sequence DESC) lv
	FROM (
		SELECT
		variants,
		product_type,
		title product_name,
		_sdc_sequence
		FROM `growth-engines-pipeline.shopify_lucadanni.products` 
		)
	cross join unnest(variants)
	
	

)

SELECT
b.account,
b.store,
b.platform,
max(product_type) product_type,
product_id,
variant_id,
sku,
created_at,
product_name
FROM products a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence
group by product_id, account, store, platform, sku, variant_id, created_at, product_name


  );

    
2018-07-30 12:28:18,745: Writing injected SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 12:28:18,950: Writing runtime SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 12:28:18,950: Fetching data for query ga_transactions:
create or replace table `template`.`ga_transactions`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`,`growth-engines-pipeline`.`template`.`mappings_ga_proc`




with ga_report as (

	    
	    	
		   	SELECT
		   	'yandy' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_yandy.report` 

		     UNION ALL 
	   
	    	
		   	SELECT
		   	'lucadanni' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_lucadanni.report` 

		    
	   

)


SELECT  
date,
b.store store,
c.source source,
c.medium medium,
a.campaign campaign,
concat(a.source, ' / ', a.medium) source_medium,  
case when c.platform is null then "Unmapped" else c.platform end as platform,
case when c.channel is null then "Unmapped" else c.channel end as channel,
url,
transactionid
FROM (

	SELECT 
	store_name,
	lookup_platform,
	date,
	transactionid,
	max(url) url,
	max(source) source,
	max(medium) medium,
	max(campaign) campaign
	FROM ga_report
	where lv = _sdc_sequence
	group by store_name, lookup_platform, date, transactionid

) a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name 
	AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`mappings_ga_proc` c
ON ( a.source = c.source
  AND a.medium = c.medium 
  AND a.store_name = c.store_name )


  );

    
2018-07-30 12:28:20,482: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087ed390>]}
2018-07-30 12:28:20,793: 12:28:20 | 9 of 22 OK created table model template.shopify_products_proc........ [OK in 3.36s]
2018-07-30 12:28:22,003: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088061d0>]}
2018-07-30 12:28:22,307: 12:28:22 | 10 of 22 OK created table model template.agg_customers............... [OK in 4.86s]
2018-07-30 12:28:40,828: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108626710>]}
2018-07-30 12:28:41,165: 12:28:41 | 8 of 22 OK created table model template.ga_transactions.............. [OK in 23.70s]
2018-07-30 12:28:41,166: 12:28:41 | 11 of 22 START table model template.shopify_orders_proc.............. [RUN]
2018-07-30 12:28:41,166: Compiling model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 12:28:41,194: Acquiring new bigquery connection "shopify_orders_proc".
2018-07-30 12:28:41,194: Re-using an available connection from the pool.
2018-07-30 12:28:41,195: Fetching data for query shopify_orders_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:28:41,828: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 12:28:41,964: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 12:28:41,965: Fetching data for query shopify_orders_proc:
create or replace table `template`.`shopify_orders_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`, `growth-engines-pipeline`.`template`.`shopify_discounts_proc`





with orders as (

	
	SELECT 
	store_name,
	lookup_platform,
	created_at,
	order_number,
	quantity,
	price, 
	total_order_price_undiscounted,
	total_discounts,
	total_order_shipping_price,
	total_order_price_incl_shipping,
	checkout_id,
	product_id, 
	landing_site,
	sku, 
	variant_title, 
	variant_id,
	line_item_id,
	customer_id,
	_sdc_sequence,
	lv
	FROM (

		SELECT
		'lucadanni' store_name,
		'Shopify' as lookup_platform,
		created_at,
		order_number,
		quantity,
		cast(pre_tax_price as float64) price, 
		total_line_items_price total_order_price_undiscounted,
		total_discounts,
		cast(discounted_price as float64) total_order_shipping_price,
		total_price_usd total_order_price_incl_shipping,
		checkout_id,
		product_id, 
		landing_site,
		sku, 
		variant_title, 
		variant_id,
		_id line_item_id,
		customer.id customer_id,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(line_items), unnest(shipping_lines)
		where source_name != 'shopify_draft_order'
	)
	
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
a.order_number,
a.quantity prelim_quantity,
c.quantity refund_quantity,
case when c.quantity is not null then a.quantity - c.quantity else a.quantity end as quantity,
price prelim_revenue, 
total_order_price_undiscounted,
total_discounts,
trim(lower(d.discount_code)) discount_code,
d.discount_type,
total_order_shipping_price,
total_order_price_incl_shipping,
refund_amount,
case when refund_amount is not null then price - refund_amount else price end as revenue,
a.checkout_id,
a.product_id, 
landing_site,
sku, 
variant_title, 
a.variant_id,
a.line_item_id,	
customer_id
FROM orders a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_refunds_proc` c
ON ( a.order_number = c.order_number
	AND a.line_item_id = c.line_item_id
	AND a.store_name = c.store_name )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_discounts_proc` d
ON ( a.order_number = d.order_number 
    AND a.store_name = d.store_name )  	
where a.lv = a._sdc_sequence


  );

    
2018-07-30 12:28:52,436: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108787ba8>]}
2018-07-30 12:28:53,079: 12:28:53 | 11 of 22 OK created table model template.shopify_orders_proc......... [OK in 11.27s]
2018-07-30 12:28:53,081: 12:28:53 | 12 of 22 START table model template.transaction_by_order_number...... [RUN]
2018-07-30 12:28:53,081: Compiling model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 12:28:53,093: Writing injected SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 12:28:53,096: Acquiring new bigquery connection "transaction_by_order_number".
2018-07-30 12:28:53,096: Re-using an available connection from the pool.
2018-07-30 12:28:53,747: Writing runtime SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 12:28:53,750: Fetching data for query transaction_by_order_number:
create or replace table `template`.`transaction_by_order_number`
  
  as (
    SELECT
store,
cast(created_at as date) order_date,
order_number,
customer_id,
sum(quantity) quantity,
sum(revenue) revenue,
max(total_order_shipping_price) shipping_price
FROM
`growth-engines-pipeline`.`template`.`shopify_orders_proc`
GROUP BY store, order_date, order_number, customer_id
  );

    
2018-07-30 12:28:58,747: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108626710>]}
2018-07-30 12:28:59,079: 12:28:59 | 12 of 22 OK created table model template.transaction_by_order_number. [OK in 5.67s]
2018-07-30 12:28:59,080: 12:28:59 | 13 of 22 START table model template.customers_by_transaction......... [RUN]
2018-07-30 12:28:59,080: Compiling model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 12:28:59,090: Writing injected SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 12:28:59,091: Acquiring new bigquery connection "customers_by_transaction".
2018-07-30 12:28:59,092: Re-using an available connection from the pool.
2018-07-30 12:28:59,592: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 12:28:59,593: Fetching data for query customers_by_transaction:
create or replace table `template`.`customers_by_transaction`
  
  as (
    SELECT
store,
customer_id,
order_number,
order_date,
recent_order_date,
first_order_date,
case when first_order_number = order_number then 'New'
	when date_diff(order_date, recent_order_date, DAY) <= 365 then 'Repeat'
	when date_diff(order_date, recent_order_date, DAY) > 365 then 'Reactivated'
 else '' end as order_type,
quantity,
revenue,
1 as orders,
first_order_revenue,
lifetime_revenue
FROM

(

	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	quantity,
	revenue,
	lag(order_date) over w1 recent_order_date,
	first_value(order_date) over w1 first_order_date,
	first_value(order_number) over w1 first_order_number,
	first_value(revenue) over w1 first_order_revenue,
	sum(revenue) over w2 lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`transaction_by_order_number`
	WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc),
	w2 as (PARTITION BY store, customer_id)
)
  );

    
2018-07-30 12:29:03,609: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108787ba8>]}
2018-07-30 12:29:05,282: 12:29:05 | 13 of 22 OK created table model template.customers_by_transaction.... [OK in 4.53s]
2018-07-30 12:29:05,286: 12:29:05 | 14 of 22 START table model template.agg_transactions................. [RUN]
2018-07-30 12:29:05,286: Compiling model.shopify_cohort_analysis.agg_transactions
2018-07-30 12:29:05,308: Writing injected SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 12:29:05,310: Acquiring new bigquery connection "agg_transactions".
2018-07-30 12:29:05,311: Re-using an available connection from the pool.
2018-07-30 12:29:05,471: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 12:29:05,472: Fetching data for query agg_transactions:
create or replace table `template`.`agg_transactions`
  
  as (
    with ga_transaction as (

	SELECT
	date, 
	store,
	transactionid,
	channel,
	platform,
	url,
	campaign
	FROM `growth-engines-pipeline`.`template`.`ga_transactions`
),

customers_by_transaction as (
	
	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	first_order_date,
	recent_order_date,
	order_type,
	quantity,
	revenue,
	orders,
	first_order_revenue,
	lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`customers_by_transaction`
)

SELECT
store,
customer_id,
order_number,
transactionid,
order_date,
first_order_date,
format_date("%Y-%m", first_order_date) AS first_order_month,
order_type,
first_order_revenue,
lifetime_revenue,
first_value(channel) over w1 as first_order_channel,
first_value(platform) over w1 as first_order_platform,
channel,
platform,
url,
campaign,
quantity,
revenue,
orders
FROM (

	SELECT
	a.store,
	a.customer_id,
	a.order_number,
	b.transactionid,
	a.order_date, 
	a.first_order_date, 
	a.order_type,
	a.first_order_revenue,
	a.lifetime_revenue,
	b.channel,
	b.platform,
	b.url,
	b.campaign,
	a.quantity,
	a.revenue,
	a.orders
	FROM customers_by_transaction a
	LEFT JOIN ga_transaction b
	ON (
	    a.store = b.store AND
	    a.order_number = b.transactionid
	)	
)
WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc)
  );

    
2018-07-30 12:29:13,797: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108626710>]}
2018-07-30 12:29:14,748: 12:29:14 | 14 of 22 OK created table model template.agg_transactions............ [OK in 8.51s]
2018-07-30 12:29:14,749: 12:29:14 | 15 of 22 START table model template.monthly_cohort_stats............. [RUN]
2018-07-30 12:29:14,750: Compiling model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 12:29:14,764: Writing injected SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 12:29:14,755: 12:29:14 | 16 of 22 START table model template.customers_proc_qoq............... [RUN]
2018-07-30 12:29:14,756: 12:29:14 | 17 of 22 START table model template.customers_proc_yoy............... [RUN]
2018-07-30 12:29:14,765: Compiling model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 12:29:14,765: Compiling model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 12:29:14,790: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 12:29:14,798: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 12:29:14,802: Acquiring new bigquery connection "monthly_cohort_stats".
2018-07-30 12:29:14,804: Acquiring new bigquery connection "customers_proc_yoy".
2018-07-30 12:29:14,807: Acquiring new bigquery connection "customers_proc_qoq".
2018-07-30 12:29:14,807: Re-using an available connection from the pool.
2018-07-30 12:29:14,808: Re-using an available connection from the pool.
2018-07-30 12:29:14,812: Re-using an available connection from the pool.
2018-07-30 12:29:15,030: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 12:29:15,083: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 12:29:15,085: Fetching data for query customers_proc_qoq:
create or replace table `template`.`customers_proc_qoq`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 90 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 90 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 90 window_end_unix_date, 
    unix_date_in_range - 180 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 180 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 90 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 12:29:15,090: Writing runtime SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 12:29:15,095: Fetching data for query monthly_cohort_stats:
create or replace table `template`.`monthly_cohort_stats`
  
  as (
    WITH transactions AS (

  SELECT 
  store, 
  order_number,
  order_date,
  order_type,
  first_order_month,
  unix_date(order_date) d, 
  customer_id, 
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (

  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT 
date_in_range date,
store, 
order_type,
first_order_channel,
first_order_platform,
first_order_month,
channel,
platform,
url,
campaign,
count(distinct(customer_id)) buyers,
sum(orders) orders,
sum(quantity) quantity,
sum(revenue) revenue
FROM daterange
JOIN transactions
ON transactions.d >= daterange.unix_date_in_range_bom 
AND transactions.d <= daterange.unix_date_in_range
GROUP BY date, store, order_type, 
first_order_channel, first_order_platform, first_order_month, channel, platform, url, campaign
  );

    
2018-07-30 12:29:15,103: Fetching data for query customers_proc_yoy:
create or replace table `template`.`customers_proc_yoy`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 365 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 365 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 365 window_end_unix_date, 
    unix_date_in_range - 730 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 730 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 365 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 12:29:20,032: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10873c898>]}
2018-07-30 12:29:20,330: 12:29:20 | 15 of 22 OK created table model template.monthly_cohort_stats........ [OK in 5.28s]
2018-07-30 12:29:27,400: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087b3cf8>]}
2018-07-30 12:29:27,739: 12:29:27 | 16 of 22 OK created table model template.customers_proc_qoq.......... [OK in 12.63s]
2018-07-30 12:29:35,097: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087b3550>]}
2018-07-30 12:29:35,444: 12:29:35 | 17 of 22 OK created table model template.customers_proc_yoy.......... [OK in 20.33s]
2018-07-30 12:29:35,445: 12:29:35 | 18 of 22 START table model template.customers_proc................... [RUN]
2018-07-30 12:29:35,445: Compiling model.shopify_cohort_analysis.customers_proc
2018-07-30 12:29:35,457: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 12:29:35,458: Acquiring new bigquery connection "customers_proc".
2018-07-30 12:29:35,459: Re-using an available connection from the pool.
2018-07-30 12:29:35,627: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 12:29:35,627: Fetching data for query customers_proc:
create or replace table `template`.`customers_proc`
  
  as (
    SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_qoq`

UNION ALL

SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_yoy`
  );

    
2018-07-30 12:30:01,810: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108626710>]}
2018-07-30 12:30:02,463: 12:30:02 | 18 of 22 OK created table model template.customers_proc.............. [OK in 26.36s]
2018-07-30 12:30:02,464: 12:30:02 | 19 of 22 START table model template.segment_proc_customers........... [RUN]
2018-07-30 12:30:02,465: Compiling model.shopify_cohort_analysis.segment_proc_customers
2018-07-30 12:30:02,478: Writing injected SQL for node "model.shopify_cohort_analysis.segment_proc_customers"
2018-07-30 12:30:02,482: Acquiring new bigquery connection "segment_proc_customers".
2018-07-30 12:30:02,482: Re-using an available connection from the pool.
2018-07-30 12:30:02,733: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_proc_customers"
2018-07-30 12:30:02,736: Fetching data for query segment_proc_customers:
create or replace table `template`.`segment_proc_customers`
  
  as (
    SELECT
store,
period,
customer_id,
date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct,
case when first_order_unix_date >= window_start_unix_date then 'New'
	else 'Existing' end as newness_segment,
case when revenue >= revenue_90pct then 'Whale'
	when revenue <= revenue_10pct then 'Minnow'
	else 'Bristlemouth' end as revenue_segment,
case when frequency = 1 then '1'
	when frequency = 2 then '2'
	when frequency > 2 then '3+'
	else null end as frequency_segment
FROM `growth-engines-pipeline`.`template`.`customers_proc`
  );

    
2018-07-30 12:30:32,230: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108715048>]}
2018-07-30 12:30:33,032: 12:30:33 | 19 of 22 OK created table model template.segment_proc_customers...... [OK in 29.77s]
2018-07-30 12:30:33,032: 12:30:33 | 20 of 22 START table model template.segment_stats_customers_agg...... [RUN]
2018-07-30 12:30:33,033: Compiling model.shopify_cohort_analysis.segment_stats_customers_agg
2018-07-30 12:30:33,045: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_customers_agg"
2018-07-30 12:30:33,047: Acquiring new bigquery connection "segment_stats_customers_agg".
2018-07-30 12:30:33,047: Re-using an available connection from the pool.
2018-07-30 12:30:33,176: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_customers_agg"
2018-07-30 12:30:33,177: Fetching data for query segment_stats_customers_agg:
create or replace table `template`.`segment_stats_customers_agg`
  
  as (
    WITH ty as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Year'

),

this_month_1yr as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Previous Year'

),

this_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,	
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Quarter'

),

last_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev		
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Previous Quarter'

)

SELECT
store,
period,
date, 
customer_id,
1 as buyers,
first_order_channel,
first_order_platform,	
case when max(revenue_segment) != '' then max(revenue_segment) 
	when max(revenue_segment_prev) != '' then 'Dormant'
	else '' end as revenue_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(revenue_segment_prev) end as revenue_segment_prev,
case when max(frequency_segment) != '' then max(frequency_segment) 
	when max(frequency_segment_prev) != '' then 'Dormant'
	else '' end as frequency_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(frequency_segment_prev) end as frequency_segment_prev,
ifnull(sum(recency), 0) recency,
ifnull(sum(frequency), 0) frequency,
ifnull(sum(revenue), 0) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else 0 end as aov,
ifnull(sum(recency_prev), 0) recency_prev,
ifnull(sum(frequency_prev), 0) frequency_prev,
ifnull(sum(revenue_prev), 0) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else 0 end as aov_prev
FROM
(
	SELECT * FROM ty
	UNION ALL
	SELECT * FROM this_month_1yr
	UNION ALL
	SELECT * FROM this_quarter
	UNION ALL
	SELECT * FROM last_quarter

)
GROUP BY store, period, date, customer_id, first_order_channel, first_order_platform
  );

    
2018-07-30 12:31:05,532: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108626710>]}
2018-07-30 12:31:06,220: 12:31:06 | 20 of 22 OK created table model template.segment_stats_customers_agg. [OK in 32.50s]
2018-07-30 12:31:06,221: 12:31:06 | 21 of 22 START table model template.buyer_segment_stats.............. [RUN]
2018-07-30 12:31:06,222: Compiling model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 12:31:06,235: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 12:31:06,239: Acquiring new bigquery connection "buyer_segment_stats".
2018-07-30 12:31:06,239: Re-using an available connection from the pool.
2018-07-30 12:31:06,425: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 12:31:06,433: Fetching data for query buyer_segment_stats:
create or replace table `template`.`buyer_segment_stats`
  
  as (
    SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
sum(retention_eligible) retention_eligible,
sum(retention_success) retention_success
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
sum(retention_eligible) retention_eligible,
sum(retention_success) retention_success
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
sum(retention_eligible) retention_eligible,
sum(retention_success) retention_success
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
sum(retention_eligible) retention_eligible,
sum(retention_success) retention_success
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
sum(retention_eligible) retention_eligible,
sum(retention_success) retention_success
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
sum(retention_eligible) retention_eligible,
sum(retention_success) retention_success
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type
  );

    
2018-07-30 12:31:07,657: Bad request while running:
create dataset
2018-07-30 12:31:07,658: 400 GET https://www.googleapis.com/bigquery/v2/projects/growth-engines-pipeline/queries/cd2bed1b-2ddc-47c8-b7f7-008b0039e960?maxResults=0: Unrecognized name: retention_eligible at [22:5]
2018-07-30 12:31:07,658: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10870d1d0>]}
2018-07-30 12:31:08,526: 12:31:08 | 21 of 22 ERROR creating table model template.buyer_segment_stats..... [ERROR in 1.44s]
2018-07-30 12:31:08,527: 12:31:08 | 22 of 22 START table model template.buyer_segment_lists.............. [RUN]
2018-07-30 12:31:08,528: Compiling model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 12:31:08,540: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 12:31:08,550: Acquiring new bigquery connection "buyer_segment_lists".
2018-07-30 12:31:08,550: Re-using an available connection from the pool.
2018-07-30 12:31:09,084: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 12:31:09,085: Fetching data for query buyer_segment_lists:
create or replace table `template`.`buyer_segment_lists`
  
  as (
    SELECT
a.store,
period,
date,
customer_id,
b.first_name,
b.last_name,
b.email,
recency,
frequency,
revenue,
aov,
revenue_segment,
frequency_segment
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg` a
LEFT JOIN `growth-engines-pipeline`.`template`.`agg_customers` b
ON (
	a.store = b.store AND
	a.customer_id = b.id
)
where ( revenue_segment != '' or frequency_segment != '' )
  );

    
2018-07-30 12:31:44,059: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29e22fa9-0078-44c8-b58e-3530359b7c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108626710>]}
2018-07-30 12:31:46,305: 12:31:46 | 22 of 22 OK created table model template.buyer_segment_lists......... [OK in 35.53s]
2018-07-30 12:31:46,362: 12:31:46 | 
2018-07-30 12:31:46,362: 12:31:46 | Finished running 22 table models in 224.57s.
2018-07-30 12:31:46,362: Connection 'master' was left open.
2018-07-30 12:31:46,363: 
2018-07-30 12:31:46,364: Completed with 1 errors:
2018-07-30 12:31:46,364: 
2018-07-30 12:31:46,364: Database Error in model buyer_segment_stats (models/math/buyer-segmentation/buyer_segment_stats.sql)
2018-07-30 12:31:46,364:   Unrecognized name: retention_eligible at [22:5]
2018-07-30 12:31:46,365:   compiled SQL at target/run/shopify_cohort_analysis/math/buyer-segmentation/buyer_segment_stats.sql
2018-07-30 12:31:46,365: 
Done. PASS=21 ERROR=1 SKIP=0 TOTAL=22
2018-07-30 12:31:46,367: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085f1080>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085f11d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085f1780>]}
2018-07-30 12:31:46,671: Flushing usage events
2018-07-30 12:31:47,236: sys:1: ResourceWarning: unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50428), raddr=('172.217.11.237', 443)>

2018-07-30 12:31:47,237: sys:1: ResourceWarning: unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50426), raddr=('172.217.3.10', 443)>

2018-07-30 12:31:47,238: sys:1: ResourceWarning: unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50411), raddr=('172.217.11.237', 443)>

2018-07-30 12:31:47,238: sys:1: ResourceWarning: unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50429), raddr=('172.217.11.237', 443)>

2018-07-30 12:31:47,239: sys:1: ResourceWarning: unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50434), raddr=('172.217.3.10', 443)>

2018-07-30 12:31:47,239: sys:1: ResourceWarning: unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50439), raddr=('172.217.3.10', 443)>

2018-07-30 12:31:47,240: sys:1: ResourceWarning: unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50430), raddr=('172.217.11.237', 443)>

2018-07-30 12:31:47,240: sys:1: ResourceWarning: unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50431), raddr=('172.217.11.237', 443)>

2018-07-30 12:31:47,241: sys:1: ResourceWarning: unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50435), raddr=('172.217.3.10', 443)>

2018-07-30 12:31:47,241: sys:1: ResourceWarning: unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 50440), raddr=('172.217.3.10', 443)>

2018-07-30 12:34:45,741: Tracking: tracking
2018-07-30 12:34:45,744: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b04add8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b04afd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b04ae48>]}
2018-07-30 12:34:47,254: Loading dependency project from /usr/local/Cellar/dbt/0.10.1/libexec/lib/python3.6/site-packages/dbt/include
2018-07-30 12:34:47,286: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/shopify-cohort-analysis/dbt_modules
2018-07-30 12:34:47,296: Parsing get_column_values.sql
2018-07-30 12:34:47,323: Parsing get_url_parameter.sql
2018-07-30 12:34:47,334: Parsing split_part.sql
2018-07-30 12:34:47,342: Parsing table_exists.sql
2018-07-30 12:34:47,356: Parsing core.sql
2018-07-30 12:34:47,370: Parsing adapters/bigquery.sql
2018-07-30 12:34:47,380: Parsing adapters/common.sql
2018-07-30 12:34:47,405: Parsing adapters/redshift.sql
2018-07-30 12:34:47,434: Parsing adapters/snowflake.sql
2018-07-30 12:34:47,441: Parsing etc/bigquery.sql
2018-07-30 12:34:47,447: Parsing etc/datetime.sql
2018-07-30 12:34:47,480: Parsing etc/get_custom_schema.sql
2018-07-30 12:34:47,489: Parsing materializations/helpers.sql
2018-07-30 12:34:47,510: Parsing materializations/archive/archive.sql
2018-07-30 12:34:47,561: Parsing materializations/incremental/incremental.sql
2018-07-30 12:34:47,598: Parsing materializations/seed/bigquery.sql
2018-07-30 12:34:47,606: Parsing materializations/seed/seed.sql
2018-07-30 12:34:47,660: Parsing materializations/table/bigquery_table.sql
2018-07-30 12:34:47,698: Parsing materializations/table/table.sql
2018-07-30 12:34:47,741: Parsing materializations/view/bigquery_view.sql
2018-07-30 12:34:47,765: Parsing materializations/view/view.sql
2018-07-30 12:34:47,786: Parsing schema_tests/accepted_values.sql
2018-07-30 12:34:47,798: Parsing schema_tests/not_null.sql
2018-07-30 12:34:47,802: Parsing schema_tests/relationships.sql
2018-07-30 12:34:47,807: Parsing schema_tests/unique.sql
2018-07-30 12:34:47,843: Parsing model.shopify_cohort_analysis.all_dates
2018-07-30 12:34:47,847: Parsing model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 12:34:47,850: Parsing model.shopify_cohort_analysis.monthend_dates
2018-07-30 12:34:47,852: Parsing model.shopify_cohort_analysis.stores_proc
2018-07-30 12:34:47,854: Parsing model.shopify_cohort_analysis.ga_transactions
2018-07-30 12:34:47,864: Parsing model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 12:34:47,872: Parsing model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 12:34:47,882: Parsing model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 12:34:47,899: Parsing model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 12:34:47,913: Parsing model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 12:34:47,923: Parsing model.shopify_cohort_analysis.agg_customers
2018-07-30 12:34:47,927: Parsing model.shopify_cohort_analysis.agg_transactions
2018-07-30 12:34:47,931: Parsing model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 12:34:47,935: Parsing model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 12:34:47,939: Parsing model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 12:34:47,945: Parsing model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 12:34:47,957: Parsing model.shopify_cohort_analysis.customers_proc
2018-07-30 12:34:47,962: Parsing model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 12:34:47,971: Parsing model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 12:34:47,978: Parsing model.shopify_cohort_analysis.segment_proc_customers
2018-07-30 12:34:47,980: Parsing model.shopify_cohort_analysis.segment_stats_customers_agg
2018-07-30 12:34:47,986: Parsing model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 12:34:48,005: Found 22 models, 0 tests, 0 archives, 0 analyses, 62 macros, 0 operations, 0 seed files
2018-07-30 12:34:48,020: 
2018-07-30 12:34:48,119: Acquiring new bigquery connection "master".
2018-07-30 12:34:48,119: Opening a new connection (0 currently allocated)
2018-07-30 12:34:49,521: 12:34:49 | Concurrency: 4 threads (target='template')
2018-07-30 12:34:49,521: 12:34:49 | 
2018-07-30 12:34:49,648: 12:34:49 | 1 of 22 START table model template.monthend_dates.................... [RUN]
2018-07-30 12:34:49,648: 12:34:49 | 2 of 22 START table model template.all_dates......................... [RUN]
2018-07-30 12:34:49,649: Compiling model.shopify_cohort_analysis.monthend_dates
2018-07-30 12:34:49,648: 12:34:49 | 3 of 22 START table model template.mappings_ga_proc.................. [RUN]
2018-07-30 12:34:49,649: Compiling model.shopify_cohort_analysis.all_dates
2018-07-30 12:34:49,648: 12:34:49 | 4 of 22 START table model template.stores_proc....................... [RUN]
2018-07-30 12:34:49,659: Writing injected SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 12:34:49,659: Compiling model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 12:34:49,668: Writing injected SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 12:34:49,668: Compiling model.shopify_cohort_analysis.stores_proc
2018-07-30 12:34:49,678: Writing injected SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 12:34:49,680: Acquiring new bigquery connection "monthend_dates".
2018-07-30 12:34:49,696: Opening a new connection (1 currently allocated)
2018-07-30 12:34:49,695: Acquiring new bigquery connection "all_dates".
2018-07-30 12:34:49,696: Writing injected SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 12:34:49,699: Opening a new connection (2 currently allocated)
2018-07-30 12:34:49,704: Acquiring new bigquery connection "mappings_ga_proc".
2018-07-30 12:34:49,710: Acquiring new bigquery connection "stores_proc".
2018-07-30 12:34:49,710: Opening a new connection (3 currently allocated)
2018-07-30 12:34:49,720: Opening a new connection (4 currently allocated)
2018-07-30 12:34:50,129: Writing runtime SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 12:34:50,129: Fetching data for query all_dates:
create or replace table `template`.`all_dates`
  
  as (
    SELECT 
date_in_range,
unix_date(date_in_range) unix_date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
  );

    
2018-07-30 12:34:50,154: Writing runtime SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 12:34:50,155: Fetching data for query monthend_dates:
create or replace table `template`.`monthend_dates`
  
  as (
    SELECT
date_in_range,
date_in_range_bom,
date_in_range_bom_mom,
unix_date_in_range,
unix_date_in_range_bom,
unix_date(date_in_range_bom_mom) unix_date_in_range_bom_mom,
yyyymm,
date_in_range_yoy,
unix_date(date_in_range_yoy) unix_date_in_range_yoy

FROM
(
	SELECT 
	date_in_range,
	date_in_range_bom,
	date_sub(date_in_range_bom, INTERVAL 1 MONTH) date_in_range_bom_mom,
	date_sub(date_in_range, INTERVAL 1 YEAR) date_in_range_yoy,
	unix_date_in_range,
	unix_date(date_in_range_bom) unix_date_in_range_bom,
	yyyymm,
	first_value(date_in_range) over (partition by yyyymm order by date_in_range desc) monthend_date_in_range
	FROM
	( 
		SELECT 
		date_in_range,
		date_trunc( date_in_range, MONTH) date_in_range_bom,
		unix_date(date_in_range) unix_date_in_range,
		format_date("%Y-%m", date_in_range) AS yyyymm
		FROM UNNEST(
		    GENERATE_DATE_ARRAY(DATE('2016-01-31'), CURRENT_DATE(), INTERVAL 1 DAY)
		) AS date_in_range
	)
)
where date_in_range = monthend_date_in_range
  );

    
2018-07-30 12:34:50,184: Writing runtime SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 12:34:50,185: Fetching data for query stores_proc:
create or replace table `template`.`stores_proc`
  
  as (
    select 
store,
store_name,
account,
platform,
max(time_of_entry) time_of_entry

from  ( 

SELECT  
client store,
client_name store_name,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.accounts` 
where client_name != ''

) 

WHERE lv = time_of_entry
group by store, store_name, account, platform
  );

    
2018-07-30 12:34:50,202: Writing runtime SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 12:34:50,202: Fetching data for query mappings_ga_proc:
create or replace table `template`.`mappings_ga_proc`
  
  as (
    select 
store,
account,
store_name,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client store,
account,
client_name store_name,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.mappings_ga` 

) 

WHERE lv = time_of_entry
group by store, account, store_name, source, medium, platform_n, channel_n, time_of_entry
  );

    
2018-07-30 12:34:51,825: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b264240>]}
2018-07-30 12:34:51,975: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b264358>]}
2018-07-30 12:34:52,139: 12:34:52 | 2 of 22 OK created table model template.all_dates.................... [OK in 2.18s]
2018-07-30 12:34:52,208: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b2641d0>]}
2018-07-30 12:34:52,408: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b207908>]}
2018-07-30 12:34:52,428: 12:34:52 | 3 of 22 OK created table model template.mappings_ga_proc............. [OK in 2.32s]
2018-07-30 12:34:52,742: 12:34:52 | 4 of 22 OK created table model template.stores_proc.................. [OK in 2.54s]
2018-07-30 12:34:53,049: 12:34:53 | 1 of 22 OK created table model template.monthend_dates............... [OK in 2.76s]
2018-07-30 12:34:53,049: 12:34:53 | 5 of 22 START table model template.shopify_refunds_proc.............. [RUN]
2018-07-30 12:34:53,050: Compiling model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 12:34:53,049: 12:34:53 | 6 of 22 START table model template.shopify_customers_proc............ [RUN]
2018-07-30 12:34:53,059: Acquiring new bigquery connection "shopify_refunds_proc".
2018-07-30 12:34:53,050: 12:34:53 | 7 of 22 START table model template.shopify_discounts_proc............ [RUN]
2018-07-30 12:34:53,059: Compiling model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 12:34:53,059: Compiling model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 12:34:53,061: Re-using an available connection from the pool.
2018-07-30 12:34:53,078: Acquiring new bigquery connection "shopify_customers_proc".
2018-07-30 12:34:53,079: Acquiring new bigquery connection "shopify_discounts_proc".
2018-07-30 12:34:53,079: Fetching data for query shopify_refunds_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:34:53,079: Re-using an available connection from the pool.
2018-07-30 12:34:53,080: Fetching data for query shopify_customers_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:34:53,080: Re-using an available connection from the pool.
2018-07-30 12:34:53,080: Fetching data for query shopify_discounts_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:34:55,260: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 12:34:55,482: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 12:34:55,503: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 12:34:55,552: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 12:34:55,553: Fetching data for query shopify_refunds_proc:
create or replace table `template`.`shopify_refunds_proc`
  
  as (
    



with refunds as (

	
	SELECT
	'lucadanni' store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal,
	line_item.variant_id variant_id,
	line_item.id refund_id,
 	_sdc_sequence
	FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
	cross join unnest(refunds), unnest(refund_line_items)
  	where financial_status like '%refund%'
	
	

)

SELECT * 
FROM 
	(
    SELECT
    store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal refund_amount,
	variant_id,
	refund_id,
 	_sdc_sequence,
    first_value(_sdc_sequence) OVER (PARTITION BY order_number, line_item_id ORDER BY _sdc_sequence DESC) lv
    FROM refunds
   	) 
WHERE lv = _sdc_sequence


  );

    
2018-07-30 12:34:55,691: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 12:34:55,691: Fetching data for query shopify_customers_proc:
create or replace table `template`.`shopify_customers_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`





with customers as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	created_at,
	id,
	first_name,
	last_name,
	email,
	_sdc_sequence,
	first_value(_sdc_sequence) over (partition by id order by _sdc_sequence desc) lv
	FROM `growth-engines-pipeline.shopify_lucadanni.customers` 
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
id,
first_name,
last_name,
email
FROM customers a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence


  );

    
2018-07-30 12:34:55,842: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 12:34:55,843: Fetching data for query shopify_discounts_proc:
create or replace table `template`.`shopify_discounts_proc`
  
  as (
    



with orders as (

	
		SELECT
		'lucadanni' store_name,
		created_at,
		order_number,
		code discount_code,
		type discount_type,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(discount_codes)
		where source_name != 'shopify_draft_order'
	
	
	

)

SELECT
store_name,
order_number,
discount_code,
discount_type
FROM orders
where lv = _sdc_sequence


  );

    
2018-07-30 12:34:57,547: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b1fae48>]}
2018-07-30 12:34:57,844: 12:34:57 | 5 of 22 OK created table model template.shopify_refunds_proc......... [OK in 4.50s]
2018-07-30 12:34:58,774: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b264eb8>]}
2018-07-30 12:34:59,936: 12:34:59 | 7 of 22 OK created table model template.shopify_discounts_proc....... [OK in 5.71s]
2018-07-30 12:35:00,759: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10996bf98>]}
2018-07-30 12:35:02,138: 12:35:02 | 6 of 22 OK created table model template.shopify_customers_proc....... [OK in 7.70s]
2018-07-30 12:35:02,140: 12:35:02 | 8 of 22 START table model template.ga_transactions................... [RUN]
2018-07-30 12:35:02,140: Compiling model.shopify_cohort_analysis.ga_transactions
2018-07-30 12:35:02,151: 12:35:02 | 9 of 22 START table model template.shopify_products_proc............. [RUN]
2018-07-30 12:35:02,152: Compiling model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 12:35:02,159: 12:35:02 | 10 of 22 START table model template.agg_customers.................... [RUN]
2018-07-30 12:35:02,166: Compiling model.shopify_cohort_analysis.agg_customers
2018-07-30 12:35:02,182: Acquiring new bigquery connection "shopify_products_proc".
2018-07-30 12:35:02,195: Writing injected SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 12:35:02,205: Acquiring new bigquery connection "ga_transactions".
2018-07-30 12:35:02,206: Re-using an available connection from the pool.
2018-07-30 12:35:02,206: Fetching data for query shopify_products_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:35:02,206: Re-using an available connection from the pool.
2018-07-30 12:35:02,207: Fetching data for query ga_transactions:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Google Analytics'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:35:02,210: Acquiring new bigquery connection "agg_customers".
2018-07-30 12:35:02,212: Re-using an available connection from the pool.
2018-07-30 12:35:02,362: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 12:35:02,365: Fetching data for query agg_customers:
create or replace table `template`.`agg_customers`
  
  as (
    SELECT 
account,
store,
id,
created_at,
first_name,
last_name,
email,
split(email,'@')[SAFE_ORDINAL(2)] email_domain
FROM
`growth-engines-pipeline`.`template`.`shopify_customers_proc`
  );

    
2018-07-30 12:35:02,974: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 12:35:03,098: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 12:35:03,099: Fetching data for query shopify_products_proc:
create or replace table `template`.`shopify_products_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`





with products as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	product_name,
	lower(product_type) product_type,
	product_id,
	sku,
	id variant_id,
	cast(created_at as date) created_at,
	_sdc_sequence,
	first_value(_sdc_sequence) OVER (PARTITION BY product_id ORDER BY _sdc_sequence DESC) lv
	FROM (
		SELECT
		variants,
		product_type,
		title product_name,
		_sdc_sequence
		FROM `growth-engines-pipeline.shopify_lucadanni.products` 
		)
	cross join unnest(variants)
	
	

)

SELECT
b.account,
b.store,
b.platform,
max(product_type) product_type,
product_id,
variant_id,
sku,
created_at,
product_name
FROM products a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence
group by product_id, account, store, platform, sku, variant_id, created_at, product_name


  );

    
2018-07-30 12:35:04,138: Writing injected SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 12:35:04,313: Writing runtime SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 12:35:04,317: Fetching data for query ga_transactions:
create or replace table `template`.`ga_transactions`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`,`growth-engines-pipeline`.`template`.`mappings_ga_proc`




with ga_report as (

	    
	    	
		   	SELECT
		   	'yandy' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_yandy.report` 

		     UNION ALL 
	   
	    	
		   	SELECT
		   	'lucadanni' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_lucadanni.report` 

		    
	   

)


SELECT  
date,
b.store store,
c.source source,
c.medium medium,
a.campaign campaign,
concat(a.source, ' / ', a.medium) source_medium,  
case when c.platform is null then "Unmapped" else c.platform end as platform,
case when c.channel is null then "Unmapped" else c.channel end as channel,
url,
transactionid
FROM (

	SELECT 
	store_name,
	lookup_platform,
	date,
	transactionid,
	max(url) url,
	max(source) source,
	max(medium) medium,
	max(campaign) campaign
	FROM ga_report
	where lv = _sdc_sequence
	group by store_name, lookup_platform, date, transactionid

) a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name 
	AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`mappings_ga_proc` c
ON ( a.source = c.source
  AND a.medium = c.medium 
  AND a.store_name = c.store_name )


  );

    
2018-07-30 12:35:05,862: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b2ad6d8>]}
2018-07-30 12:35:06,524: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b247ef0>]}
2018-07-30 12:35:07,337: 12:35:07 | 9 of 22 OK created table model template.shopify_products_proc........ [OK in 3.71s]
2018-07-30 12:35:07,635: 12:35:07 | 10 of 22 OK created table model template.agg_customers............... [OK in 4.36s]
2018-07-30 12:35:31,537: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b1175f8>]}
2018-07-30 12:35:31,875: 12:35:31 | 8 of 22 OK created table model template.ga_transactions.............. [OK in 29.40s]
2018-07-30 12:35:31,876: 12:35:31 | 11 of 22 START table model template.shopify_orders_proc.............. [RUN]
2018-07-30 12:35:31,876: Compiling model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 12:35:31,905: Acquiring new bigquery connection "shopify_orders_proc".
2018-07-30 12:35:31,905: Re-using an available connection from the pool.
2018-07-30 12:35:31,906: Fetching data for query shopify_orders_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:35:33,613: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 12:35:33,841: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 12:35:33,841: Fetching data for query shopify_orders_proc:
create or replace table `template`.`shopify_orders_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`, `growth-engines-pipeline`.`template`.`shopify_discounts_proc`





with orders as (

	
	SELECT 
	store_name,
	lookup_platform,
	created_at,
	order_number,
	quantity,
	price, 
	total_order_price_undiscounted,
	total_discounts,
	total_order_shipping_price,
	total_order_price_incl_shipping,
	checkout_id,
	product_id, 
	landing_site,
	sku, 
	variant_title, 
	variant_id,
	line_item_id,
	customer_id,
	_sdc_sequence,
	lv
	FROM (

		SELECT
		'lucadanni' store_name,
		'Shopify' as lookup_platform,
		created_at,
		order_number,
		quantity,
		cast(pre_tax_price as float64) price, 
		total_line_items_price total_order_price_undiscounted,
		total_discounts,
		cast(discounted_price as float64) total_order_shipping_price,
		total_price_usd total_order_price_incl_shipping,
		checkout_id,
		product_id, 
		landing_site,
		sku, 
		variant_title, 
		variant_id,
		_id line_item_id,
		customer.id customer_id,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(line_items), unnest(shipping_lines)
		where source_name != 'shopify_draft_order'
	)
	
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
a.order_number,
a.quantity prelim_quantity,
c.quantity refund_quantity,
case when c.quantity is not null then a.quantity - c.quantity else a.quantity end as quantity,
price prelim_revenue, 
total_order_price_undiscounted,
total_discounts,
trim(lower(d.discount_code)) discount_code,
d.discount_type,
total_order_shipping_price,
total_order_price_incl_shipping,
refund_amount,
case when refund_amount is not null then price - refund_amount else price end as revenue,
a.checkout_id,
a.product_id, 
landing_site,
sku, 
variant_title, 
a.variant_id,
a.line_item_id,	
customer_id
FROM orders a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_refunds_proc` c
ON ( a.order_number = c.order_number
	AND a.line_item_id = c.line_item_id
	AND a.store_name = c.store_name )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_discounts_proc` d
ON ( a.order_number = d.order_number 
    AND a.store_name = d.store_name )  	
where a.lv = a._sdc_sequence


  );

    
2018-07-30 12:35:43,378: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10996bf98>]}
2018-07-30 12:35:44,133: 12:35:44 | 11 of 22 OK created table model template.shopify_orders_proc......... [OK in 11.50s]
2018-07-30 12:35:44,134: 12:35:44 | 12 of 22 START table model template.transaction_by_order_number...... [RUN]
2018-07-30 12:35:44,135: Compiling model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 12:35:44,143: Writing injected SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 12:35:44,146: Acquiring new bigquery connection "transaction_by_order_number".
2018-07-30 12:35:44,146: Re-using an available connection from the pool.
2018-07-30 12:35:44,330: Writing runtime SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 12:35:44,331: Fetching data for query transaction_by_order_number:
create or replace table `template`.`transaction_by_order_number`
  
  as (
    SELECT
store,
cast(created_at as date) order_date,
order_number,
customer_id,
sum(quantity) quantity,
sum(revenue) revenue,
max(total_order_shipping_price) shipping_price
FROM
`growth-engines-pipeline`.`template`.`shopify_orders_proc`
GROUP BY store, order_date, order_number, customer_id
  );

    
2018-07-30 12:35:48,914: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b1175f8>]}
2018-07-30 12:35:49,750: 12:35:49 | 12 of 22 OK created table model template.transaction_by_order_number. [OK in 4.78s]
2018-07-30 12:35:49,753: 12:35:49 | 13 of 22 START table model template.customers_by_transaction......... [RUN]
2018-07-30 12:35:49,753: Compiling model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 12:35:49,761: Writing injected SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 12:35:49,769: Acquiring new bigquery connection "customers_by_transaction".
2018-07-30 12:35:49,769: Re-using an available connection from the pool.
2018-07-30 12:35:49,895: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 12:35:49,896: Fetching data for query customers_by_transaction:
create or replace table `template`.`customers_by_transaction`
  
  as (
    SELECT
store,
customer_id,
order_number,
order_date,
recent_order_date,
first_order_date,
case when first_order_number = order_number then 'New'
	when date_diff(order_date, recent_order_date, DAY) <= 365 then 'Repeat'
	when date_diff(order_date, recent_order_date, DAY) > 365 then 'Reactivated'
 else '' end as order_type,
quantity,
revenue,
1 as orders,
first_order_revenue,
lifetime_revenue
FROM

(

	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	quantity,
	revenue,
	lag(order_date) over w1 recent_order_date,
	first_value(order_date) over w1 first_order_date,
	first_value(order_number) over w1 first_order_number,
	first_value(revenue) over w1 first_order_revenue,
	sum(revenue) over w2 lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`transaction_by_order_number`
	WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc),
	w2 as (PARTITION BY store, customer_id)
)
  );

    
2018-07-30 12:35:53,705: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10996bf98>]}
2018-07-30 12:35:54,159: 12:35:54 | 13 of 22 OK created table model template.customers_by_transaction.... [OK in 3.95s]
2018-07-30 12:35:54,160: 12:35:54 | 14 of 22 START table model template.agg_transactions................. [RUN]
2018-07-30 12:35:54,160: Compiling model.shopify_cohort_analysis.agg_transactions
2018-07-30 12:35:54,171: Writing injected SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 12:35:54,176: Acquiring new bigquery connection "agg_transactions".
2018-07-30 12:35:54,176: Re-using an available connection from the pool.
2018-07-30 12:35:54,302: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 12:35:54,303: Fetching data for query agg_transactions:
create or replace table `template`.`agg_transactions`
  
  as (
    with ga_transaction as (

	SELECT
	date, 
	store,
	transactionid,
	channel,
	platform,
	url,
	campaign
	FROM `growth-engines-pipeline`.`template`.`ga_transactions`
),

customers_by_transaction as (
	
	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	first_order_date,
	recent_order_date,
	order_type,
	quantity,
	revenue,
	orders,
	first_order_revenue,
	lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`customers_by_transaction`
)

SELECT
store,
customer_id,
order_number,
transactionid,
order_date,
first_order_date,
format_date("%Y-%m", first_order_date) AS first_order_month,
order_type,
first_order_revenue,
lifetime_revenue,
first_value(channel) over w1 as first_order_channel,
first_value(platform) over w1 as first_order_platform,
channel,
platform,
url,
campaign,
quantity,
revenue,
orders
FROM (

	SELECT
	a.store,
	a.customer_id,
	a.order_number,
	b.transactionid,
	a.order_date, 
	a.first_order_date, 
	a.order_type,
	a.first_order_revenue,
	a.lifetime_revenue,
	b.channel,
	b.platform,
	b.url,
	b.campaign,
	a.quantity,
	a.revenue,
	a.orders
	FROM customers_by_transaction a
	LEFT JOIN ga_transaction b
	ON (
	    a.store = b.store AND
	    a.order_number = b.transactionid
	)	
)
WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc)
  );

    
2018-07-30 12:36:03,089: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b1175f8>]}
2018-07-30 12:36:04,627: 12:36:04 | 14 of 22 OK created table model template.agg_transactions............ [OK in 8.93s]
2018-07-30 12:36:04,628: 12:36:04 | 15 of 22 START table model template.customers_proc_yoy............... [RUN]
2018-07-30 12:36:04,628: Compiling model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 12:36:04,628: 12:36:04 | 16 of 22 START table model template.customers_proc_qoq............... [RUN]
2018-07-30 12:36:04,628: 12:36:04 | 17 of 22 START table model template.monthly_cohort_stats............. [RUN]
2018-07-30 12:36:04,644: Compiling model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 12:36:04,643: Compiling model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 12:36:04,643: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 12:36:04,662: Writing injected SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 12:36:04,669: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 12:36:04,677: Acquiring new bigquery connection "monthly_cohort_stats".
2018-07-30 12:36:04,677: Re-using an available connection from the pool.
2018-07-30 12:36:04,682: Acquiring new bigquery connection "customers_proc_yoy".
2018-07-30 12:36:04,682: Re-using an available connection from the pool.
2018-07-30 12:36:04,704: Acquiring new bigquery connection "customers_proc_qoq".
2018-07-30 12:36:04,705: Re-using an available connection from the pool.
2018-07-30 12:36:04,873: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 12:36:04,891: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 12:36:04,892: Fetching data for query customers_proc_yoy:
create or replace table `template`.`customers_proc_yoy`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 365 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 365 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 365 window_end_unix_date, 
    unix_date_in_range - 730 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 730 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 365 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 12:36:04,900: Writing runtime SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 12:36:04,904: Fetching data for query monthly_cohort_stats:
create or replace table `template`.`monthly_cohort_stats`
  
  as (
    WITH transactions AS (

  SELECT 
  store, 
  order_number,
  order_date,
  order_type,
  first_order_month,
  unix_date(order_date) d, 
  customer_id, 
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (

  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT 
date_in_range date,
store, 
order_type,
first_order_channel,
first_order_platform,
first_order_month,
channel,
platform,
url,
campaign,
count(distinct(customer_id)) buyers,
sum(orders) orders,
sum(quantity) quantity,
sum(revenue) revenue
FROM daterange
JOIN transactions
ON transactions.d >= daterange.unix_date_in_range_bom 
AND transactions.d <= daterange.unix_date_in_range
GROUP BY date, store, order_type, 
first_order_channel, first_order_platform, first_order_month, channel, platform, url, campaign
  );

    
2018-07-30 12:36:04,910: Fetching data for query customers_proc_qoq:
create or replace table `template`.`customers_proc_qoq`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 90 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 90 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 90 window_end_unix_date, 
    unix_date_in_range - 180 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 180 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 90 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 12:36:09,518: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b29b400>]}
2018-07-30 12:36:10,144: 12:36:10 | 17 of 22 OK created table model template.monthly_cohort_stats........ [OK in 4.87s]
2018-07-30 12:36:17,758: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e93160>]}
2018-07-30 12:36:18,055: 12:36:18 | 16 of 22 OK created table model template.customers_proc_qoq.......... [OK in 13.11s]
2018-07-30 12:36:31,158: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10996bf98>]}
2018-07-30 12:36:31,808: 12:36:31 | 15 of 22 OK created table model template.customers_proc_yoy.......... [OK in 26.53s]
2018-07-30 12:36:31,809: 12:36:31 | 18 of 22 START table model template.customers_proc................... [RUN]
2018-07-30 12:36:31,810: Compiling model.shopify_cohort_analysis.customers_proc
2018-07-30 12:36:31,834: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 12:36:31,839: Acquiring new bigquery connection "customers_proc".
2018-07-30 12:36:31,839: Re-using an available connection from the pool.
2018-07-30 12:36:31,993: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 12:36:31,994: Fetching data for query customers_proc:
create or replace table `template`.`customers_proc`
  
  as (
    SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_qoq`

UNION ALL

SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_yoy`
  );

    
2018-07-30 12:36:58,546: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b1175f8>]}
2018-07-30 12:37:00,228: 12:37:00 | 18 of 22 OK created table model template.customers_proc.............. [OK in 26.73s]
2018-07-30 12:37:00,229: 12:37:00 | 19 of 22 START table model template.segment_proc_customers........... [RUN]
2018-07-30 12:37:00,230: Compiling model.shopify_cohort_analysis.segment_proc_customers
2018-07-30 12:37:00,265: Writing injected SQL for node "model.shopify_cohort_analysis.segment_proc_customers"
2018-07-30 12:37:00,267: Acquiring new bigquery connection "segment_proc_customers".
2018-07-30 12:37:00,267: Re-using an available connection from the pool.
2018-07-30 12:37:00,405: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_proc_customers"
2018-07-30 12:37:00,406: Fetching data for query segment_proc_customers:
create or replace table `template`.`segment_proc_customers`
  
  as (
    SELECT
store,
period,
customer_id,
date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct,
case when first_order_unix_date >= window_start_unix_date then 'New'
	else 'Existing' end as newness_segment,
case when revenue >= revenue_90pct then 'Whale'
	when revenue <= revenue_10pct then 'Minnow'
	else 'Bristlemouth' end as revenue_segment,
case when frequency = 1 then '1'
	when frequency = 2 then '2'
	when frequency > 2 then '3+'
	else null end as frequency_segment
FROM `growth-engines-pipeline`.`template`.`customers_proc`
  );

    
2018-07-30 12:37:29,244: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10996bf98>]}
2018-07-30 12:37:29,583: 12:37:29 | 19 of 22 OK created table model template.segment_proc_customers...... [OK in 29.01s]
2018-07-30 12:37:29,585: 12:37:29 | 20 of 22 START table model template.segment_stats_customers_agg...... [RUN]
2018-07-30 12:37:29,585: Compiling model.shopify_cohort_analysis.segment_stats_customers_agg
2018-07-30 12:37:29,617: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_customers_agg"
2018-07-30 12:37:29,621: Acquiring new bigquery connection "segment_stats_customers_agg".
2018-07-30 12:37:29,621: Re-using an available connection from the pool.
2018-07-30 12:37:29,774: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_customers_agg"
2018-07-30 12:37:29,775: Fetching data for query segment_stats_customers_agg:
create or replace table `template`.`segment_stats_customers_agg`
  
  as (
    WITH ty as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Year'

),

this_month_1yr as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Previous Year'

),

this_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,	
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Quarter'

),

last_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev		
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Previous Quarter'

)

SELECT
store,
period,
date, 
customer_id,
1 as buyers,
first_order_channel,
first_order_platform,	
case when max(revenue_segment) != '' then max(revenue_segment) 
	when max(revenue_segment_prev) != '' then 'Dormant'
	else '' end as revenue_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(revenue_segment_prev) end as revenue_segment_prev,
case when max(frequency_segment) != '' then max(frequency_segment) 
	when max(frequency_segment_prev) != '' then 'Dormant'
	else '' end as frequency_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(frequency_segment_prev) end as frequency_segment_prev,
ifnull(sum(recency), 0) recency,
ifnull(sum(frequency), 0) frequency,
ifnull(sum(revenue), 0) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else 0 end as aov,
ifnull(sum(recency_prev), 0) recency_prev,
ifnull(sum(frequency_prev), 0) frequency_prev,
ifnull(sum(revenue_prev), 0) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else 0 end as aov_prev,
case when max(newness_segment_prev) != '' then 1 else 0 end as retention_eligible,
case when max(newness_segment_prev) != '' and max(newness_segment) != '' then 1 else 0 end as retention_success
FROM
(
	SELECT * FROM ty
	UNION ALL
	SELECT * FROM this_month_1yr
	UNION ALL
	SELECT * FROM this_quarter
	UNION ALL
	SELECT * FROM last_quarter

)
GROUP BY store, period, date, customer_id, first_order_channel, first_order_platform
  );

    
2018-07-30 12:37:56,130: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b1175f8>]}
2018-07-30 12:37:56,546: 12:37:56 | 20 of 22 OK created table model template.segment_stats_customers_agg. [OK in 26.54s]
2018-07-30 12:37:56,548: 12:37:56 | 21 of 22 START table model template.buyer_segment_stats.............. [RUN]
2018-07-30 12:37:56,548: Compiling model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 12:37:56,589: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 12:37:56,593: Acquiring new bigquery connection "buyer_segment_stats".
2018-07-30 12:37:56,594: Re-using an available connection from the pool.
2018-07-30 12:37:56,735: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 12:37:56,736: Fetching data for query buyer_segment_stats:
create or replace table `template`.`buyer_segment_stats`
  
  as (
    SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
sum(retention_eligible) retention_eligible,
sum(retention_success) retention_success
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
sum(retention_eligible) retention_eligible,
sum(retention_success) retention_success
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
sum(retention_eligible) retention_eligible,
sum(retention_success) retention_success
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
sum(retention_eligible) retention_eligible,
sum(retention_success) retention_success
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
sum(retention_eligible) retention_eligible,
sum(retention_success) retention_success
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
sum(retention_eligible) retention_eligible,
sum(retention_success) retention_success
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type
  );

    
2018-07-30 12:37:59,755: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10996bf98>]}
2018-07-30 12:38:01,086: 12:38:01 | 21 of 22 OK created table model template.buyer_segment_stats......... [OK in 3.21s]
2018-07-30 12:38:01,087: 12:38:01 | 22 of 22 START table model template.buyer_segment_lists.............. [RUN]
2018-07-30 12:38:01,087: Compiling model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 12:38:01,095: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 12:38:01,097: Acquiring new bigquery connection "buyer_segment_lists".
2018-07-30 12:38:01,097: Re-using an available connection from the pool.
2018-07-30 12:38:01,280: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 12:38:01,282: Fetching data for query buyer_segment_lists:
create or replace table `template`.`buyer_segment_lists`
  
  as (
    SELECT
a.store,
period,
date,
customer_id,
b.first_name,
b.last_name,
b.email,
recency,
frequency,
revenue,
aov,
revenue_segment,
frequency_segment
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg` a
LEFT JOIN `growth-engines-pipeline`.`template`.`agg_customers` b
ON (
	a.store = b.store AND
	a.customer_id = b.id
)
where ( revenue_segment != '' or frequency_segment != '' )
  );

    
2018-07-30 12:38:31,023: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c560430-9006-407a-8d3c-b38ed10f0c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b1175f8>]}
2018-07-30 12:38:31,643: 12:38:31 | 22 of 22 OK created table model template.buyer_segment_lists......... [OK in 29.93s]
2018-07-30 12:38:31,708: 12:38:31 | 
2018-07-30 12:38:31,709: 12:38:31 | Finished running 22 table models in 223.69s.
2018-07-30 12:38:31,710: Connection 'master' was left open.
2018-07-30 12:38:31,711: 
2018-07-30 12:38:31,711: Completed successfully
2018-07-30 12:38:31,712: 
Done. PASS=22 ERROR=0 SKIP=0 TOTAL=22
2018-07-30 12:38:31,713: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b14a048>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b272588>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b272ba8>]}
2018-07-30 12:38:32,029: Flushing usage events
2018-07-30 12:38:32,448: sys:1: ResourceWarning: unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 51378), raddr=('172.217.11.237', 443)>

2018-07-30 12:38:32,450: sys:1: ResourceWarning: unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 51379), raddr=('172.217.11.237', 443)>

2018-07-30 12:38:32,450: sys:1: ResourceWarning: unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 51376), raddr=('172.217.1.74', 443)>

2018-07-30 12:38:32,451: sys:1: ResourceWarning: unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 51371), raddr=('172.217.11.237', 443)>

2018-07-30 12:38:32,452: sys:1: ResourceWarning: unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 51380), raddr=('172.217.11.237', 443)>

2018-07-30 12:38:32,452: sys:1: ResourceWarning: unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 51381), raddr=('172.217.11.237', 443)>

2018-07-30 12:38:32,452: sys:1: ResourceWarning: unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 51388), raddr=('172.217.12.10', 443)>

2018-07-30 12:38:32,453: sys:1: ResourceWarning: unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 51389), raddr=('172.217.12.10', 443)>

2018-07-30 12:38:32,453: sys:1: ResourceWarning: unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 51385), raddr=('172.217.12.10', 443)>

2018-07-30 12:38:32,453: sys:1: ResourceWarning: unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 51387), raddr=('172.217.12.10', 443)>

2018-07-30 12:42:40,316: Tracking: tracking
2018-07-30 12:42:40,318: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105295e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052952b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105295ef0>]}
2018-07-30 12:42:41,251: Loading dependency project from /usr/local/Cellar/dbt/0.10.1/libexec/lib/python3.6/site-packages/dbt/include
2018-07-30 12:42:41,294: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/shopify-cohort-analysis/dbt_modules
2018-07-30 12:42:41,301: Parsing get_column_values.sql
2018-07-30 12:42:41,320: Parsing get_url_parameter.sql
2018-07-30 12:42:41,329: Parsing split_part.sql
2018-07-30 12:42:41,341: Parsing table_exists.sql
2018-07-30 12:42:41,354: Parsing core.sql
2018-07-30 12:42:41,371: Parsing adapters/bigquery.sql
2018-07-30 12:42:41,382: Parsing adapters/common.sql
2018-07-30 12:42:41,407: Parsing adapters/redshift.sql
2018-07-30 12:42:41,428: Parsing adapters/snowflake.sql
2018-07-30 12:42:41,434: Parsing etc/bigquery.sql
2018-07-30 12:42:41,439: Parsing etc/datetime.sql
2018-07-30 12:42:41,468: Parsing etc/get_custom_schema.sql
2018-07-30 12:42:41,482: Parsing materializations/helpers.sql
2018-07-30 12:42:41,509: Parsing materializations/archive/archive.sql
2018-07-30 12:42:41,549: Parsing materializations/incremental/incremental.sql
2018-07-30 12:42:41,589: Parsing materializations/seed/bigquery.sql
2018-07-30 12:42:41,597: Parsing materializations/seed/seed.sql
2018-07-30 12:42:41,648: Parsing materializations/table/bigquery_table.sql
2018-07-30 12:42:41,682: Parsing materializations/table/table.sql
2018-07-30 12:42:41,717: Parsing materializations/view/bigquery_view.sql
2018-07-30 12:42:41,733: Parsing materializations/view/view.sql
2018-07-30 12:42:41,759: Parsing schema_tests/accepted_values.sql
2018-07-30 12:42:41,768: Parsing schema_tests/not_null.sql
2018-07-30 12:42:41,774: Parsing schema_tests/relationships.sql
2018-07-30 12:42:41,782: Parsing schema_tests/unique.sql
2018-07-30 12:42:41,812: Parsing model.shopify_cohort_analysis.all_dates
2018-07-30 12:42:41,815: Parsing model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 12:42:41,818: Parsing model.shopify_cohort_analysis.monthend_dates
2018-07-30 12:42:41,820: Parsing model.shopify_cohort_analysis.stores_proc
2018-07-30 12:42:41,823: Parsing model.shopify_cohort_analysis.ga_transactions
2018-07-30 12:42:41,833: Parsing model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 12:42:41,841: Parsing model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 12:42:41,849: Parsing model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 12:42:41,858: Parsing model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 12:42:41,867: Parsing model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 12:42:41,873: Parsing model.shopify_cohort_analysis.agg_customers
2018-07-30 12:42:41,875: Parsing model.shopify_cohort_analysis.agg_transactions
2018-07-30 12:42:41,879: Parsing model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 12:42:41,882: Parsing model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 12:42:41,885: Parsing model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 12:42:41,888: Parsing model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 12:42:41,896: Parsing model.shopify_cohort_analysis.customers_proc
2018-07-30 12:42:41,900: Parsing model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 12:42:41,904: Parsing model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 12:42:41,909: Parsing model.shopify_cohort_analysis.segment_proc_customers
2018-07-30 12:42:41,913: Parsing model.shopify_cohort_analysis.segment_stats_customers_agg
2018-07-30 12:42:41,920: Parsing model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 12:42:41,941: Found 22 models, 0 tests, 0 archives, 0 analyses, 62 macros, 0 operations, 0 seed files
2018-07-30 12:42:41,949: 
2018-07-30 12:42:41,955: Acquiring new bigquery connection "master".
2018-07-30 12:42:41,956: Opening a new connection (0 currently allocated)
2018-07-30 12:42:45,675: 12:42:45 | Concurrency: 4 threads (target='template')
2018-07-30 12:42:45,676: 12:42:45 | 
2018-07-30 12:42:45,743: 12:42:45 | 1 of 22 START table model template.all_dates......................... [RUN]
2018-07-30 12:42:45,744: Compiling model.shopify_cohort_analysis.all_dates
2018-07-30 12:42:45,749: Writing injected SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 12:42:45,744: 12:42:45 | 2 of 22 START table model template.monthend_dates.................... [RUN]
2018-07-30 12:42:45,750: Compiling model.shopify_cohort_analysis.monthend_dates
2018-07-30 12:42:45,755: Writing injected SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 12:42:45,744: 12:42:45 | 3 of 22 START table model template.mappings_ga_proc.................. [RUN]
2018-07-30 12:42:45,756: Compiling model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 12:42:45,744: 12:42:45 | 4 of 22 START table model template.stores_proc....................... [RUN]
2018-07-30 12:42:45,762: Writing injected SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 12:42:45,762: Compiling model.shopify_cohort_analysis.stores_proc
2018-07-30 12:42:45,764: Acquiring new bigquery connection "mappings_ga_proc".
2018-07-30 12:42:45,769: Writing injected SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 12:42:45,771: Acquiring new bigquery connection "monthend_dates".
2018-07-30 12:42:45,772: Acquiring new bigquery connection "all_dates".
2018-07-30 12:42:45,772: Opening a new connection (1 currently allocated)
2018-07-30 12:42:45,778: Acquiring new bigquery connection "stores_proc".
2018-07-30 12:42:45,780: Opening a new connection (2 currently allocated)
2018-07-30 12:42:45,783: Opening a new connection (3 currently allocated)
2018-07-30 12:42:45,793: Opening a new connection (4 currently allocated)
2018-07-30 12:42:46,985: Writing runtime SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 12:42:47,017: Writing runtime SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 12:42:47,018: Writing runtime SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 12:42:47,018: Fetching data for query stores_proc:
create or replace table `template`.`stores_proc`
  
  as (
    select 
store,
store_name,
account,
platform,
max(time_of_entry) time_of_entry

from  ( 

SELECT  
client store,
client_name store_name,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.accounts` 
where client_name != ''

) 

WHERE lv = time_of_entry
group by store, store_name, account, platform
  );

    
2018-07-30 12:42:47,036: Fetching data for query mappings_ga_proc:
create or replace table `template`.`mappings_ga_proc`
  
  as (
    select 
store,
account,
store_name,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client store,
account,
client_name store_name,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.mappings_ga` 

) 

WHERE lv = time_of_entry
group by store, account, store_name, source, medium, platform_n, channel_n, time_of_entry
  );

    
2018-07-30 12:42:47,037: Fetching data for query monthend_dates:
create or replace table `template`.`monthend_dates`
  
  as (
    SELECT
date_in_range,
date_in_range_bom,
date_in_range_bom_mom,
unix_date_in_range,
unix_date_in_range_bom,
unix_date(date_in_range_bom_mom) unix_date_in_range_bom_mom,
yyyymm,
date_in_range_yoy,
unix_date(date_in_range_yoy) unix_date_in_range_yoy

FROM
(
	SELECT 
	date_in_range,
	date_in_range_bom,
	date_sub(date_in_range_bom, INTERVAL 1 MONTH) date_in_range_bom_mom,
	date_sub(date_in_range, INTERVAL 1 YEAR) date_in_range_yoy,
	unix_date_in_range,
	unix_date(date_in_range_bom) unix_date_in_range_bom,
	yyyymm,
	first_value(date_in_range) over (partition by yyyymm order by date_in_range desc) monthend_date_in_range
	FROM
	( 
		SELECT 
		date_in_range,
		date_trunc( date_in_range, MONTH) date_in_range_bom,
		unix_date(date_in_range) unix_date_in_range,
		format_date("%Y-%m", date_in_range) AS yyyymm
		FROM UNNEST(
		    GENERATE_DATE_ARRAY(DATE('2016-01-31'), CURRENT_DATE(), INTERVAL 1 DAY)
		) AS date_in_range
	)
)
where date_in_range = monthend_date_in_range
  );

    
2018-07-30 12:42:47,046: Writing runtime SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 12:42:47,055: Fetching data for query all_dates:
create or replace table `template`.`all_dates`
  
  as (
    SELECT 
date_in_range,
unix_date(date_in_range) unix_date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
  );

    
2018-07-30 12:42:48,801: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053d95f8>]}
2018-07-30 12:42:48,815: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053c14a8>]}
2018-07-30 12:42:48,817: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105425470>]}
2018-07-30 12:42:49,021: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1054251d0>]}
2018-07-30 12:42:49,150: 12:42:49 | 3 of 22 OK created table model template.mappings_ga_proc............. [OK in 3.05s]
2018-07-30 12:42:49,448: 12:42:49 | 2 of 22 OK created table model template.monthend_dates............... [OK in 3.07s]
2018-07-30 12:42:49,750: 12:42:49 | 1 of 22 OK created table model template.all_dates.................... [OK in 3.07s]
2018-07-30 12:42:50,056: 12:42:50 | 4 of 22 OK created table model template.stores_proc.................. [OK in 3.26s]
2018-07-30 12:42:50,057: 12:42:50 | 5 of 22 START table model template.shopify_discounts_proc............ [RUN]
2018-07-30 12:42:50,057: Compiling model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 12:42:50,057: 12:42:50 | 6 of 22 START table model template.shopify_refunds_proc.............. [RUN]
2018-07-30 12:42:50,063: Compiling model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 12:42:50,057: 12:42:50 | 7 of 22 START table model template.shopify_customers_proc............ [RUN]
2018-07-30 12:42:50,078: Compiling model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 12:42:50,078: Acquiring new bigquery connection "shopify_refunds_proc".
2018-07-30 12:42:50,084: Acquiring new bigquery connection "shopify_discounts_proc".
2018-07-30 12:42:50,092: Acquiring new bigquery connection "shopify_customers_proc".
2018-07-30 12:42:50,092: Re-using an available connection from the pool.
2018-07-30 12:42:50,092: Fetching data for query shopify_refunds_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:42:50,093: Re-using an available connection from the pool.
2018-07-30 12:42:50,093: Fetching data for query shopify_discounts_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:42:50,093: Re-using an available connection from the pool.
2018-07-30 12:42:50,096: Fetching data for query shopify_customers_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:42:51,542: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 12:42:51,670: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 12:42:51,680: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 12:42:51,686: Fetching data for query shopify_discounts_proc:
create or replace table `template`.`shopify_discounts_proc`
  
  as (
    



with orders as (

	
		SELECT
		'lucadanni' store_name,
		created_at,
		order_number,
		code discount_code,
		type discount_type,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(discount_codes)
		where source_name != 'shopify_draft_order'
	
	
	

)

SELECT
store_name,
order_number,
discount_code,
discount_type
FROM orders
where lv = _sdc_sequence


  );

    
2018-07-30 12:42:51,713: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 12:42:51,828: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 12:42:51,829: Fetching data for query shopify_customers_proc:
create or replace table `template`.`shopify_customers_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`





with customers as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	created_at,
	id,
	first_name,
	last_name,
	email,
	_sdc_sequence,
	first_value(_sdc_sequence) over (partition by id order by _sdc_sequence desc) lv
	FROM `growth-engines-pipeline.shopify_lucadanni.customers` 
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
id,
first_name,
last_name,
email
FROM customers a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence


  );

    
2018-07-30 12:42:51,884: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 12:42:51,884: Fetching data for query shopify_refunds_proc:
create or replace table `template`.`shopify_refunds_proc`
  
  as (
    



with refunds as (

	
	SELECT
	'lucadanni' store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal,
	line_item.variant_id variant_id,
	line_item.id refund_id,
 	_sdc_sequence
	FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
	cross join unnest(refunds), unnest(refund_line_items)
  	where financial_status like '%refund%'
	
	

)

SELECT * 
FROM 
	(
    SELECT
    store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal refund_amount,
	variant_id,
	refund_id,
 	_sdc_sequence,
    first_value(_sdc_sequence) OVER (PARTITION BY order_number, line_item_id ORDER BY _sdc_sequence DESC) lv
    FROM refunds
   	) 
WHERE lv = _sdc_sequence


  );

    
2018-07-30 12:42:53,999: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1054251d0>]}
2018-07-30 12:42:54,344: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053c14a8>]}
2018-07-30 12:42:54,659: 12:42:54 | 6 of 22 OK created table model template.shopify_refunds_proc......... [OK in 3.94s]
2018-07-30 12:42:55,305: 12:42:55 | 5 of 22 OK created table model template.shopify_discounts_proc....... [OK in 4.29s]
2018-07-30 12:42:56,437: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053db9e8>]}
2018-07-30 12:42:56,726: 12:42:56 | 7 of 22 OK created table model template.shopify_customers_proc....... [OK in 6.36s]
2018-07-30 12:42:56,727: 12:42:56 | 8 of 22 START table model template.shopify_products_proc............. [RUN]
2018-07-30 12:42:56,727: Compiling model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 12:42:56,727: 12:42:56 | 9 of 22 START table model template.ga_transactions................... [RUN]
2018-07-30 12:42:56,727: 12:42:56 | 10 of 22 START table model template.agg_customers.................... [RUN]
2018-07-30 12:42:56,730: Compiling model.shopify_cohort_analysis.ga_transactions
2018-07-30 12:42:56,737: Compiling model.shopify_cohort_analysis.agg_customers
2018-07-30 12:42:56,744: Acquiring new bigquery connection "shopify_products_proc".
2018-07-30 12:42:56,763: Writing injected SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 12:42:56,764: Re-using an available connection from the pool.
2018-07-30 12:42:56,767: Acquiring new bigquery connection "ga_transactions".
2018-07-30 12:42:56,767: Fetching data for query shopify_products_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:42:56,768: Re-using an available connection from the pool.
2018-07-30 12:42:56,770: Acquiring new bigquery connection "agg_customers".
2018-07-30 12:42:56,772: Fetching data for query ga_transactions:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Google Analytics'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:42:56,774: Re-using an available connection from the pool.
2018-07-30 12:42:56,933: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 12:42:56,936: Fetching data for query agg_customers:
create or replace table `template`.`agg_customers`
  
  as (
    SELECT 
account,
store,
id,
created_at,
first_name,
last_name,
email,
split(email,'@')[SAFE_ORDINAL(2)] email_domain
FROM
`growth-engines-pipeline`.`template`.`shopify_customers_proc`
  );

    
2018-07-30 12:42:57,620: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 12:42:57,750: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 12:42:57,750: Fetching data for query shopify_products_proc:
create or replace table `template`.`shopify_products_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`





with products as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	product_name,
	lower(product_type) product_type,
	product_id,
	sku,
	id variant_id,
	cast(created_at as date) created_at,
	_sdc_sequence,
	first_value(_sdc_sequence) OVER (PARTITION BY product_id ORDER BY _sdc_sequence DESC) lv
	FROM (
		SELECT
		variants,
		product_type,
		title product_name,
		_sdc_sequence
		FROM `growth-engines-pipeline.shopify_lucadanni.products` 
		)
	cross join unnest(variants)
	
	

)

SELECT
b.account,
b.store,
b.platform,
max(product_type) product_type,
product_id,
variant_id,
sku,
created_at,
product_name
FROM products a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence
group by product_id, account, store, platform, sku, variant_id, created_at, product_name


  );

    
2018-07-30 12:42:58,346: Writing injected SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 12:42:58,486: Writing runtime SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 12:42:58,490: Fetching data for query ga_transactions:
create or replace table `template`.`ga_transactions`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`,`growth-engines-pipeline`.`template`.`mappings_ga_proc`




with ga_report as (

	    
	    	
		   	SELECT
		   	'yandy' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_yandy.report` 

		     UNION ALL 
	   
	    	
		   	SELECT
		   	'lucadanni' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_lucadanni.report` 

		    
	   

)


SELECT  
date,
b.store store,
c.source source,
c.medium medium,
a.campaign campaign,
concat(a.source, ' / ', a.medium) source_medium,  
case when c.platform is null then "Unmapped" else c.platform end as platform,
case when c.channel is null then "Unmapped" else c.channel end as channel,
url,
transactionid
FROM (

	SELECT 
	store_name,
	lookup_platform,
	date,
	transactionid,
	max(url) url,
	max(source) source,
	max(medium) medium,
	max(campaign) campaign
	FROM ga_report
	where lv = _sdc_sequence
	group by store_name, lookup_platform, date, transactionid

) a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name 
	AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`mappings_ga_proc` c
ON ( a.source = c.source
  AND a.medium = c.medium 
  AND a.store_name = c.store_name )


  );

    
2018-07-30 12:42:59,967: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105395e48>]}
2018-07-30 12:43:00,265: 12:43:00 | 8 of 22 OK created table model template.shopify_products_proc........ [OK in 3.24s]
2018-07-30 12:43:01,240: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053f5240>]}
2018-07-30 12:43:01,544: 12:43:01 | 10 of 22 OK created table model template.agg_customers............... [OK in 4.50s]
2018-07-30 12:43:26,600: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053f8748>]}
2018-07-30 12:43:26,932: 12:43:26 | 9 of 22 OK created table model template.ga_transactions.............. [OK in 29.87s]
2018-07-30 12:43:26,932: 12:43:26 | 11 of 22 START table model template.shopify_orders_proc.............. [RUN]
2018-07-30 12:43:26,932: Compiling model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 12:43:26,943: Acquiring new bigquery connection "shopify_orders_proc".
2018-07-30 12:43:26,943: Re-using an available connection from the pool.
2018-07-30 12:43:26,944: Fetching data for query shopify_orders_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:43:27,726: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 12:43:27,844: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 12:43:27,845: Fetching data for query shopify_orders_proc:
create or replace table `template`.`shopify_orders_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`, `growth-engines-pipeline`.`template`.`shopify_discounts_proc`





with orders as (

	
	SELECT 
	store_name,
	lookup_platform,
	created_at,
	order_number,
	quantity,
	price, 
	total_order_price_undiscounted,
	total_discounts,
	total_order_shipping_price,
	total_order_price_incl_shipping,
	checkout_id,
	product_id, 
	landing_site,
	sku, 
	variant_title, 
	variant_id,
	line_item_id,
	customer_id,
	_sdc_sequence,
	lv
	FROM (

		SELECT
		'lucadanni' store_name,
		'Shopify' as lookup_platform,
		created_at,
		order_number,
		quantity,
		cast(pre_tax_price as float64) price, 
		total_line_items_price total_order_price_undiscounted,
		total_discounts,
		cast(discounted_price as float64) total_order_shipping_price,
		total_price_usd total_order_price_incl_shipping,
		checkout_id,
		product_id, 
		landing_site,
		sku, 
		variant_title, 
		variant_id,
		_id line_item_id,
		customer.id customer_id,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(line_items), unnest(shipping_lines)
		where source_name != 'shopify_draft_order'
	)
	
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
a.order_number,
a.quantity prelim_quantity,
c.quantity refund_quantity,
case when c.quantity is not null then a.quantity - c.quantity else a.quantity end as quantity,
price prelim_revenue, 
total_order_price_undiscounted,
total_discounts,
trim(lower(d.discount_code)) discount_code,
d.discount_type,
total_order_shipping_price,
total_order_price_incl_shipping,
refund_amount,
case when refund_amount is not null then price - refund_amount else price end as revenue,
a.checkout_id,
a.product_id, 
landing_site,
sku, 
variant_title, 
a.variant_id,
a.line_item_id,	
customer_id
FROM orders a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_refunds_proc` c
ON ( a.order_number = c.order_number
	AND a.line_item_id = c.line_item_id
	AND a.store_name = c.store_name )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_discounts_proc` d
ON ( a.order_number = d.order_number 
    AND a.store_name = d.store_name )  	
where a.lv = a._sdc_sequence


  );

    
2018-07-30 12:43:41,192: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053db9e8>]}
2018-07-30 12:43:45,661: 12:43:45 | 11 of 22 OK created table model template.shopify_orders_proc......... [OK in 14.26s]
2018-07-30 12:43:45,664: 12:43:45 | 12 of 22 START table model template.transaction_by_order_number...... [RUN]
2018-07-30 12:43:45,665: Compiling model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 12:43:45,675: Writing injected SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 12:43:45,677: Acquiring new bigquery connection "transaction_by_order_number".
2018-07-30 12:43:45,677: Re-using an available connection from the pool.
2018-07-30 12:43:45,869: Writing runtime SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 12:43:45,870: Fetching data for query transaction_by_order_number:
create or replace table `template`.`transaction_by_order_number`
  
  as (
    SELECT
store,
cast(created_at as date) order_date,
order_number,
customer_id,
sum(quantity) quantity,
sum(revenue) revenue,
max(total_order_shipping_price) shipping_price
FROM
`growth-engines-pipeline`.`template`.`shopify_orders_proc`
GROUP BY store, order_date, order_number, customer_id
  );

    
2018-07-30 12:43:51,820: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053fe4a8>]}
2018-07-30 12:43:54,443: 12:43:54 | 12 of 22 OK created table model template.transaction_by_order_number. [OK in 6.16s]
2018-07-30 12:43:54,448: 12:43:54 | 13 of 22 START table model template.customers_by_transaction......... [RUN]
2018-07-30 12:43:54,449: Compiling model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 12:43:54,455: Writing injected SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 12:43:54,465: Acquiring new bigquery connection "customers_by_transaction".
2018-07-30 12:43:54,465: Re-using an available connection from the pool.
2018-07-30 12:43:54,670: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 12:43:54,670: Fetching data for query customers_by_transaction:
create or replace table `template`.`customers_by_transaction`
  
  as (
    SELECT
store,
customer_id,
order_number,
order_date,
recent_order_date,
first_order_date,
case when first_order_number = order_number then 'New'
	when date_diff(order_date, recent_order_date, DAY) <= 365 then 'Repeat'
	when date_diff(order_date, recent_order_date, DAY) > 365 then 'Reactivated'
 else '' end as order_type,
quantity,
revenue,
1 as orders,
first_order_revenue,
lifetime_revenue
FROM

(

	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	quantity,
	revenue,
	lag(order_date) over w1 recent_order_date,
	first_value(order_date) over w1 first_order_date,
	first_value(order_number) over w1 first_order_number,
	first_value(revenue) over w1 first_order_revenue,
	sum(revenue) over w2 lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`transaction_by_order_number`
	WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc),
	w2 as (PARTITION BY store, customer_id)
)
  );

    
2018-07-30 12:43:59,380: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053db9e8>]}
2018-07-30 12:44:02,803: 12:44:02 | 13 of 22 OK created table model template.customers_by_transaction.... [OK in 4.93s]
2018-07-30 12:44:02,806: 12:44:02 | 14 of 22 START table model template.agg_transactions................. [RUN]
2018-07-30 12:44:02,806: Compiling model.shopify_cohort_analysis.agg_transactions
2018-07-30 12:44:02,820: Writing injected SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 12:44:02,825: Acquiring new bigquery connection "agg_transactions".
2018-07-30 12:44:02,825: Re-using an available connection from the pool.
2018-07-30 12:44:03,579: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 12:44:03,580: Fetching data for query agg_transactions:
create or replace table `template`.`agg_transactions`
  
  as (
    with ga_transaction as (

	SELECT
	date, 
	store,
	transactionid,
	channel,
	platform,
	url,
	campaign
	FROM `growth-engines-pipeline`.`template`.`ga_transactions`
),

customers_by_transaction as (
	
	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	first_order_date,
	recent_order_date,
	order_type,
	quantity,
	revenue,
	orders,
	first_order_revenue,
	lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`customers_by_transaction`
)

SELECT
store,
customer_id,
order_number,
transactionid,
order_date,
first_order_date,
format_date("%Y-%m", first_order_date) AS first_order_month,
order_type,
first_order_revenue,
lifetime_revenue,
first_value(channel) over w1 as first_order_channel,
first_value(platform) over w1 as first_order_platform,
channel,
platform,
url,
campaign,
quantity,
revenue,
orders
FROM (

	SELECT
	a.store,
	a.customer_id,
	a.order_number,
	b.transactionid,
	a.order_date, 
	a.first_order_date, 
	a.order_type,
	a.first_order_revenue,
	a.lifetime_revenue,
	b.channel,
	b.platform,
	b.url,
	b.campaign,
	a.quantity,
	a.revenue,
	a.orders
	FROM customers_by_transaction a
	LEFT JOIN ga_transaction b
	ON (
	    a.store = b.store AND
	    a.order_number = b.transactionid
	)	
)
WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc)
  );

    
2018-07-30 12:44:11,954: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053616a0>]}
2018-07-30 12:44:12,819: 12:44:12 | 14 of 22 OK created table model template.agg_transactions............ [OK in 9.15s]
2018-07-30 12:44:12,820: 12:44:12 | 15 of 22 START table model template.customers_proc_yoy............... [RUN]
2018-07-30 12:44:12,821: Compiling model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 12:44:12,820: 12:44:12 | 16 of 22 START table model template.customers_proc_qoq............... [RUN]
2018-07-30 12:44:12,831: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 12:44:12,820: 12:44:12 | 17 of 22 START table model template.monthly_cohort_stats............. [RUN]
2018-07-30 12:44:12,831: Compiling model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 12:44:12,831: Compiling model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 12:44:12,841: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 12:44:12,854: Acquiring new bigquery connection "customers_proc_qoq".
2018-07-30 12:44:12,854: Re-using an available connection from the pool.
2018-07-30 12:44:12,849: Writing injected SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 12:44:12,861: Acquiring new bigquery connection "monthly_cohort_stats".
2018-07-30 12:44:12,861: Re-using an available connection from the pool.
2018-07-30 12:44:12,868: Acquiring new bigquery connection "customers_proc_yoy".
2018-07-30 12:44:12,870: Re-using an available connection from the pool.
2018-07-30 12:44:13,157: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 12:44:13,157: Fetching data for query customers_proc_qoq:
create or replace table `template`.`customers_proc_qoq`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 90 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 90 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 90 window_end_unix_date, 
    unix_date_in_range - 180 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 180 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 90 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 12:44:13,221: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 12:44:13,231: Writing runtime SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 12:44:13,231: Fetching data for query customers_proc_yoy:
create or replace table `template`.`customers_proc_yoy`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 365 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 365 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 365 window_end_unix_date, 
    unix_date_in_range - 730 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 730 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 365 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 12:44:13,231: Fetching data for query monthly_cohort_stats:
create or replace table `template`.`monthly_cohort_stats`
  
  as (
    WITH transactions AS (

  SELECT 
  store, 
  order_number,
  order_date,
  order_type,
  first_order_month,
  unix_date(order_date) d, 
  customer_id, 
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (

  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT 
date_in_range date,
store, 
order_type,
first_order_channel,
first_order_platform,
first_order_month,
channel,
platform,
url,
campaign,
count(distinct(customer_id)) buyers,
sum(orders) orders,
sum(quantity) quantity,
sum(revenue) revenue
FROM daterange
JOIN transactions
ON transactions.d >= daterange.unix_date_in_range_bom 
AND transactions.d <= daterange.unix_date_in_range
GROUP BY date, store, order_type, 
first_order_channel, first_order_platform, first_order_month, channel, platform, url, campaign
  );

    
2018-07-30 12:44:18,434: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105472358>]}
2018-07-30 12:44:20,604: 12:44:20 | 17 of 22 OK created table model template.monthly_cohort_stats........ [OK in 5.60s]
2018-07-30 12:44:26,818: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1054e5a20>]}
2018-07-30 12:44:31,879: 12:44:31 | 16 of 22 OK created table model template.customers_proc_qoq.......... [OK in 13.99s]
2018-07-30 12:44:33,951: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053db9e8>]}
2018-07-30 12:44:34,345: 12:44:34 | 15 of 22 OK created table model template.customers_proc_yoy.......... [OK in 21.13s]
2018-07-30 12:44:34,346: 12:44:34 | 18 of 22 START table model template.customers_proc................... [RUN]
2018-07-30 12:44:34,346: Compiling model.shopify_cohort_analysis.customers_proc
2018-07-30 12:44:34,359: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 12:44:34,362: Acquiring new bigquery connection "customers_proc".
2018-07-30 12:44:34,362: Re-using an available connection from the pool.
2018-07-30 12:44:34,557: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 12:44:34,558: Fetching data for query customers_proc:
create or replace table `template`.`customers_proc`
  
  as (
    SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_qoq`

UNION ALL

SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_yoy`
  );

    
2018-07-30 12:45:02,126: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053616a0>]}
2018-07-30 12:45:04,702: 12:45:04 | 18 of 22 OK created table model template.customers_proc.............. [OK in 27.78s]
2018-07-30 12:45:04,702: 12:45:04 | 19 of 22 START table model template.segment_proc_customers........... [RUN]
2018-07-30 12:45:04,702: Compiling model.shopify_cohort_analysis.segment_proc_customers
2018-07-30 12:45:04,712: Writing injected SQL for node "model.shopify_cohort_analysis.segment_proc_customers"
2018-07-30 12:45:04,714: Acquiring new bigquery connection "segment_proc_customers".
2018-07-30 12:45:04,714: Re-using an available connection from the pool.
2018-07-30 12:45:05,131: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_proc_customers"
2018-07-30 12:45:05,131: Fetching data for query segment_proc_customers:
create or replace table `template`.`segment_proc_customers`
  
  as (
    SELECT
store,
period,
customer_id,
date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct,
case when first_order_unix_date >= window_start_unix_date then 'New'
	else 'Existing' end as newness_segment,
case when revenue >= revenue_90pct then 'Whale'
	when revenue <= revenue_10pct then 'Minnow'
	else 'Bristlemouth' end as revenue_segment,
case when frequency = 1 then '1'
	when frequency = 2 then '2'
	when frequency > 2 then '3+'
	else null end as frequency_segment
FROM `growth-engines-pipeline`.`template`.`customers_proc`
  );

    
2018-07-30 12:45:34,118: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053db9e8>]}
2018-07-30 12:45:34,494: 12:45:34 | 19 of 22 OK created table model template.segment_proc_customers...... [OK in 29.42s]
2018-07-30 12:45:34,495: 12:45:34 | 20 of 22 START table model template.segment_stats_customers_agg...... [RUN]
2018-07-30 12:45:34,495: Compiling model.shopify_cohort_analysis.segment_stats_customers_agg
2018-07-30 12:45:34,505: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_customers_agg"
2018-07-30 12:45:34,509: Acquiring new bigquery connection "segment_stats_customers_agg".
2018-07-30 12:45:34,510: Re-using an available connection from the pool.
2018-07-30 12:45:36,545: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_customers_agg"
2018-07-30 12:45:36,546: Fetching data for query segment_stats_customers_agg:
create or replace table `template`.`segment_stats_customers_agg`
  
  as (
    WITH ty as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Year'

),

this_month_1yr as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Previous Year'

),

this_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,	
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Quarter'

),

last_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev		
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Previous Quarter'

)

SELECT
store,
period,
date, 
customer_id,
1 as buyers,
first_order_channel,
first_order_platform,	
case when max(revenue_segment) != '' then max(revenue_segment) 
	when max(revenue_segment_prev) != '' then 'Dormant'
	else '' end as revenue_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(revenue_segment_prev) end as revenue_segment_prev,
case when max(frequency_segment) != '' then max(frequency_segment) 
	when max(frequency_segment_prev) != '' then 'Dormant'
	else '' end as frequency_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(frequency_segment_prev) end as frequency_segment_prev,
ifnull(sum(recency), 0) recency,
ifnull(sum(frequency), 0) frequency,
ifnull(sum(revenue), 0) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else 0 end as aov,
ifnull(sum(recency_prev), 0) recency_prev,
ifnull(sum(frequency_prev), 0) frequency_prev,
ifnull(sum(revenue_prev), 0) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else 0 end as aov_prev,
case when max(newness_segment_prev) != '' then 1 else 0 end as retention_eligible,
case when max(newness_segment_prev) != '' and max(newness_segment) != '' then 1 else 0 end as retention_success
FROM
(
	SELECT * FROM ty
	UNION ALL
	SELECT * FROM this_month_1yr
	UNION ALL
	SELECT * FROM this_quarter
	UNION ALL
	SELECT * FROM last_quarter

)
GROUP BY store, period, date, customer_id, first_order_channel, first_order_platform
  );

    
2018-07-30 12:46:06,681: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053feb00>]}
2018-07-30 12:46:07,588: 12:46:07 | 20 of 22 OK created table model template.segment_stats_customers_agg. [OK in 32.19s]
2018-07-30 12:46:07,589: 12:46:07 | 21 of 22 START table model template.buyer_segment_stats.............. [RUN]
2018-07-30 12:46:07,589: Compiling model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 12:46:07,612: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 12:46:07,615: Acquiring new bigquery connection "buyer_segment_stats".
2018-07-30 12:46:07,615: Re-using an available connection from the pool.
2018-07-30 12:46:08,128: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 12:46:08,129: Fetching data for query buyer_segment_stats:
create or replace table `template`.`buyer_segment_stats`
  
  as (
    SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_elibible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_elibible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_elibible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_elibible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_elibible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_elibible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type
  );

    
2018-07-30 12:46:09,943: Bad request while running:
create dataset
2018-07-30 12:46:09,943: 400 GET https://www.googleapis.com/bigquery/v2/projects/growth-engines-pipeline/queries/ba5b92ff-2086-405c-b977-ce6820e7a8e5?maxResults=0: Unrecognized name: retention_elibible; Did you mean retention_eligible? at [22:15]
2018-07-30 12:46:09,944: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102810208>]}
2018-07-30 12:46:10,247: 12:46:10 | 21 of 22 ERROR creating table model template.buyer_segment_stats..... [ERROR in 2.36s]
2018-07-30 12:46:10,248: 12:46:10 | 22 of 22 START table model template.buyer_segment_lists.............. [RUN]
2018-07-30 12:46:10,249: Compiling model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 12:46:10,257: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 12:46:10,260: Acquiring new bigquery connection "buyer_segment_lists".
2018-07-30 12:46:10,260: Re-using an available connection from the pool.
2018-07-30 12:46:10,824: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 12:46:10,825: Fetching data for query buyer_segment_lists:
create or replace table `template`.`buyer_segment_lists`
  
  as (
    SELECT
a.store,
period,
date,
customer_id,
b.first_name,
b.last_name,
b.email,
recency,
frequency,
revenue,
aov,
revenue_segment,
frequency_segment
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg` a
LEFT JOIN `growth-engines-pipeline`.`template`.`agg_customers` b
ON (
	a.store = b.store AND
	a.customer_id = b.id
)
where ( revenue_segment != '' or frequency_segment != '' )
  );

    
2018-07-30 12:46:45,795: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b41cc30-298f-4cfb-a05f-791ed5d3288d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105395e48>]}
2018-07-30 12:46:46,572: 12:46:46 | 22 of 22 OK created table model template.buyer_segment_lists......... [OK in 35.55s]
2018-07-30 12:46:46,625: 12:46:46 | 
2018-07-30 12:46:46,626: 12:46:46 | Finished running 22 table models in 244.68s.
2018-07-30 12:46:46,626: Connection 'master' was left open.
2018-07-30 12:46:46,626: 
2018-07-30 12:46:46,626: Completed with 1 errors:
2018-07-30 12:46:46,627: 
2018-07-30 12:46:46,627: Database Error in model buyer_segment_stats (models/math/buyer-segmentation/buyer_segment_stats.sql)
2018-07-30 12:46:46,627:   Unrecognized name: retention_elibible; Did you mean retention_eligible? at [22:15]
2018-07-30 12:46:46,627:   compiled SQL at target/run/shopify_cohort_analysis/math/buyer-segmentation/buyer_segment_stats.sql
2018-07-30 12:46:46,627: 
Done. PASS=21 ERROR=1 SKIP=0 TOTAL=22
2018-07-30 12:46:46,628: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1054256d8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1054be1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1054be240>]}
2018-07-30 12:46:48,168: Flushing usage events
2018-07-30 12:46:48,445: sys:1: ResourceWarning: unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 52079), raddr=('172.217.11.234', 443)>

2018-07-30 12:46:48,446: sys:1: ResourceWarning: unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 52078), raddr=('172.217.2.13', 443)>

2018-07-30 12:46:48,446: sys:1: ResourceWarning: unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 52081), raddr=('172.217.2.13', 443)>

2018-07-30 12:46:48,446: sys:1: ResourceWarning: unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 52080), raddr=('172.217.2.13', 443)>

2018-07-30 12:46:48,447: sys:1: ResourceWarning: unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 52082), raddr=('172.217.2.13', 443)>

2018-07-30 12:46:48,447: sys:1: ResourceWarning: unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 52083), raddr=('172.217.2.13', 443)>

2018-07-30 12:46:48,447: sys:1: ResourceWarning: unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 52088), raddr=('172.217.12.10', 443)>

2018-07-30 12:46:48,447: sys:1: ResourceWarning: unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 52087), raddr=('172.217.12.10', 443)>

2018-07-30 12:46:48,448: sys:1: ResourceWarning: unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 52085), raddr=('172.217.12.10', 443)>

2018-07-30 12:46:48,448: sys:1: ResourceWarning: unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 52086), raddr=('172.217.12.10', 443)>

2018-07-30 12:48:54,633: Tracking: tracking
2018-07-30 12:48:54,635: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ff1b358>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ff1bb38>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ff1bcf8>]}
2018-07-30 12:48:56,819: Loading dependency project from /usr/local/Cellar/dbt/0.10.1/libexec/lib/python3.6/site-packages/dbt/include
2018-07-30 12:48:56,879: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/shopify-cohort-analysis/dbt_modules
2018-07-30 12:48:56,887: Parsing get_column_values.sql
2018-07-30 12:48:56,915: Parsing get_url_parameter.sql
2018-07-30 12:48:56,921: Parsing split_part.sql
2018-07-30 12:48:56,928: Parsing table_exists.sql
2018-07-30 12:48:56,945: Parsing core.sql
2018-07-30 12:48:56,971: Parsing adapters/bigquery.sql
2018-07-30 12:48:56,984: Parsing adapters/common.sql
2018-07-30 12:48:57,034: Parsing adapters/redshift.sql
2018-07-30 12:48:57,074: Parsing adapters/snowflake.sql
2018-07-30 12:48:57,082: Parsing etc/bigquery.sql
2018-07-30 12:48:57,088: Parsing etc/datetime.sql
2018-07-30 12:48:57,132: Parsing etc/get_custom_schema.sql
2018-07-30 12:48:57,156: Parsing materializations/helpers.sql
2018-07-30 12:48:57,194: Parsing materializations/archive/archive.sql
2018-07-30 12:48:57,272: Parsing materializations/incremental/incremental.sql
2018-07-30 12:48:57,350: Parsing materializations/seed/bigquery.sql
2018-07-30 12:48:57,366: Parsing materializations/seed/seed.sql
2018-07-30 12:48:57,444: Parsing materializations/table/bigquery_table.sql
2018-07-30 12:48:57,493: Parsing materializations/table/table.sql
2018-07-30 12:48:57,549: Parsing materializations/view/bigquery_view.sql
2018-07-30 12:48:57,574: Parsing materializations/view/view.sql
2018-07-30 12:48:57,598: Parsing schema_tests/accepted_values.sql
2018-07-30 12:48:57,605: Parsing schema_tests/not_null.sql
2018-07-30 12:48:57,609: Parsing schema_tests/relationships.sql
2018-07-30 12:48:57,614: Parsing schema_tests/unique.sql
2018-07-30 12:48:57,636: Parsing model.shopify_cohort_analysis.all_dates
2018-07-30 12:48:57,639: Parsing model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 12:48:57,642: Parsing model.shopify_cohort_analysis.monthend_dates
2018-07-30 12:48:57,646: Parsing model.shopify_cohort_analysis.stores_proc
2018-07-30 12:48:57,649: Parsing model.shopify_cohort_analysis.ga_transactions
2018-07-30 12:48:57,662: Parsing model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 12:48:57,673: Parsing model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 12:48:57,683: Parsing model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 12:48:57,698: Parsing model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 12:48:57,712: Parsing model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 12:48:57,721: Parsing model.shopify_cohort_analysis.agg_customers
2018-07-30 12:48:57,724: Parsing model.shopify_cohort_analysis.agg_transactions
2018-07-30 12:48:57,729: Parsing model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 12:48:57,733: Parsing model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 12:48:57,736: Parsing model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 12:48:57,740: Parsing model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 12:48:57,748: Parsing model.shopify_cohort_analysis.customers_proc
2018-07-30 12:48:57,753: Parsing model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 12:48:57,757: Parsing model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 12:48:57,763: Parsing model.shopify_cohort_analysis.segment_proc_customers
2018-07-30 12:48:57,767: Parsing model.shopify_cohort_analysis.segment_stats_customers_agg
2018-07-30 12:48:57,773: Parsing model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 12:48:57,794: Found 22 models, 0 tests, 0 archives, 0 analyses, 62 macros, 0 operations, 0 seed files
2018-07-30 12:48:57,802: 
2018-07-30 12:48:57,821: Acquiring new bigquery connection "master".
2018-07-30 12:48:57,822: Opening a new connection (0 currently allocated)
2018-07-30 12:48:59,142: 12:48:59 | Concurrency: 4 threads (target='template')
2018-07-30 12:48:59,142: 12:48:59 | 
2018-07-30 12:48:59,299: 12:48:59 | 1 of 22 START table model template.all_dates......................... [RUN]
2018-07-30 12:48:59,299: Compiling model.shopify_cohort_analysis.all_dates
2018-07-30 12:48:59,311: Writing injected SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 12:48:59,306: 12:48:59 | 2 of 22 START table model template.stores_proc....................... [RUN]
2018-07-30 12:48:59,311: 12:48:59 | 3 of 22 START table model template.monthend_dates.................... [RUN]
2018-07-30 12:48:59,314: Compiling model.shopify_cohort_analysis.monthend_dates
2018-07-30 12:48:59,312: 12:48:59 | 4 of 22 START table model template.mappings_ga_proc.................. [RUN]
2018-07-30 12:48:59,328: Compiling model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 12:48:59,312: Compiling model.shopify_cohort_analysis.stores_proc
2018-07-30 12:48:59,346: Writing injected SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 12:48:59,347: Writing injected SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 12:48:59,358: Writing injected SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 12:48:59,361: Acquiring new bigquery connection "all_dates".
2018-07-30 12:48:59,363: Acquiring new bigquery connection "mappings_ga_proc".
2018-07-30 12:48:59,364: Opening a new connection (1 currently allocated)
2018-07-30 12:48:59,368: Acquiring new bigquery connection "monthend_dates".
2018-07-30 12:48:59,376: Opening a new connection (2 currently allocated)
2018-07-30 12:48:59,378: Acquiring new bigquery connection "stores_proc".
2018-07-30 12:48:59,383: Opening a new connection (3 currently allocated)
2018-07-30 12:48:59,385: Opening a new connection (4 currently allocated)
2018-07-30 12:48:59,812: Writing runtime SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 12:48:59,813: Fetching data for query all_dates:
create or replace table `template`.`all_dates`
  
  as (
    SELECT 
date_in_range,
unix_date(date_in_range) unix_date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
  );

    
2018-07-30 12:48:59,846: Writing runtime SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 12:48:59,846: Fetching data for query mappings_ga_proc:
create or replace table `template`.`mappings_ga_proc`
  
  as (
    select 
store,
account,
store_name,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client store,
account,
client_name store_name,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.mappings_ga` 

) 

WHERE lv = time_of_entry
group by store, account, store_name, source, medium, platform_n, channel_n, time_of_entry
  );

    
2018-07-30 12:48:59,864: Writing runtime SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 12:48:59,865: Fetching data for query stores_proc:
create or replace table `template`.`stores_proc`
  
  as (
    select 
store,
store_name,
account,
platform,
max(time_of_entry) time_of_entry

from  ( 

SELECT  
client store,
client_name store_name,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.accounts` 
where client_name != ''

) 

WHERE lv = time_of_entry
group by store, store_name, account, platform
  );

    
2018-07-30 12:48:59,892: Writing runtime SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 12:48:59,892: Fetching data for query monthend_dates:
create or replace table `template`.`monthend_dates`
  
  as (
    SELECT
date_in_range,
date_in_range_bom,
date_in_range_bom_mom,
unix_date_in_range,
unix_date_in_range_bom,
unix_date(date_in_range_bom_mom) unix_date_in_range_bom_mom,
yyyymm,
date_in_range_yoy,
unix_date(date_in_range_yoy) unix_date_in_range_yoy

FROM
(
	SELECT 
	date_in_range,
	date_in_range_bom,
	date_sub(date_in_range_bom, INTERVAL 1 MONTH) date_in_range_bom_mom,
	date_sub(date_in_range, INTERVAL 1 YEAR) date_in_range_yoy,
	unix_date_in_range,
	unix_date(date_in_range_bom) unix_date_in_range_bom,
	yyyymm,
	first_value(date_in_range) over (partition by yyyymm order by date_in_range desc) monthend_date_in_range
	FROM
	( 
		SELECT 
		date_in_range,
		date_trunc( date_in_range, MONTH) date_in_range_bom,
		unix_date(date_in_range) unix_date_in_range,
		format_date("%Y-%m", date_in_range) AS yyyymm
		FROM UNNEST(
		    GENERATE_DATE_ARRAY(DATE('2016-01-31'), CURRENT_DATE(), INTERVAL 1 DAY)
		) AS date_in_range
	)
)
where date_in_range = monthend_date_in_range
  );

    
2018-07-30 12:49:01,227: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100b3240>]}
2018-07-30 12:49:01,522: 12:49:01 | 1 of 22 OK created table model template.all_dates.................... [OK in 1.93s]
2018-07-30 12:49:01,555: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110059ef0>]}
2018-07-30 12:49:01,746: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100b2f98>]}
2018-07-30 12:49:01,816: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110016b38>]}
2018-07-30 12:49:01,850: 12:49:01 | 3 of 22 OK created table model template.monthend_dates............... [OK in 2.24s]
2018-07-30 12:49:02,141: 12:49:02 | 2 of 22 OK created table model template.stores_proc.................. [OK in 2.43s]
2018-07-30 12:49:02,434: 12:49:02 | 4 of 22 OK created table model template.mappings_ga_proc............. [OK in 2.49s]
2018-07-30 12:49:02,435: 12:49:02 | 5 of 22 START table model template.shopify_discounts_proc............ [RUN]
2018-07-30 12:49:02,435: Compiling model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 12:49:02,435: 12:49:02 | 6 of 22 START table model template.shopify_customers_proc............ [RUN]
2018-07-30 12:49:02,435: 12:49:02 | 7 of 22 START table model template.shopify_refunds_proc.............. [RUN]
2018-07-30 12:49:02,437: Compiling model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 12:49:02,444: Compiling model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 12:49:02,446: Acquiring new bigquery connection "shopify_discounts_proc".
2018-07-30 12:49:02,463: Acquiring new bigquery connection "shopify_customers_proc".
2018-07-30 12:49:02,466: Acquiring new bigquery connection "shopify_refunds_proc".
2018-07-30 12:49:02,466: Re-using an available connection from the pool.
2018-07-30 12:49:02,466: Fetching data for query shopify_discounts_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:49:02,467: Re-using an available connection from the pool.
2018-07-30 12:49:02,467: Fetching data for query shopify_customers_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:49:02,467: Re-using an available connection from the pool.
2018-07-30 12:49:02,469: Fetching data for query shopify_refunds_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:49:04,273: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 12:49:04,274: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 12:49:04,551: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 12:49:04,568: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 12:49:04,570: Fetching data for query shopify_refunds_proc:
create or replace table `template`.`shopify_refunds_proc`
  
  as (
    



with refunds as (

	
	SELECT
	'lucadanni' store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal,
	line_item.variant_id variant_id,
	line_item.id refund_id,
 	_sdc_sequence
	FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
	cross join unnest(refunds), unnest(refund_line_items)
  	where financial_status like '%refund%'
	
	

)

SELECT * 
FROM 
	(
    SELECT
    store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal refund_amount,
	variant_id,
	refund_id,
 	_sdc_sequence,
    first_value(_sdc_sequence) OVER (PARTITION BY order_number, line_item_id ORDER BY _sdc_sequence DESC) lv
    FROM refunds
   	) 
WHERE lv = _sdc_sequence


  );

    
2018-07-30 12:49:04,575: Fetching data for query shopify_customers_proc:
create or replace table `template`.`shopify_customers_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`





with customers as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	created_at,
	id,
	first_name,
	last_name,
	email,
	_sdc_sequence,
	first_value(_sdc_sequence) over (partition by id order by _sdc_sequence desc) lv
	FROM `growth-engines-pipeline.shopify_lucadanni.customers` 
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
id,
first_name,
last_name,
email
FROM customers a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence


  );

    
2018-07-30 12:49:04,868: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 12:49:05,044: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 12:49:05,050: Fetching data for query shopify_discounts_proc:
create or replace table `template`.`shopify_discounts_proc`
  
  as (
    



with orders as (

	
		SELECT
		'lucadanni' store_name,
		created_at,
		order_number,
		code discount_code,
		type discount_type,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(discount_codes)
		where source_name != 'shopify_draft_order'
	
	
	

)

SELECT
store_name,
order_number,
discount_code,
discount_type
FROM orders
where lv = _sdc_sequence


  );

    
2018-07-30 12:49:06,639: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e0b3400>]}
2018-07-30 12:49:06,954: 12:49:06 | 7 of 22 OK created table model template.shopify_refunds_proc......... [OK in 4.20s]
2018-07-30 12:49:07,170: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100b2128>]}
2018-07-30 12:49:07,483: 12:49:07 | 5 of 22 OK created table model template.shopify_discounts_proc....... [OK in 4.73s]
2018-07-30 12:49:09,328: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cbe77b8>]}
2018-07-30 12:49:09,622: 12:49:09 | 6 of 22 OK created table model template.shopify_customers_proc....... [OK in 6.89s]
2018-07-30 12:49:09,623: 12:49:09 | 8 of 22 START table model template.shopify_products_proc............. [RUN]
2018-07-30 12:49:09,624: Compiling model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 12:49:09,623: 12:49:09 | 9 of 22 START table model template.agg_customers..................... [RUN]
2018-07-30 12:49:09,623: 12:49:09 | 10 of 22 START table model template.ga_transactions.................. [RUN]
2018-07-30 12:49:09,637: Compiling model.shopify_cohort_analysis.agg_customers
2018-07-30 12:49:09,637: Acquiring new bigquery connection "shopify_products_proc".
2018-07-30 12:49:09,637: Compiling model.shopify_cohort_analysis.ga_transactions
2018-07-30 12:49:09,638: Re-using an available connection from the pool.
2018-07-30 12:49:09,657: Fetching data for query shopify_products_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:49:09,643: Writing injected SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 12:49:09,662: Acquiring new bigquery connection "agg_customers".
2018-07-30 12:49:09,663: Re-using an available connection from the pool.
2018-07-30 12:49:09,669: Acquiring new bigquery connection "ga_transactions".
2018-07-30 12:49:09,669: Re-using an available connection from the pool.
2018-07-30 12:49:09,669: Fetching data for query ga_transactions:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Google Analytics'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:49:09,821: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 12:49:09,824: Fetching data for query agg_customers:
create or replace table `template`.`agg_customers`
  
  as (
    SELECT 
account,
store,
id,
created_at,
first_name,
last_name,
email,
split(email,'@')[SAFE_ORDINAL(2)] email_domain
FROM
`growth-engines-pipeline`.`template`.`shopify_customers_proc`
  );

    
2018-07-30 12:49:10,432: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 12:49:10,558: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 12:49:10,559: Fetching data for query shopify_products_proc:
create or replace table `template`.`shopify_products_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`





with products as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	product_name,
	lower(product_type) product_type,
	product_id,
	sku,
	id variant_id,
	cast(created_at as date) created_at,
	_sdc_sequence,
	first_value(_sdc_sequence) OVER (PARTITION BY product_id ORDER BY _sdc_sequence DESC) lv
	FROM (
		SELECT
		variants,
		product_type,
		title product_name,
		_sdc_sequence
		FROM `growth-engines-pipeline.shopify_lucadanni.products` 
		)
	cross join unnest(variants)
	
	

)

SELECT
b.account,
b.store,
b.platform,
max(product_type) product_type,
product_id,
variant_id,
sku,
created_at,
product_name
FROM products a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence
group by product_id, account, store, platform, sku, variant_id, created_at, product_name


  );

    
2018-07-30 12:49:11,199: Writing injected SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 12:49:11,328: Writing runtime SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 12:49:11,329: Fetching data for query ga_transactions:
create or replace table `template`.`ga_transactions`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`,`growth-engines-pipeline`.`template`.`mappings_ga_proc`




with ga_report as (

	    
	    	
		   	SELECT
		   	'yandy' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_yandy.report` 

		     UNION ALL 
	   
	    	
		   	SELECT
		   	'lucadanni' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_lucadanni.report` 

		    
	   

)


SELECT  
date,
b.store store,
c.source source,
c.medium medium,
a.campaign campaign,
concat(a.source, ' / ', a.medium) source_medium,  
case when c.platform is null then "Unmapped" else c.platform end as platform,
case when c.channel is null then "Unmapped" else c.channel end as channel,
url,
transactionid
FROM (

	SELECT 
	store_name,
	lookup_platform,
	date,
	transactionid,
	max(url) url,
	max(source) source,
	max(medium) medium,
	max(campaign) campaign
	FROM ga_report
	where lv = _sdc_sequence
	group by store_name, lookup_platform, date, transactionid

) a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name 
	AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`mappings_ga_proc` c
ON ( a.source = c.source
  AND a.medium = c.medium 
  AND a.store_name = c.store_name )


  );

    
2018-07-30 12:49:12,922: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110016b38>]}
2018-07-30 12:49:13,585: 12:49:13 | 8 of 22 OK created table model template.shopify_products_proc........ [OK in 3.30s]
2018-07-30 12:49:13,877: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11018ae48>]}
2018-07-30 12:49:14,543: 12:49:14 | 9 of 22 OK created table model template.agg_customers................ [OK in 4.24s]
2018-07-30 12:49:34,518: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100b3c88>]}
2018-07-30 12:49:34,913: 12:49:34 | 10 of 22 OK created table model template.ga_transactions............. [OK in 24.88s]
2018-07-30 12:49:34,914: 12:49:34 | 11 of 22 START table model template.shopify_orders_proc.............. [RUN]
2018-07-30 12:49:34,915: Compiling model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 12:49:34,942: Acquiring new bigquery connection "shopify_orders_proc".
2018-07-30 12:49:34,943: Re-using an available connection from the pool.
2018-07-30 12:49:34,943: Fetching data for query shopify_orders_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 12:49:35,901: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 12:49:36,034: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 12:49:36,035: Fetching data for query shopify_orders_proc:
create or replace table `template`.`shopify_orders_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`, `growth-engines-pipeline`.`template`.`shopify_discounts_proc`





with orders as (

	
	SELECT 
	store_name,
	lookup_platform,
	created_at,
	order_number,
	quantity,
	price, 
	total_order_price_undiscounted,
	total_discounts,
	total_order_shipping_price,
	total_order_price_incl_shipping,
	checkout_id,
	product_id, 
	landing_site,
	sku, 
	variant_title, 
	variant_id,
	line_item_id,
	customer_id,
	_sdc_sequence,
	lv
	FROM (

		SELECT
		'lucadanni' store_name,
		'Shopify' as lookup_platform,
		created_at,
		order_number,
		quantity,
		cast(pre_tax_price as float64) price, 
		total_line_items_price total_order_price_undiscounted,
		total_discounts,
		cast(discounted_price as float64) total_order_shipping_price,
		total_price_usd total_order_price_incl_shipping,
		checkout_id,
		product_id, 
		landing_site,
		sku, 
		variant_title, 
		variant_id,
		_id line_item_id,
		customer.id customer_id,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(line_items), unnest(shipping_lines)
		where source_name != 'shopify_draft_order'
	)
	
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
a.order_number,
a.quantity prelim_quantity,
c.quantity refund_quantity,
case when c.quantity is not null then a.quantity - c.quantity else a.quantity end as quantity,
price prelim_revenue, 
total_order_price_undiscounted,
total_discounts,
trim(lower(d.discount_code)) discount_code,
d.discount_type,
total_order_shipping_price,
total_order_price_incl_shipping,
refund_amount,
case when refund_amount is not null then price - refund_amount else price end as revenue,
a.checkout_id,
a.product_id, 
landing_site,
sku, 
variant_title, 
a.variant_id,
a.line_item_id,	
customer_id
FROM orders a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_refunds_proc` c
ON ( a.order_number = c.order_number
	AND a.line_item_id = c.line_item_id
	AND a.store_name = c.store_name )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_discounts_proc` d
ON ( a.order_number = d.order_number 
    AND a.store_name = d.store_name )  	
where a.lv = a._sdc_sequence


  );

    
2018-07-30 12:49:44,736: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cbe77b8>]}
2018-07-30 12:49:45,215: 12:49:45 | 11 of 22 OK created table model template.shopify_orders_proc......... [OK in 9.82s]
2018-07-30 12:49:45,217: 12:49:45 | 12 of 22 START table model template.transaction_by_order_number...... [RUN]
2018-07-30 12:49:45,218: Compiling model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 12:49:45,234: Writing injected SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 12:49:45,237: Acquiring new bigquery connection "transaction_by_order_number".
2018-07-30 12:49:45,238: Re-using an available connection from the pool.
2018-07-30 12:49:45,791: Writing runtime SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 12:49:45,792: Fetching data for query transaction_by_order_number:
create or replace table `template`.`transaction_by_order_number`
  
  as (
    SELECT
store,
cast(created_at as date) order_date,
order_number,
customer_id,
sum(quantity) quantity,
sum(revenue) revenue,
max(total_order_shipping_price) shipping_price
FROM
`growth-engines-pipeline`.`template`.`shopify_orders_proc`
GROUP BY store, order_date, order_number, customer_id
  );

    
2018-07-30 12:49:50,117: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100b3c88>]}
2018-07-30 12:49:50,434: 12:49:50 | 12 of 22 OK created table model template.transaction_by_order_number. [OK in 4.90s]
2018-07-30 12:49:50,435: 12:49:50 | 13 of 22 START table model template.customers_by_transaction......... [RUN]
2018-07-30 12:49:50,435: Compiling model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 12:49:50,448: Writing injected SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 12:49:50,455: Acquiring new bigquery connection "customers_by_transaction".
2018-07-30 12:49:50,455: Re-using an available connection from the pool.
2018-07-30 12:49:50,699: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 12:49:50,700: Fetching data for query customers_by_transaction:
create or replace table `template`.`customers_by_transaction`
  
  as (
    SELECT
store,
customer_id,
order_number,
order_date,
recent_order_date,
first_order_date,
case when first_order_number = order_number then 'New'
	when date_diff(order_date, recent_order_date, DAY) <= 365 then 'Repeat'
	when date_diff(order_date, recent_order_date, DAY) > 365 then 'Reactivated'
 else '' end as order_type,
quantity,
revenue,
1 as orders,
first_order_revenue,
lifetime_revenue
FROM

(

	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	quantity,
	revenue,
	lag(order_date) over w1 recent_order_date,
	first_value(order_date) over w1 first_order_date,
	first_value(order_number) over w1 first_order_number,
	first_value(revenue) over w1 first_order_revenue,
	sum(revenue) over w2 lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`transaction_by_order_number`
	WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc),
	w2 as (PARTITION BY store, customer_id)
)
  );

    
2018-07-30 12:49:54,414: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cbe77b8>]}
2018-07-30 12:49:54,726: 12:49:54 | 13 of 22 OK created table model template.customers_by_transaction.... [OK in 3.98s]
2018-07-30 12:49:54,727: 12:49:54 | 14 of 22 START table model template.agg_transactions................. [RUN]
2018-07-30 12:49:54,727: Compiling model.shopify_cohort_analysis.agg_transactions
2018-07-30 12:49:54,747: Writing injected SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 12:49:54,750: Acquiring new bigquery connection "agg_transactions".
2018-07-30 12:49:54,750: Re-using an available connection from the pool.
2018-07-30 12:49:54,891: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 12:49:54,892: Fetching data for query agg_transactions:
create or replace table `template`.`agg_transactions`
  
  as (
    with ga_transaction as (

	SELECT
	date, 
	store,
	transactionid,
	channel,
	platform,
	url,
	campaign
	FROM `growth-engines-pipeline`.`template`.`ga_transactions`
),

customers_by_transaction as (
	
	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	first_order_date,
	recent_order_date,
	order_type,
	quantity,
	revenue,
	orders,
	first_order_revenue,
	lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`customers_by_transaction`
)

SELECT
store,
customer_id,
order_number,
transactionid,
order_date,
first_order_date,
format_date("%Y-%m", first_order_date) AS first_order_month,
order_type,
first_order_revenue,
lifetime_revenue,
first_value(channel) over w1 as first_order_channel,
first_value(platform) over w1 as first_order_platform,
channel,
platform,
url,
campaign,
quantity,
revenue,
orders
FROM (

	SELECT
	a.store,
	a.customer_id,
	a.order_number,
	b.transactionid,
	a.order_date, 
	a.first_order_date, 
	a.order_type,
	a.first_order_revenue,
	a.lifetime_revenue,
	b.channel,
	b.platform,
	b.url,
	b.campaign,
	a.quantity,
	a.revenue,
	a.orders
	FROM customers_by_transaction a
	LEFT JOIN ga_transaction b
	ON (
	    a.store = b.store AND
	    a.order_number = b.transactionid
	)	
)
WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc)
  );

    
2018-07-30 12:50:03,774: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11007e550>]}
2018-07-30 12:50:04,602: 12:50:04 | 14 of 22 OK created table model template.agg_transactions............ [OK in 9.05s]
2018-07-30 12:50:04,603: 12:50:04 | 15 of 22 START table model template.monthly_cohort_stats............. [RUN]
2018-07-30 12:50:04,603: Compiling model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 12:50:04,603: 12:50:04 | 16 of 22 START table model template.customers_proc_qoq............... [RUN]
2018-07-30 12:50:04,603: 12:50:04 | 17 of 22 START table model template.customers_proc_yoy............... [RUN]
2018-07-30 12:50:04,611: Writing injected SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 12:50:04,611: Compiling model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 12:50:04,611: Compiling model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 12:50:04,628: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 12:50:04,630: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 12:50:04,634: Acquiring new bigquery connection "monthly_cohort_stats".
2018-07-30 12:50:04,635: Re-using an available connection from the pool.
2018-07-30 12:50:04,641: Acquiring new bigquery connection "customers_proc_qoq".
2018-07-30 12:50:04,644: Re-using an available connection from the pool.
2018-07-30 12:50:04,644: Acquiring new bigquery connection "customers_proc_yoy".
2018-07-30 12:50:04,648: Re-using an available connection from the pool.
2018-07-30 12:50:04,765: Writing runtime SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 12:50:04,783: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 12:50:04,796: Fetching data for query monthly_cohort_stats:
create or replace table `template`.`monthly_cohort_stats`
  
  as (
    WITH transactions AS (

  SELECT 
  store, 
  order_number,
  order_date,
  order_type,
  first_order_month,
  unix_date(order_date) d, 
  customer_id, 
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (

  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT 
date_in_range date,
store, 
order_type,
first_order_channel,
first_order_platform,
first_order_month,
channel,
platform,
url,
campaign,
count(distinct(customer_id)) buyers,
sum(orders) orders,
sum(quantity) quantity,
sum(revenue) revenue
FROM daterange
JOIN transactions
ON transactions.d >= daterange.unix_date_in_range_bom 
AND transactions.d <= daterange.unix_date_in_range
GROUP BY date, store, order_type, 
first_order_channel, first_order_platform, first_order_month, channel, platform, url, campaign
  );

    
2018-07-30 12:50:04,801: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 12:50:04,802: Fetching data for query customers_proc_yoy:
create or replace table `template`.`customers_proc_yoy`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 365 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 365 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 365 window_end_unix_date, 
    unix_date_in_range - 730 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 730 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 365 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 12:50:04,805: Fetching data for query customers_proc_qoq:
create or replace table `template`.`customers_proc_qoq`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 90 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 90 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 90 window_end_unix_date, 
    unix_date_in_range - 180 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 180 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 90 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 12:50:11,029: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cbe77b8>]}
2018-07-30 12:50:11,681: 12:50:11 | 15 of 22 OK created table model template.monthly_cohort_stats........ [OK in 6.43s]
2018-07-30 12:50:15,689: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cc9e390>]}
2018-07-30 12:50:16,175: 12:50:16 | 16 of 22 OK created table model template.customers_proc_qoq.......... [OK in 11.08s]
2018-07-30 12:50:29,706: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110083898>]}
2018-07-30 12:50:31,154: 12:50:31 | 17 of 22 OK created table model template.customers_proc_yoy.......... [OK in 25.09s]
2018-07-30 12:50:31,160: 12:50:31 | 18 of 22 START table model template.customers_proc................... [RUN]
2018-07-30 12:50:31,161: Compiling model.shopify_cohort_analysis.customers_proc
2018-07-30 12:50:31,185: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 12:50:31,194: Acquiring new bigquery connection "customers_proc".
2018-07-30 12:50:31,194: Re-using an available connection from the pool.
2018-07-30 12:50:31,943: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 12:50:31,944: Fetching data for query customers_proc:
create or replace table `template`.`customers_proc`
  
  as (
    SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_qoq`

UNION ALL

SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_yoy`
  );

    
2018-07-30 12:51:01,450: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110140f60>]}
2018-07-30 12:51:01,893: 12:51:01 | 18 of 22 OK created table model template.customers_proc.............. [OK in 30.29s]
2018-07-30 12:51:01,896: 12:51:01 | 19 of 22 START table model template.segment_proc_customers........... [RUN]
2018-07-30 12:51:01,896: Compiling model.shopify_cohort_analysis.segment_proc_customers
2018-07-30 12:51:01,918: Writing injected SQL for node "model.shopify_cohort_analysis.segment_proc_customers"
2018-07-30 12:51:01,926: Acquiring new bigquery connection "segment_proc_customers".
2018-07-30 12:51:01,926: Re-using an available connection from the pool.
2018-07-30 12:51:02,114: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_proc_customers"
2018-07-30 12:51:02,115: Fetching data for query segment_proc_customers:
create or replace table `template`.`segment_proc_customers`
  
  as (
    SELECT
store,
period,
customer_id,
date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct,
case when first_order_unix_date >= window_start_unix_date then 'New'
	else 'Existing' end as newness_segment,
case when revenue >= revenue_90pct then 'Whale'
	when revenue <= revenue_10pct then 'Minnow'
	else 'Bristlemouth' end as revenue_segment,
case when frequency = 1 then '1'
	when frequency = 2 then '2'
	when frequency > 2 then '3+'
	else null end as frequency_segment
FROM `growth-engines-pipeline`.`template`.`customers_proc`
  );

    
2018-07-30 12:51:31,245: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11018a668>]}
2018-07-30 12:51:32,112: 12:51:32 | 19 of 22 OK created table model template.segment_proc_customers...... [OK in 29.35s]
2018-07-30 12:51:32,114: 12:51:32 | 20 of 22 START table model template.segment_stats_customers_agg...... [RUN]
2018-07-30 12:51:32,114: Compiling model.shopify_cohort_analysis.segment_stats_customers_agg
2018-07-30 12:51:32,134: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_customers_agg"
2018-07-30 12:51:32,136: Acquiring new bigquery connection "segment_stats_customers_agg".
2018-07-30 12:51:32,137: Re-using an available connection from the pool.
2018-07-30 12:51:32,279: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_customers_agg"
2018-07-30 12:51:32,280: Fetching data for query segment_stats_customers_agg:
create or replace table `template`.`segment_stats_customers_agg`
  
  as (
    WITH ty as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Year'

),

this_month_1yr as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Previous Year'

),

this_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,	
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Quarter'

),

last_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev		
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Previous Quarter'

)

SELECT
store,
period,
date, 
customer_id,
1 as buyers,
first_order_channel,
first_order_platform,	
case when max(revenue_segment) != '' then max(revenue_segment) 
	when max(revenue_segment_prev) != '' then 'Dormant'
	else '' end as revenue_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(revenue_segment_prev) end as revenue_segment_prev,
case when max(frequency_segment) != '' then max(frequency_segment) 
	when max(frequency_segment_prev) != '' then 'Dormant'
	else '' end as frequency_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(frequency_segment_prev) end as frequency_segment_prev,
ifnull(sum(recency), 0) recency,
ifnull(sum(frequency), 0) frequency,
ifnull(sum(revenue), 0) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else 0 end as aov,
ifnull(sum(recency_prev), 0) recency_prev,
ifnull(sum(frequency_prev), 0) frequency_prev,
ifnull(sum(revenue_prev), 0) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else 0 end as aov_prev,
case when max(newness_segment_prev) != '' then 1 else 0 end as retention_eligible,
case when max(newness_segment_prev) != '' and max(newness_segment) != '' then 1 else 0 end as retention_success
FROM
(
	SELECT * FROM ty
	UNION ALL
	SELECT * FROM this_month_1yr
	UNION ALL
	SELECT * FROM this_quarter
	UNION ALL
	SELECT * FROM last_quarter

)
GROUP BY store, period, date, customer_id, first_order_channel, first_order_platform
  );

    
2018-07-30 12:51:58,434: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ffe7160>]}
2018-07-30 12:51:58,820: 12:51:58 | 20 of 22 OK created table model template.segment_stats_customers_agg. [OK in 26.32s]
2018-07-30 12:51:58,822: 12:51:58 | 21 of 22 START table model template.buyer_segment_stats.............. [RUN]
2018-07-30 12:51:58,822: Compiling model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 12:51:58,850: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 12:51:58,863: Acquiring new bigquery connection "buyer_segment_stats".
2018-07-30 12:51:58,863: Re-using an available connection from the pool.
2018-07-30 12:51:59,064: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 12:51:59,066: Fetching data for query buyer_segment_stats:
create or replace table `template`.`buyer_segment_stats`
  
  as (
    SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type
  );

    
2018-07-30 12:52:02,186: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11018a668>]}
2018-07-30 12:52:02,474: 12:52:02 | 21 of 22 OK created table model template.buyer_segment_stats......... [OK in 3.36s]
2018-07-30 12:52:02,475: 12:52:02 | 22 of 22 START table model template.buyer_segment_lists.............. [RUN]
2018-07-30 12:52:02,475: Compiling model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 12:52:02,488: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 12:52:02,492: Acquiring new bigquery connection "buyer_segment_lists".
2018-07-30 12:52:02,492: Re-using an available connection from the pool.
2018-07-30 12:52:02,631: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 12:52:02,632: Fetching data for query buyer_segment_lists:
create or replace table `template`.`buyer_segment_lists`
  
  as (
    SELECT
a.store,
period,
date,
customer_id,
b.first_name,
b.last_name,
b.email,
recency,
frequency,
revenue,
aov,
revenue_segment,
frequency_segment
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg` a
LEFT JOIN `growth-engines-pipeline`.`template`.`agg_customers` b
ON (
	a.store = b.store AND
	a.customer_id = b.id
)
where ( revenue_segment != '' or frequency_segment != '' )
  );

    
2018-07-30 12:52:35,672: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd3b49b-23ff-4d1b-b423-dbf88405b815', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ffe7160>]}
2018-07-30 12:52:37,111: 12:52:37 | 22 of 22 OK created table model template.buyer_segment_lists......... [OK in 33.20s]
2018-07-30 12:52:37,258: 12:52:37 | 
2018-07-30 12:52:37,258: 12:52:37 | Finished running 22 table models in 219.45s.
2018-07-30 12:52:37,259: Connection 'master' was left open.
2018-07-30 12:52:37,278: 
2018-07-30 12:52:37,282: Completed successfully
2018-07-30 12:52:37,282: 
Done. PASS=22 ERROR=0 SKIP=0 TOTAL=22
2018-07-30 12:52:37,301: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11001e518>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100b3ba8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100b30b8>]}
2018-07-30 12:52:37,645: Flushing usage events
2018-07-30 12:52:38,147: sys:1: ResourceWarning: unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 52530), raddr=('172.217.11.237', 443)>

2018-07-30 12:52:38,148: sys:1: ResourceWarning: unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 52529), raddr=('172.217.11.234', 443)>

2018-07-30 12:52:38,148: sys:1: ResourceWarning: unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 52526), raddr=('172.217.11.237', 443)>

2018-07-30 12:52:38,149: sys:1: ResourceWarning: unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 52531), raddr=('172.217.11.237', 443)>

2018-07-30 12:52:38,149: sys:1: ResourceWarning: unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 52537), raddr=('172.217.12.10', 443)>

2018-07-30 12:52:38,150: sys:1: ResourceWarning: unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 52535), raddr=('172.217.12.10', 443)>

2018-07-30 12:52:38,152: sys:1: ResourceWarning: unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 52532), raddr=('172.217.11.237', 443)>

2018-07-30 12:52:38,153: sys:1: ResourceWarning: unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 52533), raddr=('172.217.11.237', 443)>

2018-07-30 12:52:38,153: sys:1: ResourceWarning: unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 52534), raddr=('172.217.12.10', 443)>

2018-07-30 12:52:38,160: sys:1: ResourceWarning: unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.144', 52536), raddr=('172.217.12.10', 443)>

2018-07-30 13:36:33,354: Tracking: tracking
2018-07-30 13:36:33,357: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111ed0320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111ed0f60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111ed0278>]}
2018-07-30 13:36:35,078: Loading dependency project from /usr/local/Cellar/dbt/0.10.1/libexec/lib/python3.6/site-packages/dbt/include
2018-07-30 13:36:35,114: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/shopify-cohort-analysis/dbt_modules
2018-07-30 13:36:35,121: Parsing get_column_values.sql
2018-07-30 13:36:35,138: Parsing get_url_parameter.sql
2018-07-30 13:36:35,146: Parsing split_part.sql
2018-07-30 13:36:35,154: Parsing table_exists.sql
2018-07-30 13:36:35,167: Parsing core.sql
2018-07-30 13:36:35,191: Parsing adapters/bigquery.sql
2018-07-30 13:36:35,203: Parsing adapters/common.sql
2018-07-30 13:36:35,238: Parsing adapters/redshift.sql
2018-07-30 13:36:35,285: Parsing adapters/snowflake.sql
2018-07-30 13:36:35,292: Parsing etc/bigquery.sql
2018-07-30 13:36:35,297: Parsing etc/datetime.sql
2018-07-30 13:36:35,349: Parsing etc/get_custom_schema.sql
2018-07-30 13:36:35,360: Parsing materializations/helpers.sql
2018-07-30 13:36:35,391: Parsing materializations/archive/archive.sql
2018-07-30 13:36:35,462: Parsing materializations/incremental/incremental.sql
2018-07-30 13:36:35,519: Parsing materializations/seed/bigquery.sql
2018-07-30 13:36:35,528: Parsing materializations/seed/seed.sql
2018-07-30 13:36:35,588: Parsing materializations/table/bigquery_table.sql
2018-07-30 13:36:35,625: Parsing materializations/table/table.sql
2018-07-30 13:36:35,658: Parsing materializations/view/bigquery_view.sql
2018-07-30 13:36:35,677: Parsing materializations/view/view.sql
2018-07-30 13:36:35,707: Parsing schema_tests/accepted_values.sql
2018-07-30 13:36:35,714: Parsing schema_tests/not_null.sql
2018-07-30 13:36:35,719: Parsing schema_tests/relationships.sql
2018-07-30 13:36:35,724: Parsing schema_tests/unique.sql
2018-07-30 13:36:35,756: Parsing model.shopify_cohort_analysis.all_dates
2018-07-30 13:36:35,760: Parsing model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 13:36:35,762: Parsing model.shopify_cohort_analysis.monthend_dates
2018-07-30 13:36:35,766: Parsing model.shopify_cohort_analysis.stores_proc
2018-07-30 13:36:35,770: Parsing model.shopify_cohort_analysis.ga_transactions
2018-07-30 13:36:35,781: Parsing model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 13:36:35,790: Parsing model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 13:36:35,798: Parsing model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 13:36:35,809: Parsing model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 13:36:35,818: Parsing model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 13:36:35,826: Parsing model.shopify_cohort_analysis.agg_customers
2018-07-30 13:36:35,829: Parsing model.shopify_cohort_analysis.agg_transactions
2018-07-30 13:36:35,833: Parsing model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 13:36:35,836: Parsing model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 13:36:35,839: Parsing model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 13:36:35,844: Parsing model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 13:36:35,852: Parsing model.shopify_cohort_analysis.customers_proc
2018-07-30 13:36:35,857: Parsing model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 13:36:35,862: Parsing model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 13:36:35,867: Parsing model.shopify_cohort_analysis.segment_proc_customers
2018-07-30 13:36:35,871: Parsing model.shopify_cohort_analysis.segment_stats_customers_agg
2018-07-30 13:36:35,879: Parsing model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 13:36:35,899: Found 22 models, 0 tests, 0 archives, 0 analyses, 62 macros, 0 operations, 0 seed files
2018-07-30 13:36:35,905: 
2018-07-30 13:36:35,919: Acquiring new bigquery connection "master".
2018-07-30 13:36:35,920: Opening a new connection (0 currently allocated)
2018-07-30 13:36:37,321: 13:36:37 | Concurrency: 4 threads (target='template')
2018-07-30 13:36:37,322: 13:36:37 | 
2018-07-30 13:36:37,462: 13:36:37 | 1 of 22 START table model template.monthend_dates.................... [RUN]
2018-07-30 13:36:37,463: Compiling model.shopify_cohort_analysis.monthend_dates
2018-07-30 13:36:37,462: 13:36:37 | 2 of 22 START table model template.stores_proc....................... [RUN]
2018-07-30 13:36:37,462: 13:36:37 | 3 of 22 START table model template.mappings_ga_proc.................. [RUN]
2018-07-30 13:36:37,469: Compiling model.shopify_cohort_analysis.stores_proc
2018-07-30 13:36:37,473: Writing injected SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 13:36:37,463: 13:36:37 | 4 of 22 START table model template.all_dates......................... [RUN]
2018-07-30 13:36:37,475: Compiling model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 13:36:37,482: Writing injected SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 13:36:37,482: Compiling model.shopify_cohort_analysis.all_dates
2018-07-30 13:36:37,489: Writing injected SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 13:36:37,491: Acquiring new bigquery connection "monthend_dates".
2018-07-30 13:36:37,503: Opening a new connection (1 currently allocated)
2018-07-30 13:36:37,503: Acquiring new bigquery connection "stores_proc".
2018-07-30 13:36:37,500: Writing injected SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 13:36:37,506: Acquiring new bigquery connection "mappings_ga_proc".
2018-07-30 13:36:37,509: Opening a new connection (2 currently allocated)
2018-07-30 13:36:37,512: Acquiring new bigquery connection "all_dates".
2018-07-30 13:36:37,518: Opening a new connection (3 currently allocated)
2018-07-30 13:36:37,522: Opening a new connection (4 currently allocated)
2018-07-30 13:36:37,987: Writing runtime SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 13:36:37,995: Fetching data for query stores_proc:
create or replace table `template`.`stores_proc`
  
  as (
    select 
store,
store_name,
account,
platform,
max(time_of_entry) time_of_entry

from  ( 

SELECT  
client store,
client_name store_name,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.accounts` 
where client_name != ''

) 

WHERE lv = time_of_entry
group by store, store_name, account, platform
  );

    
2018-07-30 13:36:38,011: Writing runtime SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 13:36:38,012: Fetching data for query monthend_dates:
create or replace table `template`.`monthend_dates`
  
  as (
    SELECT
date_in_range,
date_in_range_bom,
date_in_range_bom_mom,
unix_date_in_range,
unix_date_in_range_bom,
unix_date(date_in_range_bom_mom) unix_date_in_range_bom_mom,
yyyymm,
date_in_range_yoy,
unix_date(date_in_range_yoy) unix_date_in_range_yoy

FROM
(
	SELECT 
	date_in_range,
	date_in_range_bom,
	date_sub(date_in_range_bom, INTERVAL 1 MONTH) date_in_range_bom_mom,
	date_sub(date_in_range, INTERVAL 1 YEAR) date_in_range_yoy,
	unix_date_in_range,
	unix_date(date_in_range_bom) unix_date_in_range_bom,
	yyyymm,
	first_value(date_in_range) over (partition by yyyymm order by date_in_range desc) monthend_date_in_range
	FROM
	( 
		SELECT 
		date_in_range,
		date_trunc( date_in_range, MONTH) date_in_range_bom,
		unix_date(date_in_range) unix_date_in_range,
		format_date("%Y-%m", date_in_range) AS yyyymm
		FROM UNNEST(
		    GENERATE_DATE_ARRAY(DATE('2016-01-31'), CURRENT_DATE(), INTERVAL 1 DAY)
		) AS date_in_range
	)
)
where date_in_range = monthend_date_in_range
  );

    
2018-07-30 13:36:38,063: Writing runtime SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 13:36:38,064: Fetching data for query all_dates:
create or replace table `template`.`all_dates`
  
  as (
    SELECT 
date_in_range,
unix_date(date_in_range) unix_date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
  );

    
2018-07-30 13:36:38,068: Writing runtime SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 13:36:38,070: Fetching data for query mappings_ga_proc:
create or replace table `template`.`mappings_ga_proc`
  
  as (
    select 
store,
account,
store_name,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client store,
account,
client_name store_name,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.mappings_ga` 

) 

WHERE lv = time_of_entry
group by store, account, store_name, source, medium, platform_n, channel_n, time_of_entry
  );

    
2018-07-30 13:36:39,719: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11205d400>]}
2018-07-30 13:36:39,731: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11205d4a8>]}
2018-07-30 13:36:39,746: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11205d240>]}
2018-07-30 13:36:39,749: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112016470>]}
2018-07-30 13:36:40,007: 13:36:40 | 1 of 22 OK created table model template.monthend_dates............... [OK in 2.26s]
2018-07-30 13:36:40,289: 13:36:40 | 2 of 22 OK created table model template.stores_proc.................. [OK in 2.26s]
2018-07-30 13:36:40,583: 13:36:40 | 3 of 22 OK created table model template.mappings_ga_proc............. [OK in 2.27s]
2018-07-30 13:36:40,878: 13:36:40 | 4 of 22 OK created table model template.all_dates.................... [OK in 2.27s]
2018-07-30 13:36:40,879: 13:36:40 | 5 of 22 START table model template.shopify_refunds_proc.............. [RUN]
2018-07-30 13:36:40,879: Compiling model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 13:36:40,879: 13:36:40 | 6 of 22 START table model template.shopify_discounts_proc............ [RUN]
2018-07-30 13:36:40,885: Compiling model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 13:36:40,899: Acquiring new bigquery connection "shopify_refunds_proc".
2018-07-30 13:36:40,885: 13:36:40 | 7 of 22 START table model template.shopify_customers_proc............ [RUN]
2018-07-30 13:36:40,901: Acquiring new bigquery connection "shopify_discounts_proc".
2018-07-30 13:36:40,901: Re-using an available connection from the pool.
2018-07-30 13:36:40,901: Compiling model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 13:36:40,901: Fetching data for query shopify_refunds_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 13:36:40,901: Re-using an available connection from the pool.
2018-07-30 13:36:40,911: Acquiring new bigquery connection "shopify_customers_proc".
2018-07-30 13:36:40,911: Fetching data for query shopify_discounts_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 13:36:40,911: Re-using an available connection from the pool.
2018-07-30 13:36:40,913: Fetching data for query shopify_customers_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 13:36:42,465: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 13:36:42,605: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 13:36:42,771: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 13:36:42,940: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 13:36:42,941: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 13:36:42,943: Fetching data for query shopify_customers_proc:
create or replace table `template`.`shopify_customers_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`





with customers as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	created_at,
	id,
	first_name,
	last_name,
	email,
	_sdc_sequence,
	first_value(_sdc_sequence) over (partition by id order by _sdc_sequence desc) lv
	FROM `growth-engines-pipeline.shopify_lucadanni.customers` 
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
id,
first_name,
last_name,
email
FROM customers a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence


  );

    
2018-07-30 13:36:42,946: Fetching data for query shopify_refunds_proc:
create or replace table `template`.`shopify_refunds_proc`
  
  as (
    



with refunds as (

	
	SELECT
	'lucadanni' store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal,
	line_item.variant_id variant_id,
	line_item.id refund_id,
 	_sdc_sequence
	FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
	cross join unnest(refunds), unnest(refund_line_items)
  	where financial_status like '%refund%'
	
	

)

SELECT * 
FROM 
	(
    SELECT
    store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal refund_amount,
	variant_id,
	refund_id,
 	_sdc_sequence,
    first_value(_sdc_sequence) OVER (PARTITION BY order_number, line_item_id ORDER BY _sdc_sequence DESC) lv
    FROM refunds
   	) 
WHERE lv = _sdc_sequence


  );

    
2018-07-30 13:36:43,063: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 13:36:43,063: Fetching data for query shopify_discounts_proc:
create or replace table `template`.`shopify_discounts_proc`
  
  as (
    



with orders as (

	
		SELECT
		'lucadanni' store_name,
		created_at,
		order_number,
		code discount_code,
		type discount_type,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(discount_codes)
		where source_name != 'shopify_draft_order'
	
	
	

)

SELECT
store_name,
order_number,
discount_code,
discount_type
FROM orders
where lv = _sdc_sequence


  );

    
2018-07-30 13:36:45,099: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112016160>]}
2018-07-30 13:36:45,187: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112160ef0>]}
2018-07-30 13:36:45,410: 13:36:45 | 5 of 22 OK created table model template.shopify_refunds_proc......... [OK in 4.22s]
2018-07-30 13:36:45,795: 13:36:45 | 6 of 22 OK created table model template.shopify_discounts_proc....... [OK in 4.30s]
2018-07-30 13:36:48,344: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112035860>]}
2018-07-30 13:36:48,880: 13:36:48 | 7 of 22 OK created table model template.shopify_customers_proc....... [OK in 7.44s]
2018-07-30 13:36:48,881: 13:36:48 | 8 of 22 START table model template.ga_transactions................... [RUN]
2018-07-30 13:36:48,881: Compiling model.shopify_cohort_analysis.ga_transactions
2018-07-30 13:36:48,881: 13:36:48 | 9 of 22 START table model template.agg_customers..................... [RUN]
2018-07-30 13:36:48,881: 13:36:48 | 10 of 22 START table model template.shopify_products_proc............ [RUN]
2018-07-30 13:36:48,883: Compiling model.shopify_cohort_analysis.agg_customers
2018-07-30 13:36:48,897: Compiling model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 13:36:48,902: Acquiring new bigquery connection "ga_transactions".
2018-07-30 13:36:48,912: Writing injected SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 13:36:48,930: Acquiring new bigquery connection "shopify_products_proc".
2018-07-30 13:36:48,932: Acquiring new bigquery connection "agg_customers".
2018-07-30 13:36:48,933: Re-using an available connection from the pool.
2018-07-30 13:36:48,933: Fetching data for query ga_transactions:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Google Analytics'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 13:36:48,933: Re-using an available connection from the pool.
2018-07-30 13:36:48,934: Fetching data for query shopify_products_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 13:36:48,934: Re-using an available connection from the pool.
2018-07-30 13:36:49,073: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 13:36:49,077: Fetching data for query agg_customers:
create or replace table `template`.`agg_customers`
  
  as (
    SELECT 
account,
store,
id,
created_at,
first_name,
last_name,
email,
split(email,'@')[SAFE_ORDINAL(2)] email_domain
FROM
`growth-engines-pipeline`.`template`.`shopify_customers_proc`
  );

    
2018-07-30 13:36:49,619: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 13:36:49,770: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 13:36:49,771: Fetching data for query shopify_products_proc:
create or replace table `template`.`shopify_products_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`





with products as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	product_name,
	lower(product_type) product_type,
	product_id,
	sku,
	id variant_id,
	cast(created_at as date) created_at,
	_sdc_sequence,
	first_value(_sdc_sequence) OVER (PARTITION BY product_id ORDER BY _sdc_sequence DESC) lv
	FROM (
		SELECT
		variants,
		product_type,
		title product_name,
		_sdc_sequence
		FROM `growth-engines-pipeline.shopify_lucadanni.products` 
		)
	cross join unnest(variants)
	
	

)

SELECT
b.account,
b.store,
b.platform,
max(product_type) product_type,
product_id,
variant_id,
sku,
created_at,
product_name
FROM products a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence
group by product_id, account, store, platform, sku, variant_id, created_at, product_name


  );

    
2018-07-30 13:36:50,522: Writing injected SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 13:36:50,685: Writing runtime SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 13:36:50,685: Fetching data for query ga_transactions:
create or replace table `template`.`ga_transactions`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`,`growth-engines-pipeline`.`template`.`mappings_ga_proc`




with ga_report as (

	    
	    	
		   	SELECT
		   	'yandy' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_yandy.report` 

		     UNION ALL 
	   
	    	
		   	SELECT
		   	'lucadanni' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_lucadanni.report` 

		    
	   

)


SELECT  
date,
b.store store,
c.source source,
c.medium medium,
a.campaign campaign,
concat(a.source, ' / ', a.medium) source_medium,  
case when c.platform is null then "Unmapped" else c.platform end as platform,
case when c.channel is null then "Unmapped" else c.channel end as channel,
url,
transactionid
FROM (

	SELECT 
	store_name,
	lookup_platform,
	date,
	transactionid,
	max(url) url,
	max(source) source,
	max(medium) medium,
	max(campaign) campaign
	FROM ga_report
	where lv = _sdc_sequence
	group by store_name, lookup_platform, date, transactionid

) a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name 
	AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`mappings_ga_proc` c
ON ( a.source = c.source
  AND a.medium = c.medium 
  AND a.store_name = c.store_name )


  );

    
2018-07-30 13:36:52,036: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120adac8>]}
2018-07-30 13:36:52,820: 13:36:52 | 10 of 22 OK created table model template.shopify_products_proc....... [OK in 3.14s]
2018-07-30 13:36:54,105: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112181d30>]}
2018-07-30 13:36:54,404: 13:36:54 | 9 of 22 OK created table model template.agg_customers................ [OK in 5.22s]
2018-07-30 13:37:13,869: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112098358>]}
2018-07-30 13:37:14,177: 13:37:14 | 8 of 22 OK created table model template.ga_transactions.............. [OK in 24.99s]
2018-07-30 13:37:14,178: 13:37:14 | 11 of 22 START table model template.shopify_orders_proc.............. [RUN]
2018-07-30 13:37:14,179: Compiling model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 13:37:14,194: Acquiring new bigquery connection "shopify_orders_proc".
2018-07-30 13:37:14,194: Re-using an available connection from the pool.
2018-07-30 13:37:14,195: Fetching data for query shopify_orders_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 13:37:14,943: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 13:37:15,090: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 13:37:15,091: Fetching data for query shopify_orders_proc:
create or replace table `template`.`shopify_orders_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`, `growth-engines-pipeline`.`template`.`shopify_discounts_proc`





with orders as (

	
	SELECT 
	store_name,
	lookup_platform,
	created_at,
	order_number,
	quantity,
	price, 
	total_order_price_undiscounted,
	total_discounts,
	total_order_shipping_price,
	total_order_price_incl_shipping,
	checkout_id,
	product_id, 
	landing_site,
	sku, 
	variant_title, 
	variant_id,
	line_item_id,
	customer_id,
	_sdc_sequence,
	lv
	FROM (

		SELECT
		'lucadanni' store_name,
		'Shopify' as lookup_platform,
		created_at,
		order_number,
		quantity,
		cast(pre_tax_price as float64) price, 
		total_line_items_price total_order_price_undiscounted,
		total_discounts,
		cast(discounted_price as float64) total_order_shipping_price,
		total_price_usd total_order_price_incl_shipping,
		checkout_id,
		product_id, 
		landing_site,
		sku, 
		variant_title, 
		variant_id,
		_id line_item_id,
		customer.id customer_id,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(line_items), unnest(shipping_lines)
		where source_name != 'shopify_draft_order'
	)
	
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
a.order_number,
a.quantity prelim_quantity,
c.quantity refund_quantity,
case when c.quantity is not null then a.quantity - c.quantity else a.quantity end as quantity,
price prelim_revenue, 
total_order_price_undiscounted,
total_discounts,
trim(lower(d.discount_code)) discount_code,
d.discount_type,
total_order_shipping_price,
total_order_price_incl_shipping,
refund_amount,
case when refund_amount is not null then price - refund_amount else price end as revenue,
a.checkout_id,
a.product_id, 
landing_site,
sku, 
variant_title, 
a.variant_id,
a.line_item_id,	
customer_id
FROM orders a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_refunds_proc` c
ON ( a.order_number = c.order_number
	AND a.line_item_id = c.line_item_id
	AND a.store_name = c.store_name )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_discounts_proc` d
ON ( a.order_number = d.order_number 
    AND a.store_name = d.store_name )  	
where a.lv = a._sdc_sequence


  );

    
2018-07-30 13:37:26,083: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112035860>]}
2018-07-30 13:37:26,391: 13:37:26 | 11 of 22 OK created table model template.shopify_orders_proc......... [OK in 11.90s]
2018-07-30 13:37:26,392: 13:37:26 | 12 of 22 START table model template.transaction_by_order_number...... [RUN]
2018-07-30 13:37:26,392: Compiling model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 13:37:26,404: Writing injected SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 13:37:26,405: Acquiring new bigquery connection "transaction_by_order_number".
2018-07-30 13:37:26,405: Re-using an available connection from the pool.
2018-07-30 13:37:26,521: Writing runtime SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 13:37:26,523: Fetching data for query transaction_by_order_number:
create or replace table `template`.`transaction_by_order_number`
  
  as (
    SELECT
store,
cast(created_at as date) order_date,
order_number,
customer_id,
sum(quantity) quantity,
sum(revenue) revenue,
max(total_order_shipping_price) shipping_price
FROM
`growth-engines-pipeline`.`template`.`shopify_orders_proc`
GROUP BY store, order_date, order_number, customer_id
  );

    
2018-07-30 13:37:31,303: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112098358>]}
2018-07-30 13:37:31,878: 13:37:31 | 12 of 22 OK created table model template.transaction_by_order_number. [OK in 4.91s]
2018-07-30 13:37:31,879: 13:37:31 | 13 of 22 START table model template.customers_by_transaction......... [RUN]
2018-07-30 13:37:31,879: Compiling model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 13:37:31,886: Writing injected SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 13:37:31,890: Acquiring new bigquery connection "customers_by_transaction".
2018-07-30 13:37:31,891: Re-using an available connection from the pool.
2018-07-30 13:37:32,014: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 13:37:32,015: Fetching data for query customers_by_transaction:
create or replace table `template`.`customers_by_transaction`
  
  as (
    SELECT
store,
customer_id,
order_number,
order_date,
recent_order_date,
first_order_date,
case when first_order_number = order_number then 'New'
	when date_diff(order_date, recent_order_date, DAY) <= 365 then 'Repeat'
	when date_diff(order_date, recent_order_date, DAY) > 365 then 'Reactivated'
 else '' end as order_type,
quantity,
revenue,
1 as orders,
first_order_revenue,
lifetime_revenue
FROM

(

	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	quantity,
	revenue,
	lag(order_date) over w1 recent_order_date,
	first_value(order_date) over w1 first_order_date,
	first_value(order_number) over w1 first_order_number,
	first_value(revenue) over w1 first_order_revenue,
	sum(revenue) over w2 lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`transaction_by_order_number`
	WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc),
	w2 as (PARTITION BY store, customer_id)
)
  );

    
2018-07-30 13:37:37,090: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112160438>]}
2018-07-30 13:37:38,730: 13:37:38 | 13 of 22 OK created table model template.customers_by_transaction.... [OK in 5.21s]
2018-07-30 13:37:38,731: 13:37:38 | 14 of 22 START table model template.agg_transactions................. [RUN]
2018-07-30 13:37:38,731: Compiling model.shopify_cohort_analysis.agg_transactions
2018-07-30 13:37:38,744: Writing injected SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 13:37:38,747: Acquiring new bigquery connection "agg_transactions".
2018-07-30 13:37:38,747: Re-using an available connection from the pool.
2018-07-30 13:37:38,893: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 13:37:38,893: Fetching data for query agg_transactions:
create or replace table `template`.`agg_transactions`
  
  as (
    with ga_transaction as (

	SELECT
	date, 
	store,
	transactionid,
	channel,
	platform,
	url,
	campaign
	FROM `growth-engines-pipeline`.`template`.`ga_transactions`
),

customers_by_transaction as (
	
	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	first_order_date,
	recent_order_date,
	order_type,
	quantity,
	revenue,
	orders,
	first_order_revenue,
	lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`customers_by_transaction`
)

SELECT
store,
customer_id,
order_number,
transactionid,
order_date,
first_order_date,
format_date("%Y-%m", first_order_date) AS first_order_month,
order_type,
first_order_revenue,
lifetime_revenue,
first_value(channel) over w1 as first_order_channel,
first_value(platform) over w1 as first_order_platform,
channel,
platform,
url,
campaign,
quantity,
revenue,
orders
FROM (

	SELECT
	a.store,
	a.customer_id,
	a.order_number,
	b.transactionid,
	a.order_date, 
	a.first_order_date, 
	a.order_type,
	a.first_order_revenue,
	a.lifetime_revenue,
	b.channel,
	b.platform,
	b.url,
	b.campaign,
	a.quantity,
	a.revenue,
	a.orders
	FROM customers_by_transaction a
	LEFT JOIN ga_transaction b
	ON (
	    a.store = b.store AND
	    a.order_number = b.transactionid
	)	
)
WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc)
  );

    
2018-07-30 13:37:46,824: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112098358>]}
2018-07-30 13:37:47,127: 13:37:47 | 14 of 22 OK created table model template.agg_transactions............ [OK in 8.09s]
2018-07-30 13:37:47,128: 13:37:47 | 15 of 22 START table model template.customers_proc_yoy............... [RUN]
2018-07-30 13:37:47,128: Compiling model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 13:37:47,128: 13:37:47 | 16 of 22 START table model template.monthly_cohort_stats............. [RUN]
2018-07-30 13:37:47,128: 13:37:47 | 17 of 22 START table model template.customers_proc_qoq............... [RUN]
2018-07-30 13:37:47,137: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 13:37:47,138: Compiling model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 13:37:47,138: Compiling model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 13:37:47,144: Writing injected SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 13:37:47,154: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 13:37:47,158: Acquiring new bigquery connection "customers_proc_yoy".
2018-07-30 13:37:47,161: Acquiring new bigquery connection "monthly_cohort_stats".
2018-07-30 13:37:47,164: Re-using an available connection from the pool.
2018-07-30 13:37:47,164: Acquiring new bigquery connection "customers_proc_qoq".
2018-07-30 13:37:47,165: Re-using an available connection from the pool.
2018-07-30 13:37:47,167: Re-using an available connection from the pool.
2018-07-30 13:37:47,298: Writing runtime SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 13:37:47,299: Fetching data for query monthly_cohort_stats:
create or replace table `template`.`monthly_cohort_stats`
  
  as (
    WITH transactions AS (

  SELECT 
  store, 
  order_number,
  order_date,
  order_type,
  first_order_month,
  unix_date(order_date) d, 
  customer_id, 
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (

  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT 
date_in_range date,
store, 
order_type,
first_order_channel,
first_order_platform,
first_order_month,
channel,
platform,
url,
campaign,
count(distinct(customer_id)) buyers,
sum(orders) orders,
sum(quantity) quantity,
sum(revenue) revenue
FROM daterange
JOIN transactions
ON transactions.d >= daterange.unix_date_in_range_bom 
AND transactions.d <= daterange.unix_date_in_range
GROUP BY date, store, order_type, 
first_order_channel, first_order_platform, first_order_month, channel, platform, url, campaign
  );

    
2018-07-30 13:37:47,391: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 13:37:47,415: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 13:37:47,415: Fetching data for query customers_proc_qoq:
create or replace table `template`.`customers_proc_qoq`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 90 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 90 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 90 window_end_unix_date, 
    unix_date_in_range - 180 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 180 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 90 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 13:37:47,416: Fetching data for query customers_proc_yoy:
create or replace table `template`.`customers_proc_yoy`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 365 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 365 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 365 window_end_unix_date, 
    unix_date_in_range - 730 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 730 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 365 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 13:37:51,608: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112016748>]}
2018-07-30 13:37:51,913: 13:37:51 | 16 of 22 OK created table model template.monthly_cohort_stats........ [OK in 4.47s]
2018-07-30 13:37:59,235: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120e8ef0>]}
2018-07-30 13:38:00,023: 13:38:00 | 17 of 22 OK created table model template.customers_proc_qoq.......... [OK in 12.10s]
2018-07-30 13:38:09,500: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112160438>]}
2018-07-30 13:38:09,895: 13:38:09 | 15 of 22 OK created table model template.customers_proc_yoy.......... [OK in 22.37s]
2018-07-30 13:38:09,896: 13:38:09 | 18 of 22 START table model template.customers_proc................... [RUN]
2018-07-30 13:38:09,896: Compiling model.shopify_cohort_analysis.customers_proc
2018-07-30 13:38:09,907: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 13:38:09,909: Acquiring new bigquery connection "customers_proc".
2018-07-30 13:38:09,909: Re-using an available connection from the pool.
2018-07-30 13:38:10,056: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 13:38:10,057: Fetching data for query customers_proc:
create or replace table `template`.`customers_proc`
  
  as (
    SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_qoq`

UNION ALL

SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_yoy`
  );

    
2018-07-30 13:38:34,245: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112098358>]}
2018-07-30 13:38:34,546: 13:38:34 | 18 of 22 OK created table model template.customers_proc.............. [OK in 24.35s]
2018-07-30 13:38:34,547: 13:38:34 | 19 of 22 START table model template.segment_proc_customers........... [RUN]
2018-07-30 13:38:34,547: Compiling model.shopify_cohort_analysis.segment_proc_customers
2018-07-30 13:38:34,556: Writing injected SQL for node "model.shopify_cohort_analysis.segment_proc_customers"
2018-07-30 13:38:34,560: Acquiring new bigquery connection "segment_proc_customers".
2018-07-30 13:38:34,561: Re-using an available connection from the pool.
2018-07-30 13:38:34,794: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_proc_customers"
2018-07-30 13:38:34,794: Fetching data for query segment_proc_customers:
create or replace table `template`.`segment_proc_customers`
  
  as (
    SELECT
store,
period,
customer_id,
date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct,
case when first_order_unix_date >= window_start_unix_date then 'New'
	else 'Existing' end as newness_segment,
case when revenue >= revenue_90pct then 'Top 10%'
	when revenue <= revenue_10pct then 'Bottom 10%'
	else 'Middle 80%' end as revenue_segment,
case when frequency = 1 then '1'
	when frequency = 2 then '2'
	when frequency > 2 then '3+'
	else null end as frequency_segment
FROM `growth-engines-pipeline`.`template`.`customers_proc`
  );

    
2018-07-30 13:39:03,843: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120202b0>]}
2018-07-30 13:39:05,300: 13:39:05 | 19 of 22 OK created table model template.segment_proc_customers...... [OK in 29.30s]
2018-07-30 13:39:05,301: 13:39:05 | 20 of 22 START table model template.segment_stats_customers_agg...... [RUN]
2018-07-30 13:39:05,301: Compiling model.shopify_cohort_analysis.segment_stats_customers_agg
2018-07-30 13:39:05,310: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_customers_agg"
2018-07-30 13:39:05,311: Acquiring new bigquery connection "segment_stats_customers_agg".
2018-07-30 13:39:05,312: Re-using an available connection from the pool.
2018-07-30 13:39:05,934: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_customers_agg"
2018-07-30 13:39:05,935: Fetching data for query segment_stats_customers_agg:
create or replace table `template`.`segment_stats_customers_agg`
  
  as (
    WITH ty as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Year'

),

this_month_1yr as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Previous Year'

),

this_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,	
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Quarter'

),

last_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev		
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Previous Quarter'

)

SELECT
store,
period,
date, 
customer_id,
1 as buyers,
first_order_channel,
first_order_platform,	
case when max(revenue_segment) != '' then max(revenue_segment) 
	when max(revenue_segment_prev) != '' then 'Dormant'
	else '' end as revenue_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(revenue_segment_prev) end as revenue_segment_prev,
case when max(frequency_segment) != '' then max(frequency_segment) 
	when max(frequency_segment_prev) != '' then 'Dormant'
	else '' end as frequency_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(frequency_segment_prev) end as frequency_segment_prev,
ifnull(sum(recency), 0) recency,
ifnull(sum(frequency), 0) frequency,
ifnull(sum(revenue), 0) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else 0 end as aov,
ifnull(sum(recency_prev), 0) recency_prev,
ifnull(sum(frequency_prev), 0) frequency_prev,
ifnull(sum(revenue_prev), 0) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else 0 end as aov_prev,
case when max(newness_segment_prev) != '' then 1 else 0 end as retention_eligible,
case when max(newness_segment_prev) != '' and max(newness_segment) != '' then 1 else 0 end as retention_success
FROM
(
	SELECT * FROM ty
	UNION ALL
	SELECT * FROM this_month_1yr
	UNION ALL
	SELECT * FROM this_quarter
	UNION ALL
	SELECT * FROM last_quarter

)
GROUP BY store, period, date, customer_id, first_order_channel, first_order_platform
  );

    
2018-07-30 13:39:32,996: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112020240>]}
2018-07-30 13:39:33,652: 13:39:33 | 20 of 22 OK created table model template.segment_stats_customers_agg. [OK in 27.70s]
2018-07-30 13:39:33,653: 13:39:33 | 21 of 22 START table model template.buyer_segment_stats.............. [RUN]
2018-07-30 13:39:33,653: Compiling model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 13:39:33,664: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 13:39:33,669: Acquiring new bigquery connection "buyer_segment_stats".
2018-07-30 13:39:33,669: Re-using an available connection from the pool.
2018-07-30 13:39:33,954: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 13:39:33,954: Fetching data for query buyer_segment_stats:
create or replace table `template`.`buyer_segment_stats`
  
  as (
    SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type
  );

    
2018-07-30 13:39:37,156: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120abdd8>]}
2018-07-30 13:39:37,462: 13:39:37 | 21 of 22 OK created table model template.buyer_segment_stats......... [OK in 3.50s]
2018-07-30 13:39:37,463: 13:39:37 | 22 of 22 START table model template.buyer_segment_lists.............. [RUN]
2018-07-30 13:39:37,463: Compiling model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 13:39:37,471: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 13:39:37,472: Acquiring new bigquery connection "buyer_segment_lists".
2018-07-30 13:39:37,473: Re-using an available connection from the pool.
2018-07-30 13:39:37,622: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 13:39:37,623: Fetching data for query buyer_segment_lists:
create or replace table `template`.`buyer_segment_lists`
  
  as (
    SELECT
a.store,
period,
date,
customer_id,
b.first_name,
b.last_name,
b.email,
recency,
frequency,
revenue,
aov,
revenue_segment,
frequency_segment
FROM `growth-engines-pipeline`.`template`.`segment_stats_customers_agg` a
LEFT JOIN `growth-engines-pipeline`.`template`.`agg_customers` b
ON (
	a.store = b.store AND
	a.customer_id = b.id
)
where ( revenue_segment != '' or frequency_segment != '' )
  );

    
2018-07-30 13:40:10,461: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf992ef0-c4b6-4e28-a4d6-ec8e4457a90d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f409c50>]}
2018-07-30 13:40:12,374: 13:40:12 | 22 of 22 OK created table model template.buyer_segment_lists......... [OK in 33.00s]
2018-07-30 13:40:12,394: 13:40:12 | 
2018-07-30 13:40:12,394: 13:40:12 | Finished running 22 table models in 216.49s.
2018-07-30 13:40:12,394: Connection 'master' was left open.
2018-07-30 13:40:12,395: 
2018-07-30 13:40:12,395: Completed successfully
2018-07-30 13:40:12,395: 
Done. PASS=22 ERROR=0 SKIP=0 TOTAL=22
2018-07-30 13:40:12,396: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11205dba8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f4253c8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f425e48>]}
2018-07-30 13:40:12,701: Flushing usage events
2018-07-30 13:40:12,850: sys:1: ResourceWarning: unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55334), raddr=('172.217.1.205', 443)>

2018-07-30 13:40:12,851: sys:1: ResourceWarning: unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55333), raddr=('172.217.12.10', 443)>

2018-07-30 13:40:12,852: sys:1: ResourceWarning: unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55332), raddr=('172.217.1.205', 443)>

2018-07-30 13:40:12,852: sys:1: ResourceWarning: unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55335), raddr=('172.217.1.205', 443)>

2018-07-30 13:40:12,852: sys:1: ResourceWarning: unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55336), raddr=('172.217.1.205', 443)>

2018-07-30 13:40:12,852: sys:1: ResourceWarning: unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55337), raddr=('172.217.1.205', 443)>

2018-07-30 13:40:12,853: sys:1: ResourceWarning: unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55339), raddr=('172.217.1.202', 443)>

2018-07-30 13:40:12,853: sys:1: ResourceWarning: unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55338), raddr=('172.217.1.202', 443)>

2018-07-30 13:40:12,853: sys:1: ResourceWarning: unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55340), raddr=('172.217.1.202', 443)>

2018-07-30 13:40:12,854: sys:1: ResourceWarning: unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55341), raddr=('172.217.1.202', 443)>

2018-07-30 13:41:01,227: Tracking: tracking
2018-07-30 13:41:01,229: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109f2f60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109f2b38>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109f2320>]}
2018-07-30 13:41:01,638: Loading dependency project from /usr/local/Cellar/dbt/0.10.1/libexec/lib/python3.6/site-packages/dbt/include
2018-07-30 13:41:01,676: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/shopify-cohort-analysis/dbt_modules
2018-07-30 13:41:01,683: Parsing get_column_values.sql
2018-07-30 13:41:01,704: Parsing get_url_parameter.sql
2018-07-30 13:41:01,713: Parsing split_part.sql
2018-07-30 13:41:01,722: Parsing table_exists.sql
2018-07-30 13:41:01,735: Parsing core.sql
2018-07-30 13:41:01,753: Parsing adapters/bigquery.sql
2018-07-30 13:41:01,763: Parsing adapters/common.sql
2018-07-30 13:41:01,791: Parsing adapters/redshift.sql
2018-07-30 13:41:01,819: Parsing adapters/snowflake.sql
2018-07-30 13:41:01,825: Parsing etc/bigquery.sql
2018-07-30 13:41:01,829: Parsing etc/datetime.sql
2018-07-30 13:41:01,891: Parsing etc/get_custom_schema.sql
2018-07-30 13:41:01,901: Parsing materializations/helpers.sql
2018-07-30 13:41:01,924: Parsing materializations/archive/archive.sql
2018-07-30 13:41:01,976: Parsing materializations/incremental/incremental.sql
2018-07-30 13:41:02,014: Parsing materializations/seed/bigquery.sql
2018-07-30 13:41:02,022: Parsing materializations/seed/seed.sql
2018-07-30 13:41:02,088: Parsing materializations/table/bigquery_table.sql
2018-07-30 13:41:02,122: Parsing materializations/table/table.sql
2018-07-30 13:41:02,150: Parsing materializations/view/bigquery_view.sql
2018-07-30 13:41:02,171: Parsing materializations/view/view.sql
2018-07-30 13:41:02,194: Parsing schema_tests/accepted_values.sql
2018-07-30 13:41:02,201: Parsing schema_tests/not_null.sql
2018-07-30 13:41:02,207: Parsing schema_tests/relationships.sql
2018-07-30 13:41:02,215: Parsing schema_tests/unique.sql
2018-07-30 13:41:02,245: Parsing model.shopify_cohort_analysis.all_dates
2018-07-30 13:41:02,248: Parsing model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 13:41:02,250: Parsing model.shopify_cohort_analysis.monthend_dates
2018-07-30 13:41:02,253: Parsing model.shopify_cohort_analysis.stores_proc
2018-07-30 13:41:02,255: Parsing model.shopify_cohort_analysis.ga_transactions
2018-07-30 13:41:02,266: Parsing model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 13:41:02,274: Parsing model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 13:41:02,287: Parsing model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 13:41:02,302: Parsing model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 13:41:02,314: Parsing model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 13:41:02,322: Parsing model.shopify_cohort_analysis.agg_customers
2018-07-30 13:41:02,325: Parsing model.shopify_cohort_analysis.agg_transactions
2018-07-30 13:41:02,330: Parsing model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 13:41:02,334: Parsing model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 13:41:02,339: Parsing model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 13:41:02,351: Parsing model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 13:41:02,368: Parsing model.shopify_cohort_analysis.customers_proc
2018-07-30 13:41:02,374: Parsing model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 13:41:02,382: Parsing model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 13:41:02,391: Parsing model.shopify_cohort_analysis.segment_proc_customers
2018-07-30 13:41:02,397: Parsing model.shopify_cohort_analysis.segment_stats_customers_agg
2018-07-30 13:41:02,407: Parsing model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 13:41:02,438: Found 22 models, 0 tests, 0 archives, 0 analyses, 62 macros, 0 operations, 0 seed files
2018-07-30 13:41:02,453: 
2018-07-30 13:41:02,497: Acquiring new bigquery connection "master".
2018-07-30 13:41:02,497: Opening a new connection (0 currently allocated)
2018-07-30 13:41:03,875: 13:41:03 | Concurrency: 4 threads (target='template')
2018-07-30 13:41:03,876: 13:41:03 | 
2018-07-30 13:41:04,016: 13:41:04 | 1 of 22 START table model template.mappings_ga_proc.................. [RUN]
2018-07-30 13:41:04,017: Compiling model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 13:41:04,017: 13:41:04 | 2 of 22 START table model template.all_dates......................... [RUN]
2018-07-30 13:41:04,026: Writing injected SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 13:41:04,026: Compiling model.shopify_cohort_analysis.all_dates
2018-07-30 13:41:04,017: 13:41:04 | 3 of 22 START table model template.monthend_dates.................... [RUN]
2018-07-30 13:41:04,017: 13:41:04 | 4 of 22 START table model template.stores_proc....................... [RUN]
2018-07-30 13:41:04,036: Writing injected SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 13:41:04,036: Compiling model.shopify_cohort_analysis.monthend_dates
2018-07-30 13:41:04,039: Acquiring new bigquery connection "mappings_ga_proc".
2018-07-30 13:41:04,039: Compiling model.shopify_cohort_analysis.stores_proc
2018-07-30 13:41:04,050: Writing injected SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 13:41:04,053: Acquiring new bigquery connection "all_dates".
2018-07-30 13:41:04,053: Opening a new connection (1 currently allocated)
2018-07-30 13:41:04,066: Writing injected SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 13:41:04,068: Opening a new connection (2 currently allocated)
2018-07-30 13:41:04,074: Acquiring new bigquery connection "monthend_dates".
2018-07-30 13:41:04,081: Acquiring new bigquery connection "stores_proc".
2018-07-30 13:41:04,090: Opening a new connection (3 currently allocated)
2018-07-30 13:41:04,100: Opening a new connection (4 currently allocated)
2018-07-30 13:41:04,939: Writing runtime SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 13:41:04,962: Fetching data for query mappings_ga_proc:
create or replace table `template`.`mappings_ga_proc`
  
  as (
    select 
store,
account,
store_name,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client store,
account,
client_name store_name,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.mappings_ga` 

) 

WHERE lv = time_of_entry
group by store, account, store_name, source, medium, platform_n, channel_n, time_of_entry
  );

    
2018-07-30 13:41:04,980: Writing runtime SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 13:41:05,009: Writing runtime SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 13:41:05,011: Fetching data for query all_dates:
create or replace table `template`.`all_dates`
  
  as (
    SELECT 
date_in_range,
unix_date(date_in_range) unix_date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
  );

    
2018-07-30 13:41:05,035: Writing runtime SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 13:41:05,037: Fetching data for query stores_proc:
create or replace table `template`.`stores_proc`
  
  as (
    select 
store,
store_name,
account,
platform,
max(time_of_entry) time_of_entry

from  ( 

SELECT  
client store,
client_name store_name,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.accounts` 
where client_name != ''

) 

WHERE lv = time_of_entry
group by store, store_name, account, platform
  );

    
2018-07-30 13:41:05,039: Fetching data for query monthend_dates:
create or replace table `template`.`monthend_dates`
  
  as (
    SELECT
date_in_range,
date_in_range_bom,
date_in_range_bom_mom,
unix_date_in_range,
unix_date_in_range_bom,
unix_date(date_in_range_bom_mom) unix_date_in_range_bom_mom,
yyyymm,
date_in_range_yoy,
unix_date(date_in_range_yoy) unix_date_in_range_yoy

FROM
(
	SELECT 
	date_in_range,
	date_in_range_bom,
	date_sub(date_in_range_bom, INTERVAL 1 MONTH) date_in_range_bom_mom,
	date_sub(date_in_range, INTERVAL 1 YEAR) date_in_range_yoy,
	unix_date_in_range,
	unix_date(date_in_range_bom) unix_date_in_range_bom,
	yyyymm,
	first_value(date_in_range) over (partition by yyyymm order by date_in_range desc) monthend_date_in_range
	FROM
	( 
		SELECT 
		date_in_range,
		date_trunc( date_in_range, MONTH) date_in_range_bom,
		unix_date(date_in_range) unix_date_in_range,
		format_date("%Y-%m", date_in_range) AS yyyymm
		FROM UNNEST(
		    GENERATE_DATE_ARRAY(DATE('2016-01-31'), CURRENT_DATE(), INTERVAL 1 DAY)
		) AS date_in_range
	)
)
where date_in_range = monthend_date_in_range
  );

    
2018-07-30 13:41:06,808: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ccbbc33b-fa88-49b0-a5f9-0d07a64bbbfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b82438>]}
2018-07-30 13:41:06,972: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ccbbc33b-fa88-49b0-a5f9-0d07a64bbbfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b34550>]}
2018-07-30 13:41:07,258: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ccbbc33b-fa88-49b0-a5f9-0d07a64bbbfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b82470>]}
2018-07-30 13:41:07,261: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ccbbc33b-fa88-49b0-a5f9-0d07a64bbbfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b82358>]}
2018-07-30 13:41:07,757: 13:41:07 | 2 of 22 OK created table model template.all_dates.................... [OK in 2.78s]
2018-07-30 13:41:08,552: 13:41:08 | 3 of 22 OK created table model template.monthend_dates............... [OK in 2.94s]
2018-07-30 13:41:09,120: 13:41:09 | 4 of 22 OK created table model template.stores_proc.................. [OK in 3.22s]
2018-07-30 13:41:09,405: 13:41:09 | 1 of 22 OK created table model template.mappings_ga_proc............. [OK in 3.24s]
2018-07-30 13:41:09,406: 13:41:09 | 5 of 22 START table model template.shopify_discounts_proc............ [RUN]
2018-07-30 13:41:09,407: 13:41:09 | 6 of 22 START table model template.shopify_refunds_proc.............. [RUN]
2018-07-30 13:41:09,407: Compiling model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 13:41:09,407: 13:41:09 | 7 of 22 START table model template.shopify_customers_proc............ [RUN]
2018-07-30 13:41:09,407: Compiling model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 13:41:09,414: Compiling model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 13:41:09,422: Acquiring new bigquery connection "shopify_discounts_proc".
2018-07-30 13:41:09,430: Re-using an available connection from the pool.
2018-07-30 13:41:09,430: Fetching data for query shopify_discounts_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 13:41:09,433: Acquiring new bigquery connection "shopify_customers_proc".
2018-07-30 13:41:09,434: Re-using an available connection from the pool.
2018-07-30 13:41:09,434: Fetching data for query shopify_customers_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 13:41:09,447: Acquiring new bigquery connection "shopify_refunds_proc".
2018-07-30 13:41:09,447: Re-using an available connection from the pool.
2018-07-30 13:41:09,448: Fetching data for query shopify_refunds_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 13:41:10,934: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 13:41:11,059: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 13:41:11,062: Fetching data for query shopify_refunds_proc:
create or replace table `template`.`shopify_refunds_proc`
  
  as (
    



with refunds as (

	
	SELECT
	'lucadanni' store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal,
	line_item.variant_id variant_id,
	line_item.id refund_id,
 	_sdc_sequence
	FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
	cross join unnest(refunds), unnest(refund_line_items)
  	where financial_status like '%refund%'
	
	

)

SELECT * 
FROM 
	(
    SELECT
    store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal refund_amount,
	variant_id,
	refund_id,
 	_sdc_sequence,
    first_value(_sdc_sequence) OVER (PARTITION BY order_number, line_item_id ORDER BY _sdc_sequence DESC) lv
    FROM refunds
   	) 
WHERE lv = _sdc_sequence


  );

    
2018-07-30 13:41:11,154: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 13:41:11,208: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 13:41:11,283: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 13:41:11,284: Fetching data for query shopify_customers_proc:
create or replace table `template`.`shopify_customers_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`





with customers as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	created_at,
	id,
	first_name,
	last_name,
	email,
	_sdc_sequence,
	first_value(_sdc_sequence) over (partition by id order by _sdc_sequence desc) lv
	FROM `growth-engines-pipeline.shopify_lucadanni.customers` 
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
id,
first_name,
last_name,
email
FROM customers a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence


  );

    
2018-07-30 13:41:11,333: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 13:41:11,333: Fetching data for query shopify_discounts_proc:
create or replace table `template`.`shopify_discounts_proc`
  
  as (
    



with orders as (

	
		SELECT
		'lucadanni' store_name,
		created_at,
		order_number,
		code discount_code,
		type discount_type,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(discount_codes)
		where source_name != 'shopify_draft_order'
	
	
	

)

SELECT
store_name,
order_number,
discount_code,
discount_type
FROM orders
where lv = _sdc_sequence


  );

    
2018-07-30 13:41:13,244: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ccbbc33b-fa88-49b0-a5f9-0d07a64bbbfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c36710>]}
2018-07-30 13:41:13,526: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ccbbc33b-fa88-49b0-a5f9-0d07a64bbbfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c364a8>]}
2018-07-30 13:41:14,085: 13:41:14 | 6 of 22 OK created table model template.shopify_refunds_proc......... [OK in 3.84s]
2018-07-30 13:41:14,369: 13:41:14 | 5 of 22 OK created table model template.shopify_discounts_proc....... [OK in 4.12s]
2018-07-30 13:41:16,686: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ccbbc33b-fa88-49b0-a5f9-0d07a64bbbfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b34550>]}
2018-07-30 13:41:17,494: 13:41:17 | 7 of 22 OK created table model template.shopify_customers_proc....... [OK in 7.27s]
2018-07-30 13:41:17,495: 13:41:17 | 8 of 22 START table model template.agg_customers..................... [RUN]
2018-07-30 13:41:17,495: 13:41:17 | 9 of 22 START table model template.shopify_products_proc............. [RUN]
2018-07-30 13:41:17,496: Compiling model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 13:41:17,495: Compiling model.shopify_cohort_analysis.agg_customers
2018-07-30 13:41:17,495: 13:41:17 | 10 of 22 START table model template.ga_transactions.................. [RUN]
2018-07-30 13:41:17,508: Acquiring new bigquery connection "shopify_products_proc".
2018-07-30 13:41:17,509: Compiling model.shopify_cohort_analysis.ga_transactions
2018-07-30 13:41:17,509: Re-using an available connection from the pool.
2018-07-30 13:41:17,515: Writing injected SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 13:41:17,522: Fetching data for query shopify_products_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 13:41:17,524: Acquiring new bigquery connection "ga_transactions".
2018-07-30 13:41:17,526: Re-using an available connection from the pool.
2018-07-30 13:41:17,527: Fetching data for query ga_transactions:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Google Analytics'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 13:41:17,530: Acquiring new bigquery connection "agg_customers".
2018-07-30 13:41:17,530: Re-using an available connection from the pool.
2018-07-30 13:41:17,801: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 13:41:17,806: Fetching data for query agg_customers:
create or replace table `template`.`agg_customers`
  
  as (
    SELECT 
account,
store,
id,
created_at,
first_name,
last_name,
email,
split(email,'@')[SAFE_ORDINAL(2)] email_domain
FROM
`growth-engines-pipeline`.`template`.`shopify_customers_proc`
  );

    
2018-07-30 13:41:18,605: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 13:41:18,901: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 13:41:18,902: Fetching data for query shopify_products_proc:
create or replace table `template`.`shopify_products_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`





with products as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	product_name,
	lower(product_type) product_type,
	product_id,
	sku,
	id variant_id,
	cast(created_at as date) created_at,
	_sdc_sequence,
	first_value(_sdc_sequence) OVER (PARTITION BY product_id ORDER BY _sdc_sequence DESC) lv
	FROM (
		SELECT
		variants,
		product_type,
		title product_name,
		_sdc_sequence
		FROM `growth-engines-pipeline.shopify_lucadanni.products` 
		)
	cross join unnest(variants)
	
	

)

SELECT
b.account,
b.store,
b.platform,
max(product_type) product_type,
product_id,
variant_id,
sku,
created_at,
product_name
FROM products a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence
group by product_id, account, store, platform, sku, variant_id, created_at, product_name


  );

    
2018-07-30 13:41:19,242: Writing injected SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 13:41:19,385: Writing runtime SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 13:41:19,386: Fetching data for query ga_transactions:
create or replace table `template`.`ga_transactions`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`,`growth-engines-pipeline`.`template`.`mappings_ga_proc`




with ga_report as (

	    
	    	
		   	SELECT
		   	'yandy' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_yandy.report` 

		     UNION ALL 
	   
	    	
		   	SELECT
		   	'lucadanni' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_lucadanni.report` 

		    
	   

)


SELECT  
date,
b.store store,
c.source source,
c.medium medium,
a.campaign campaign,
concat(a.source, ' / ', a.medium) source_medium,  
case when c.platform is null then "Unmapped" else c.platform end as platform,
case when c.channel is null then "Unmapped" else c.channel end as channel,
url,
transactionid
FROM (

	SELECT 
	store_name,
	lookup_platform,
	date,
	transactionid,
	max(url) url,
	max(source) source,
	max(medium) medium,
	max(campaign) campaign
	FROM ga_report
	where lv = _sdc_sequence
	group by store_name, lookup_platform, date, transactionid

) a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name 
	AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`mappings_ga_proc` c
ON ( a.source = c.source
  AND a.medium = c.medium 
  AND a.store_name = c.store_name )


  );

    
2018-07-30 13:41:21,926: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ccbbc33b-fa88-49b0-a5f9-0d07a64bbbfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b8c7f0>]}
2018-07-30 13:41:22,214: 13:41:22 | 9 of 22 OK created table model template.shopify_products_proc........ [OK in 4.43s]
2018-07-30 13:41:22,553: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ccbbc33b-fa88-49b0-a5f9-0d07a64bbbfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c18e10>]}
2018-07-30 13:41:22,837: 13:41:22 | 8 of 22 OK created table model template.agg_customers................ [OK in 5.06s]
2018-07-30 13:41:46,337: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ccbbc33b-fa88-49b0-a5f9-0d07a64bbbfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c03eb8>]}
2018-07-30 13:41:46,850: 13:41:46 | 10 of 22 OK created table model template.ga_transactions............. [OK in 28.83s]
2018-07-30 13:41:46,851: 13:41:46 | 11 of 22 START table model template.shopify_orders_proc.............. [RUN]
2018-07-30 13:41:46,851: Compiling model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 13:41:46,865: Acquiring new bigquery connection "shopify_orders_proc".
2018-07-30 13:41:46,866: Re-using an available connection from the pool.
2018-07-30 13:41:46,866: Fetching data for query shopify_orders_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 13:41:47,589: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 13:41:47,729: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 13:41:47,730: Fetching data for query shopify_orders_proc:
create or replace table `template`.`shopify_orders_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`, `growth-engines-pipeline`.`template`.`shopify_discounts_proc`





with orders as (

	
	SELECT 
	store_name,
	lookup_platform,
	created_at,
	order_number,
	quantity,
	price, 
	total_order_price_undiscounted,
	total_discounts,
	total_order_shipping_price,
	total_order_price_incl_shipping,
	checkout_id,
	product_id, 
	landing_site,
	sku, 
	variant_title, 
	variant_id,
	line_item_id,
	customer_id,
	_sdc_sequence,
	lv
	FROM (

		SELECT
		'lucadanni' store_name,
		'Shopify' as lookup_platform,
		created_at,
		order_number,
		quantity,
		cast(pre_tax_price as float64) price, 
		total_line_items_price total_order_price_undiscounted,
		total_discounts,
		cast(discounted_price as float64) total_order_shipping_price,
		total_price_usd total_order_price_incl_shipping,
		checkout_id,
		product_id, 
		landing_site,
		sku, 
		variant_title, 
		variant_id,
		_id line_item_id,
		customer.id customer_id,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(line_items), unnest(shipping_lines)
		where source_name != 'shopify_draft_order'
	)
	
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
a.order_number,
a.quantity prelim_quantity,
c.quantity refund_quantity,
case when c.quantity is not null then a.quantity - c.quantity else a.quantity end as quantity,
price prelim_revenue, 
total_order_price_undiscounted,
total_discounts,
trim(lower(d.discount_code)) discount_code,
d.discount_type,
total_order_shipping_price,
total_order_price_incl_shipping,
refund_amount,
case when refund_amount is not null then price - refund_amount else price end as revenue,
a.checkout_id,
a.product_id, 
landing_site,
sku, 
variant_title, 
a.variant_id,
a.line_item_id,	
customer_id
FROM orders a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_refunds_proc` c
ON ( a.order_number = c.order_number
	AND a.line_item_id = c.line_item_id
	AND a.store_name = c.store_name )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_discounts_proc` d
ON ( a.order_number = d.order_number 
    AND a.store_name = d.store_name )  	
where a.lv = a._sdc_sequence


  );

    
2018-07-30 13:41:58,314: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ccbbc33b-fa88-49b0-a5f9-0d07a64bbbfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b34550>]}
2018-07-30 13:41:58,628: 13:41:58 | 11 of 22 OK created table model template.shopify_orders_proc......... [OK in 11.46s]
2018-07-30 13:41:58,628: 13:41:58 | 12 of 22 START table model template.transaction_by_order_number...... [RUN]
2018-07-30 13:41:58,629: Compiling model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 13:41:58,637: Writing injected SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 13:41:58,639: Acquiring new bigquery connection "transaction_by_order_number".
2018-07-30 13:41:58,639: Re-using an available connection from the pool.
2018-07-30 13:41:58,758: Writing runtime SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 13:41:58,759: Fetching data for query transaction_by_order_number:
create or replace table `template`.`transaction_by_order_number`
  
  as (
    SELECT
store,
cast(created_at as date) order_date,
order_number,
customer_id,
sum(quantity) quantity,
sum(revenue) revenue,
max(total_order_shipping_price) shipping_price
FROM
`growth-engines-pipeline`.`template`.`shopify_orders_proc`
GROUP BY store, order_date, order_number, customer_id
  );

    
2018-07-30 13:42:02,524: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ccbbc33b-fa88-49b0-a5f9-0d07a64bbbfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c18e10>]}
2018-07-30 13:42:03,381: 13:42:03 | 12 of 22 OK created table model template.transaction_by_order_number. [OK in 3.90s]
2018-07-30 13:42:03,382: 13:42:03 | 13 of 22 START table model template.customers_by_transaction......... [RUN]
2018-07-30 13:42:03,382: Compiling model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 13:42:03,392: Writing injected SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 13:42:03,393: Acquiring new bigquery connection "customers_by_transaction".
2018-07-30 13:42:03,394: Re-using an available connection from the pool.
2018-07-30 13:42:03,570: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 13:42:03,570: Fetching data for query customers_by_transaction:
create or replace table `template`.`customers_by_transaction`
  
  as (
    SELECT
store,
customer_id,
order_number,
order_date,
recent_order_date,
first_order_date,
case when first_order_number = order_number then 'New'
	when date_diff(order_date, recent_order_date, DAY) <= 365 then 'Repeat'
	when date_diff(order_date, recent_order_date, DAY) > 365 then 'Reactivated'
 else '' end as order_type,
quantity,
revenue,
1 as orders,
first_order_revenue,
lifetime_revenue
FROM

(

	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	quantity,
	revenue,
	lag(order_date) over w1 recent_order_date,
	first_value(order_date) over w1 first_order_date,
	first_value(order_number) over w1 first_order_number,
	first_value(revenue) over w1 first_order_revenue,
	sum(revenue) over w2 lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`transaction_by_order_number`
	WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc),
	w2 as (PARTITION BY store, customer_id)
)
  );

    
2018-07-30 13:42:07,710: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ccbbc33b-fa88-49b0-a5f9-0d07a64bbbfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b34550>]}
2018-07-30 13:42:08,008: 13:42:08 | 13 of 22 OK created table model template.customers_by_transaction.... [OK in 4.33s]
2018-07-30 13:42:08,008: 13:42:08 | 14 of 22 START table model template.agg_transactions................. [RUN]
2018-07-30 13:42:08,009: Compiling model.shopify_cohort_analysis.agg_transactions
2018-07-30 13:42:08,018: Writing injected SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 13:42:08,019: Acquiring new bigquery connection "agg_transactions".
2018-07-30 13:42:08,019: Re-using an available connection from the pool.
2018-07-30 13:42:08,143: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 13:42:08,147: Fetching data for query agg_transactions:
create or replace table `template`.`agg_transactions`
  
  as (
    with ga_transaction as (

	SELECT
	date, 
	store,
	transactionid,
	channel,
	platform,
	url,
	campaign
	FROM `growth-engines-pipeline`.`template`.`ga_transactions`
),

customers_by_transaction as (
	
	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	first_order_date,
	recent_order_date,
	order_type,
	quantity,
	revenue,
	orders,
	first_order_revenue,
	lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`customers_by_transaction`
)

SELECT
store,
customer_id,
order_number,
transactionid,
order_date,
first_order_date,
format_date("%Y-%m", first_order_date) AS first_order_month,
order_type,
first_order_revenue,
lifetime_revenue,
first_value(channel) over w1 as first_order_channel,
first_value(platform) over w1 as first_order_platform,
channel,
platform,
url,
campaign,
quantity,
revenue,
orders
FROM (

	SELECT
	a.store,
	a.customer_id,
	a.order_number,
	b.transactionid,
	a.order_date, 
	a.first_order_date, 
	a.order_type,
	a.first_order_revenue,
	a.lifetime_revenue,
	b.channel,
	b.platform,
	b.url,
	b.campaign,
	a.quantity,
	a.revenue,
	a.orders
	FROM customers_by_transaction a
	LEFT JOIN ga_transaction b
	ON (
	    a.store = b.store AND
	    a.order_number = b.transactionid
	)	
)
WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc)
  );

    
2018-07-30 13:42:16,882: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ccbbc33b-fa88-49b0-a5f9-0d07a64bbbfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c99b70>]}
2018-07-30 13:42:18,113: 13:42:18 | 14 of 22 OK created table model template.agg_transactions............ [OK in 8.87s]
2018-07-30 13:42:18,114: 13:42:18 | 15 of 22 START table model template.customers_proc_qoq............... [RUN]
2018-07-30 13:42:18,114: 13:42:18 | 16 of 22 START table model template.monthly_cohort_stats............. [RUN]
2018-07-30 13:42:18,115: Compiling model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 13:42:18,115: 13:42:18 | 17 of 22 START table model template.customers_proc_yoy............... [RUN]
2018-07-30 13:42:18,115: Compiling model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 13:42:18,123: Compiling model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 13:42:18,125: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 13:42:18,130: Writing injected SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 13:42:18,140: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 13:42:18,144: Acquiring new bigquery connection "customers_proc_yoy".
2018-07-30 13:42:18,144: Re-using an available connection from the pool.
2018-07-30 13:42:18,146: Acquiring new bigquery connection "customers_proc_qoq".
2018-07-30 13:42:18,146: Re-using an available connection from the pool.
2018-07-30 13:42:18,150: Acquiring new bigquery connection "monthly_cohort_stats".
2018-07-30 13:42:18,152: Re-using an available connection from the pool.
2018-07-30 13:42:18,308: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 13:42:18,338: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 13:42:18,347: Writing runtime SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 13:42:18,347: Fetching data for query monthly_cohort_stats:
create or replace table `template`.`monthly_cohort_stats`
  
  as (
    WITH transactions AS (

  SELECT 
  store, 
  order_number,
  order_date,
  order_type,
  first_order_month,
  unix_date(order_date) d, 
  customer_id, 
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (

  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT 
date_in_range date,
store, 
order_type,
first_order_channel,
first_order_platform,
first_order_month,
channel,
platform,
url,
campaign,
count(distinct(customer_id)) buyers,
sum(orders) orders,
sum(quantity) quantity,
sum(revenue) revenue
FROM daterange
JOIN transactions
ON transactions.d >= daterange.unix_date_in_range_bom 
AND transactions.d <= daterange.unix_date_in_range
GROUP BY date, store, order_type, 
first_order_channel, first_order_platform, first_order_month, channel, platform, url, campaign
  );

    
2018-07-30 13:42:18,354: Fetching data for query customers_proc_qoq:
create or replace table `template`.`customers_proc_qoq`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 90 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 90 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 90 window_end_unix_date, 
    unix_date_in_range - 180 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 180 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 90 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 13:42:18,355: Fetching data for query customers_proc_yoy:
create or replace table `template`.`customers_proc_yoy`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 365 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 365 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 365 window_end_unix_date, 
    unix_date_in_range - 730 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 730 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 365 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 13:42:24,327: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ccbbc33b-fa88-49b0-a5f9-0d07a64bbbfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b59da0>]}
2018-07-30 13:42:24,622: 13:42:24 | 16 of 22 OK created table model template.monthly_cohort_stats........ [OK in 6.21s]
2018-07-30 13:42:30,879: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ccbbc33b-fa88-49b0-a5f9-0d07a64bbbfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b34550>]}
2018-07-30 13:42:31,520: 13:42:31 | 15 of 22 OK created table model template.customers_proc_qoq.......... [OK in 12.76s]
2018-07-30 13:42:40,515: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ccbbc33b-fa88-49b0-a5f9-0d07a64bbbfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110bd4198>]}
2018-07-30 13:42:41,170: 13:42:41 | 17 of 22 OK created table model template.customers_proc_yoy.......... [OK in 22.39s]
2018-07-30 13:42:41,171: 13:42:41 | 18 of 22 START table model template.customers_proc................... [RUN]
2018-07-30 13:42:41,171: Compiling model.shopify_cohort_analysis.customers_proc
2018-07-30 13:42:41,179: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 13:42:41,180: Acquiring new bigquery connection "customers_proc".
2018-07-30 13:42:41,181: Re-using an available connection from the pool.
2018-07-30 13:42:41,468: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 13:42:41,468: Fetching data for query customers_proc:
create or replace table `template`.`customers_proc`
  
  as (
    SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_qoq`

UNION ALL

SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_yoy`
  );

    
2018-07-30 13:43:17,149: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ccbbc33b-fa88-49b0-a5f9-0d07a64bbbfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d739f60>]}
2018-07-30 13:43:17,518: 13:43:17 | 18 of 22 OK created table model template.customers_proc.............. [OK in 35.98s]
2018-07-30 13:43:17,519: 13:43:17 | 19 of 22 START table model template.segment_proc_customers........... [RUN]
2018-07-30 13:43:17,519: Compiling model.shopify_cohort_analysis.segment_proc_customers
2018-07-30 13:43:17,527: Writing injected SQL for node "model.shopify_cohort_analysis.segment_proc_customers"
2018-07-30 13:43:17,532: Acquiring new bigquery connection "segment_proc_customers".
2018-07-30 13:43:17,532: Re-using an available connection from the pool.
2018-07-30 13:43:17,706: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_proc_customers"
2018-07-30 13:43:17,707: Fetching data for query segment_proc_customers:
create or replace table `template`.`segment_proc_customers`
  
  as (
    SELECT
store,
period,
customer_id,
date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct,
case when first_order_unix_date >= window_start_unix_date then 'New'
	else 'Existing' end as newness_segment,
case when revenue >= revenue_90pct then 'Top 10%'
	when revenue <= revenue_10pct then 'Bottom 10%'
	else 'Middle 80%' end as revenue_segment,
case when frequency = 1 then '1'
	when frequency = 2 then '2'
	when frequency > 2 then '3+'
	else null end as frequency_segment
FROM `growth-engines-pipeline`.`template`.`customers_proc`
  );

    
2018-07-30 13:43:46,622: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ccbbc33b-fa88-49b0-a5f9-0d07a64bbbfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b2c780>]}
2018-07-30 13:43:47,928: 13:43:47 | 19 of 22 OK created table model template.segment_proc_customers...... [OK in 29.10s]
2018-07-30 13:43:47,929: 13:43:47 | 20 of 22 START table model template.segment_stats_customers_agg...... [RUN]
2018-07-30 13:43:47,930: Compiling model.shopify_cohort_analysis.segment_stats_customers_agg
2018-07-30 13:43:47,946: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_customers_agg"
2018-07-30 13:43:47,950: Acquiring new bigquery connection "segment_stats_customers_agg".
2018-07-30 13:43:47,950: Re-using an available connection from the pool.
2018-07-30 13:43:48,248: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_customers_agg"
2018-07-30 13:43:48,249: Fetching data for query segment_stats_customers_agg:
create or replace table `template`.`segment_stats_customers_agg`
  
  as (
    WITH ty as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Year'

),

this_month_1yr as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	'' as revenue_segment,
	'' as frequency_segment,
	'' as newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	revenue_segment as revenue_segment_prev,
	frequency_segment as frequency_segment_prev,
	newness_segment as newness_segment_prev,
	recency as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Previous Year'

),

this_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,	
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Quarter'

),

last_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	'' as revenue_segment,
	'' as frequency_segment,
	'' as newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	revenue_segment as revenue_segment_prev,
	frequency_segment as frequency_segment_prev,
	newness_segment as newness_segment_prev,
	recency as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev		
	FROM `growth-engines-pipeline`.`template`.`segment_proc_customers`
	WHERE period = 'Rolling Previous Quarter'

)

SELECT
store,
period,
date, 
customer_id,
1 as buyers,
first_order_channel,
first_order_platform,	
case when max(revenue_segment) != '' then max(revenue_segment) 
	when max(revenue_segment_prev) != '' then 'Dormant'
	else '' end as revenue_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(revenue_segment_prev) end as revenue_segment_prev,
case when max(frequency_segment) != '' then max(frequency_segment) 
	when max(frequency_segment_prev) != '' then 'Dormant'
	else '' end as frequency_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(frequency_segment_prev) end as frequency_segment_prev,
ifnull(sum(recency), 0) recency,
ifnull(sum(frequency), 0) frequency,
ifnull(sum(revenue), 0) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else 0 end as aov,
ifnull(sum(recency_prev), 0) recency_prev,
ifnull(sum(frequency_prev), 0) frequency_prev,
ifnull(sum(revenue_prev), 0) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else 0 end as aov_prev,
case when max(newness_segment_prev) != '' then 1 else 0 end as retention_eligible,
case when max(newness_segment_prev) != '' and max(newness_segment) != '' then 1 else 0 end as retention_success
FROM
(
	SELECT * FROM ty
	UNION ALL
	SELECT * FROM this_month_1yr
	UNION ALL
	SELECT * FROM this_quarter
	UNION ALL
	SELECT * FROM last_quarter

)
GROUP BY store, period, date, customer_id, first_order_channel, first_order_platform
  );

    
2018-07-30 13:43:49,026: Bad request while running:
create dataset
2018-07-30 13:43:49,026: 400 GET https://www.googleapis.com/bigquery/v2/projects/growth-engines-pipeline/queries/8565d834-4116-46d8-827d-31d62d988892?maxResults=0: Unrecognized name: recency; Did you mean frequency? at [48:9]
2018-07-30 13:43:49,027: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ccbbc33b-fa88-49b0-a5f9-0d07a64bbbfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b49080>]}
2018-07-30 13:43:49,416: 13:43:49 | 20 of 22 ERROR creating table model template.segment_stats_customers_agg [ERROR in 1.10s]
2018-07-30 13:43:49,418: 13:43:49 | 21 of 22 SKIP relation template.buyer_segment_stats.................. [SKIP]
2018-07-30 13:43:49,419: 13:43:49 | 22 of 22 SKIP relation template.buyer_segment_lists.................. [SKIP]
2018-07-30 13:43:49,437: 13:43:49 | 
2018-07-30 13:43:49,437: 13:43:49 | Finished running 22 table models in 166.98s.
2018-07-30 13:43:49,437: Connection 'master' was left open.
2018-07-30 13:43:49,438: 
2018-07-30 13:43:49,438: Completed with 1 errors:
2018-07-30 13:43:49,438: 
2018-07-30 13:43:49,438: Database Error in model segment_stats_customers_agg (models/math/buyer-segmentation/segment_stats_customers_agg.sql)
2018-07-30 13:43:49,438:   Unrecognized name: recency; Did you mean frequency? at [48:9]
2018-07-30 13:43:49,438:   compiled SQL at target/run/shopify_cohort_analysis/math/buyer-segmentation/segment_stats_customers_agg.sql
2018-07-30 13:43:49,438: 
Done. PASS=19 ERROR=1 SKIP=2 TOTAL=22
2018-07-30 13:43:49,439: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109f2f60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c18128>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c18e10>]}
2018-07-30 13:43:49,733: Flushing usage events
2018-07-30 13:43:49,974: sys:1: ResourceWarning: unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55379), raddr=('172.217.1.205', 443)>

2018-07-30 13:43:49,975: sys:1: ResourceWarning: unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55378), raddr=('172.217.11.234', 443)>

2018-07-30 13:43:49,976: sys:1: ResourceWarning: unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55377), raddr=('172.217.1.205', 443)>

2018-07-30 13:43:49,976: sys:1: ResourceWarning: unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55380), raddr=('172.217.1.205', 443)>

2018-07-30 13:43:49,976: sys:1: ResourceWarning: unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55383), raddr=('172.217.2.10', 443)>

2018-07-30 13:43:49,977: sys:1: ResourceWarning: unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55381), raddr=('172.217.1.205', 443)>

2018-07-30 13:43:49,977: sys:1: ResourceWarning: unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55382), raddr=('172.217.1.205', 443)>

2018-07-30 13:43:49,977: sys:1: ResourceWarning: unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55385), raddr=('172.217.2.10', 443)>

2018-07-30 13:43:49,978: sys:1: ResourceWarning: unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55384), raddr=('172.217.2.10', 443)>

2018-07-30 13:43:49,978: sys:1: ResourceWarning: unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55386), raddr=('172.217.2.10', 443)>

2018-07-30 14:06:20,480: Tracking: tracking
2018-07-30 14:06:20,482: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081c00f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082edd68>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082ede48>]}
2018-07-30 14:06:21,453: Loading dependency project from /usr/local/Cellar/dbt/0.10.1/libexec/lib/python3.6/site-packages/dbt/include
2018-07-30 14:06:21,487: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/shopify-cohort-analysis/dbt_modules
2018-07-30 14:06:21,497: Parsing get_column_values.sql
2018-07-30 14:06:21,521: Parsing get_url_parameter.sql
2018-07-30 14:06:21,528: Parsing split_part.sql
2018-07-30 14:06:21,540: Parsing table_exists.sql
2018-07-30 14:06:21,558: Parsing core.sql
2018-07-30 14:06:21,579: Parsing adapters/bigquery.sql
2018-07-30 14:06:21,596: Parsing adapters/common.sql
2018-07-30 14:06:21,629: Parsing adapters/redshift.sql
2018-07-30 14:06:21,656: Parsing adapters/snowflake.sql
2018-07-30 14:06:21,661: Parsing etc/bigquery.sql
2018-07-30 14:06:21,667: Parsing etc/datetime.sql
2018-07-30 14:06:21,698: Parsing etc/get_custom_schema.sql
2018-07-30 14:06:21,706: Parsing materializations/helpers.sql
2018-07-30 14:06:21,731: Parsing materializations/archive/archive.sql
2018-07-30 14:06:21,789: Parsing materializations/incremental/incremental.sql
2018-07-30 14:06:21,828: Parsing materializations/seed/bigquery.sql
2018-07-30 14:06:21,836: Parsing materializations/seed/seed.sql
2018-07-30 14:06:21,881: Parsing materializations/table/bigquery_table.sql
2018-07-30 14:06:21,918: Parsing materializations/table/table.sql
2018-07-30 14:06:21,950: Parsing materializations/view/bigquery_view.sql
2018-07-30 14:06:21,967: Parsing materializations/view/view.sql
2018-07-30 14:06:21,987: Parsing schema_tests/accepted_values.sql
2018-07-30 14:06:21,994: Parsing schema_tests/not_null.sql
2018-07-30 14:06:22,000: Parsing schema_tests/relationships.sql
2018-07-30 14:06:22,007: Parsing schema_tests/unique.sql
2018-07-30 14:06:22,063: Parsing model.shopify_cohort_analysis.all_dates
2018-07-30 14:06:22,067: Parsing model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 14:06:22,071: Parsing model.shopify_cohort_analysis.monthend_dates
2018-07-30 14:06:22,074: Parsing model.shopify_cohort_analysis.stores_proc
2018-07-30 14:06:22,076: Parsing model.shopify_cohort_analysis.ga_transactions
2018-07-30 14:06:22,085: Parsing model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 14:06:22,092: Parsing model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 14:06:22,099: Parsing model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 14:06:22,109: Parsing model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 14:06:22,118: Parsing model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 14:06:22,124: Parsing model.shopify_cohort_analysis.agg_customers
2018-07-30 14:06:22,127: Parsing model.shopify_cohort_analysis.agg_transactions
2018-07-30 14:06:22,130: Parsing model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 14:06:22,133: Parsing model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 14:06:22,138: Parsing model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 14:06:22,142: Parsing model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 14:06:22,145: Parsing model.shopify_cohort_analysis.customers_proc
2018-07-30 14:06:22,148: Parsing model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 14:06:22,152: Parsing model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 14:06:22,157: Parsing model.shopify_cohort_analysis.segment_proc_buyers
2018-07-30 14:06:22,159: Parsing model.shopify_cohort_analysis.segment_stats_buyers_agg
2018-07-30 14:06:22,165: Parsing model.shopify_cohort_analysis.segment_stats_buyers_view
2018-07-30 14:06:22,172: Parsing model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 14:06:22,190: Found 23 models, 0 tests, 0 archives, 0 analyses, 62 macros, 0 operations, 0 seed files
2018-07-30 14:06:22,199: 
2018-07-30 14:06:22,207: Acquiring new bigquery connection "master".
2018-07-30 14:06:22,207: Opening a new connection (0 currently allocated)
2018-07-30 14:06:23,585: 14:06:23 | Concurrency: 4 threads (target='template')
2018-07-30 14:06:23,585: 14:06:23 | 
2018-07-30 14:06:23,643: 14:06:23 | 1 of 23 START table model template.all_dates......................... [RUN]
2018-07-30 14:06:23,643: 14:06:23 | 2 of 23 START table model template.stores_proc....................... [RUN]
2018-07-30 14:06:23,644: Compiling model.shopify_cohort_analysis.all_dates
2018-07-30 14:06:23,644: 14:06:23 | 3 of 23 START table model template.monthend_dates.................... [RUN]
2018-07-30 14:06:23,644: Compiling model.shopify_cohort_analysis.stores_proc
2018-07-30 14:06:23,644: 14:06:23 | 4 of 23 START table model template.mappings_ga_proc.................. [RUN]
2018-07-30 14:06:23,649: Writing injected SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 14:06:23,649: Compiling model.shopify_cohort_analysis.monthend_dates
2018-07-30 14:06:23,655: Writing injected SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 14:06:23,655: Compiling model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 14:06:23,662: Writing injected SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 14:06:23,668: Writing injected SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 14:06:23,671: Acquiring new bigquery connection "stores_proc".
2018-07-30 14:06:23,672: Opening a new connection (1 currently allocated)
2018-07-30 14:06:23,675: Acquiring new bigquery connection "all_dates".
2018-07-30 14:06:23,677: Acquiring new bigquery connection "mappings_ga_proc".
2018-07-30 14:06:23,679: Acquiring new bigquery connection "monthend_dates".
2018-07-30 14:06:23,687: Opening a new connection (2 currently allocated)
2018-07-30 14:06:23,690: Opening a new connection (3 currently allocated)
2018-07-30 14:06:23,699: Opening a new connection (4 currently allocated)
2018-07-30 14:06:24,120: Writing runtime SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 14:06:24,121: Fetching data for query stores_proc:
create or replace table `template`.`stores_proc`
  
  as (
    select 
store,
store_name,
account,
platform,
max(time_of_entry) time_of_entry

from  ( 

SELECT  
client store,
client_name store_name,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.accounts` 
where client_name != ''

) 

WHERE lv = time_of_entry
group by store, store_name, account, platform
  );

    
2018-07-30 14:06:24,144: Writing runtime SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 14:06:24,155: Writing runtime SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 14:06:24,162: Fetching data for query all_dates:
create or replace table `template`.`all_dates`
  
  as (
    SELECT 
date_in_range,
unix_date(date_in_range) unix_date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
  );

    
2018-07-30 14:06:24,166: Writing runtime SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 14:06:24,167: Fetching data for query monthend_dates:
create or replace table `template`.`monthend_dates`
  
  as (
    SELECT
date_in_range,
date_in_range_bom,
date_in_range_bom_mom,
unix_date_in_range,
unix_date_in_range_bom,
unix_date(date_in_range_bom_mom) unix_date_in_range_bom_mom,
yyyymm,
date_in_range_yoy,
unix_date(date_in_range_yoy) unix_date_in_range_yoy

FROM
(
	SELECT 
	date_in_range,
	date_in_range_bom,
	date_sub(date_in_range_bom, INTERVAL 1 MONTH) date_in_range_bom_mom,
	date_sub(date_in_range, INTERVAL 1 YEAR) date_in_range_yoy,
	unix_date_in_range,
	unix_date(date_in_range_bom) unix_date_in_range_bom,
	yyyymm,
	first_value(date_in_range) over (partition by yyyymm order by date_in_range desc) monthend_date_in_range
	FROM
	( 
		SELECT 
		date_in_range,
		date_trunc( date_in_range, MONTH) date_in_range_bom,
		unix_date(date_in_range) unix_date_in_range,
		format_date("%Y-%m", date_in_range) AS yyyymm
		FROM UNNEST(
		    GENERATE_DATE_ARRAY(DATE('2016-01-31'), CURRENT_DATE(), INTERVAL 1 DAY)
		) AS date_in_range
	)
)
where date_in_range = monthend_date_in_range
  );

    
2018-07-30 14:06:24,173: Fetching data for query mappings_ga_proc:
create or replace table `template`.`mappings_ga_proc`
  
  as (
    select 
store,
account,
store_name,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client store,
account,
client_name store_name,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.mappings_ga` 

) 

WHERE lv = time_of_entry
group by store, account, store_name, source, medium, platform_n, channel_n, time_of_entry
  );

    
2018-07-30 14:06:25,771: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108426ef0>]}
2018-07-30 14:06:26,240: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1084265f8>]}
2018-07-30 14:06:26,243: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108426cf8>]}
2018-07-30 14:06:26,246: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108426978>]}
2018-07-30 14:06:27,531: 14:06:27 | 1 of 23 OK created table model template.all_dates.................... [OK in 2.13s]
2018-07-30 14:06:27,918: 14:06:27 | 2 of 23 OK created table model template.stores_proc.................. [OK in 2.60s]
2018-07-30 14:06:28,205: 14:06:28 | 4 of 23 OK created table model template.mappings_ga_proc............. [OK in 2.59s]
2018-07-30 14:06:28,552: 14:06:28 | 3 of 23 OK created table model template.monthend_dates............... [OK in 2.60s]
2018-07-30 14:06:28,556: 14:06:28 | 5 of 23 START table model template.shopify_customers_proc............ [RUN]
2018-07-30 14:06:28,556: Compiling model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 14:06:28,565: Acquiring new bigquery connection "shopify_customers_proc".
2018-07-30 14:06:28,565: Re-using an available connection from the pool.
2018-07-30 14:06:28,566: Fetching data for query shopify_customers_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:06:28,556: 14:06:28 | 6 of 23 START table model template.shopify_discounts_proc............ [RUN]
2018-07-30 14:06:28,566: Compiling model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 14:06:28,556: 14:06:28 | 7 of 23 START table model template.shopify_refunds_proc.............. [RUN]
2018-07-30 14:06:28,568: Compiling model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 14:06:28,581: Acquiring new bigquery connection "shopify_refunds_proc".
2018-07-30 14:06:28,582: Acquiring new bigquery connection "shopify_discounts_proc".
2018-07-30 14:06:28,583: Re-using an available connection from the pool.
2018-07-30 14:06:28,583: Fetching data for query shopify_refunds_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:06:28,584: Re-using an available connection from the pool.
2018-07-30 14:06:28,584: Fetching data for query shopify_discounts_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:06:30,053: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 14:06:30,068: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 14:06:30,184: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 14:06:30,184: Fetching data for query shopify_discounts_proc:
create or replace table `template`.`shopify_discounts_proc`
  
  as (
    



with orders as (

	
		SELECT
		'lucadanni' store_name,
		created_at,
		order_number,
		code discount_code,
		type discount_type,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(discount_codes)
		where source_name != 'shopify_draft_order'
	
	
	

)

SELECT
store_name,
order_number,
discount_code,
discount_type
FROM orders
where lv = _sdc_sequence


  );

    
2018-07-30 14:06:30,215: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 14:06:30,216: Fetching data for query shopify_customers_proc:
create or replace table `template`.`shopify_customers_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`





with customers as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	created_at,
	id,
	first_name,
	last_name,
	email,
	_sdc_sequence,
	first_value(_sdc_sequence) over (partition by id order by _sdc_sequence desc) lv
	FROM `growth-engines-pipeline.shopify_lucadanni.customers` 
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
id,
first_name,
last_name,
email
FROM customers a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence


  );

    
2018-07-30 14:06:30,937: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 14:06:31,068: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 14:06:31,069: Fetching data for query shopify_refunds_proc:
create or replace table `template`.`shopify_refunds_proc`
  
  as (
    



with refunds as (

	
	SELECT
	'lucadanni' store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal,
	line_item.variant_id variant_id,
	line_item.id refund_id,
 	_sdc_sequence
	FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
	cross join unnest(refunds), unnest(refund_line_items)
  	where financial_status like '%refund%'
	
	

)

SELECT * 
FROM 
	(
    SELECT
    store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal refund_amount,
	variant_id,
	refund_id,
 	_sdc_sequence,
    first_value(_sdc_sequence) OVER (PARTITION BY order_number, line_item_id ORDER BY _sdc_sequence DESC) lv
    FROM refunds
   	) 
WHERE lv = _sdc_sequence


  );

    
2018-07-30 14:06:32,503: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1084fce10>]}
2018-07-30 14:06:32,793: 14:06:32 | 6 of 23 OK created table model template.shopify_discounts_proc....... [OK in 3.94s]
2018-07-30 14:06:33,077: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085254e0>]}
2018-07-30 14:06:33,369: 14:06:33 | 7 of 23 OK created table model template.shopify_refunds_proc......... [OK in 4.51s]
2018-07-30 14:06:34,729: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10647f438>]}
2018-07-30 14:06:35,516: 14:06:35 | 5 of 23 OK created table model template.shopify_customers_proc....... [OK in 6.17s]
2018-07-30 14:06:35,516: 14:06:35 | 8 of 23 START table model template.ga_transactions................... [RUN]
2018-07-30 14:06:35,517: 14:06:35 | 9 of 23 START table model template.agg_customers..................... [RUN]
2018-07-30 14:06:35,517: Compiling model.shopify_cohort_analysis.ga_transactions
2018-07-30 14:06:35,517: 14:06:35 | 10 of 23 START table model template.shopify_products_proc............ [RUN]
2018-07-30 14:06:35,518: Compiling model.shopify_cohort_analysis.agg_customers
2018-07-30 14:06:35,519: Compiling model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 14:06:35,525: Writing injected SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 14:06:35,553: Acquiring new bigquery connection "shopify_products_proc".
2018-07-30 14:06:35,553: Re-using an available connection from the pool.
2018-07-30 14:06:35,555: Acquiring new bigquery connection "ga_transactions".
2018-07-30 14:06:35,555: Fetching data for query shopify_products_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:06:35,556: Re-using an available connection from the pool.
2018-07-30 14:06:35,561: Fetching data for query ga_transactions:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Google Analytics'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:06:35,559: Acquiring new bigquery connection "agg_customers".
2018-07-30 14:06:35,564: Re-using an available connection from the pool.
2018-07-30 14:06:35,868: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 14:06:35,874: Fetching data for query agg_customers:
create or replace table `template`.`agg_customers`
  
  as (
    SELECT 
account,
store,
id,
created_at,
first_name,
last_name,
email,
split(email,'@')[SAFE_ORDINAL(2)] email_domain
FROM
`growth-engines-pipeline`.`template`.`shopify_customers_proc`
  );

    
2018-07-30 14:06:36,649: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 14:06:36,818: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 14:06:36,819: Fetching data for query shopify_products_proc:
create or replace table `template`.`shopify_products_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`





with products as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	product_name,
	lower(product_type) product_type,
	product_id,
	sku,
	id variant_id,
	cast(created_at as date) created_at,
	_sdc_sequence,
	first_value(_sdc_sequence) OVER (PARTITION BY product_id ORDER BY _sdc_sequence DESC) lv
	FROM (
		SELECT
		variants,
		product_type,
		title product_name,
		_sdc_sequence
		FROM `growth-engines-pipeline.shopify_lucadanni.products` 
		)
	cross join unnest(variants)
	
	

)

SELECT
b.account,
b.store,
b.platform,
max(product_type) product_type,
product_id,
variant_id,
sku,
created_at,
product_name
FROM products a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence
group by product_id, account, store, platform, sku, variant_id, created_at, product_name


  );

    
2018-07-30 14:06:37,407: Writing injected SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 14:06:37,545: Writing runtime SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 14:06:37,545: Fetching data for query ga_transactions:
create or replace table `template`.`ga_transactions`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`,`growth-engines-pipeline`.`template`.`mappings_ga_proc`




with ga_report as (

	    
	    	
		   	SELECT
		   	'yandy' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_yandy.report` 

		     UNION ALL 
	   
	    	
		   	SELECT
		   	'lucadanni' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_lucadanni.report` 

		    
	   

)


SELECT  
date,
b.store store,
c.source source,
c.medium medium,
a.campaign campaign,
concat(a.source, ' / ', a.medium) source_medium,  
case when c.platform is null then "Unmapped" else c.platform end as platform,
case when c.channel is null then "Unmapped" else c.channel end as channel,
url,
transactionid
FROM (

	SELECT 
	store_name,
	lookup_platform,
	date,
	transactionid,
	max(url) url,
	max(source) source,
	max(medium) medium,
	max(campaign) campaign
	FROM ga_report
	where lv = _sdc_sequence
	group by store_name, lookup_platform, date, transactionid

) a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name 
	AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`mappings_ga_proc` c
ON ( a.source = c.source
  AND a.medium = c.medium 
  AND a.store_name = c.store_name )


  );

    
2018-07-30 14:06:39,070: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108475e10>]}
2018-07-30 14:06:39,356: 14:06:39 | 10 of 23 OK created table model template.shopify_products_proc....... [OK in 3.55s]
2018-07-30 14:06:39,601: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1083b7160>]}
2018-07-30 14:06:39,918: 14:06:39 | 9 of 23 OK created table model template.agg_customers................ [OK in 4.08s]
2018-07-30 14:07:01,889: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10841a470>]}
2018-07-30 14:07:02,628: 14:07:02 | 8 of 23 OK created table model template.ga_transactions.............. [OK in 26.37s]
2018-07-30 14:07:02,628: 14:07:02 | 11 of 23 START table model template.shopify_orders_proc.............. [RUN]
2018-07-30 14:07:02,629: Compiling model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 14:07:02,643: Acquiring new bigquery connection "shopify_orders_proc".
2018-07-30 14:07:02,643: Re-using an available connection from the pool.
2018-07-30 14:07:02,643: Fetching data for query shopify_orders_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:07:03,652: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 14:07:03,817: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 14:07:03,817: Fetching data for query shopify_orders_proc:
create or replace table `template`.`shopify_orders_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`, `growth-engines-pipeline`.`template`.`shopify_discounts_proc`





with orders as (

	
	SELECT 
	store_name,
	lookup_platform,
	created_at,
	order_number,
	quantity,
	price, 
	total_order_price_undiscounted,
	total_discounts,
	total_order_shipping_price,
	total_order_price_incl_shipping,
	checkout_id,
	product_id, 
	landing_site,
	sku, 
	variant_title, 
	variant_id,
	line_item_id,
	customer_id,
	_sdc_sequence,
	lv
	FROM (

		SELECT
		'lucadanni' store_name,
		'Shopify' as lookup_platform,
		created_at,
		order_number,
		quantity,
		cast(pre_tax_price as float64) price, 
		total_line_items_price total_order_price_undiscounted,
		total_discounts,
		cast(discounted_price as float64) total_order_shipping_price,
		total_price_usd total_order_price_incl_shipping,
		checkout_id,
		product_id, 
		landing_site,
		sku, 
		variant_title, 
		variant_id,
		_id line_item_id,
		customer.id customer_id,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(line_items), unnest(shipping_lines)
		where source_name != 'shopify_draft_order'
	)
	
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
a.order_number,
a.quantity prelim_quantity,
c.quantity refund_quantity,
case when c.quantity is not null then a.quantity - c.quantity else a.quantity end as quantity,
price prelim_revenue, 
total_order_price_undiscounted,
total_discounts,
trim(lower(d.discount_code)) discount_code,
d.discount_type,
total_order_shipping_price,
total_order_price_incl_shipping,
refund_amount,
case when refund_amount is not null then price - refund_amount else price end as revenue,
a.checkout_id,
a.product_id, 
landing_site,
sku, 
variant_title, 
a.variant_id,
a.line_item_id,	
customer_id
FROM orders a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_refunds_proc` c
ON ( a.order_number = c.order_number
	AND a.line_item_id = c.line_item_id
	AND a.store_name = c.store_name )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_discounts_proc` d
ON ( a.order_number = d.order_number 
    AND a.store_name = d.store_name )  	
where a.lv = a._sdc_sequence


  );

    
2018-07-30 14:07:13,908: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10647f438>]}
2018-07-30 14:07:14,563: 14:07:14 | 11 of 23 OK created table model template.shopify_orders_proc......... [OK in 11.28s]
2018-07-30 14:07:14,563: 14:07:14 | 12 of 23 START table model template.transaction_by_order_number...... [RUN]
2018-07-30 14:07:14,564: Compiling model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 14:07:14,574: Writing injected SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 14:07:14,577: Acquiring new bigquery connection "transaction_by_order_number".
2018-07-30 14:07:14,577: Re-using an available connection from the pool.
2018-07-30 14:07:14,749: Writing runtime SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 14:07:14,750: Fetching data for query transaction_by_order_number:
create or replace table `template`.`transaction_by_order_number`
  
  as (
    SELECT
store,
cast(created_at as date) order_date,
order_number,
customer_id,
sum(quantity) quantity,
sum(revenue) revenue,
max(total_order_shipping_price) shipping_price
FROM
`growth-engines-pipeline`.`template`.`shopify_orders_proc`
GROUP BY store, order_date, order_number, customer_id
  );

    
2018-07-30 14:07:18,792: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10841a470>]}
2018-07-30 14:07:19,121: 14:07:19 | 12 of 23 OK created table model template.transaction_by_order_number. [OK in 4.23s]
2018-07-30 14:07:19,128: 14:07:19 | 13 of 23 START table model template.customers_by_transaction......... [RUN]
2018-07-30 14:07:19,128: Compiling model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 14:07:19,140: Writing injected SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 14:07:19,144: Acquiring new bigquery connection "customers_by_transaction".
2018-07-30 14:07:19,144: Re-using an available connection from the pool.
2018-07-30 14:07:19,263: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 14:07:19,263: Fetching data for query customers_by_transaction:
create or replace table `template`.`customers_by_transaction`
  
  as (
    SELECT
store,
customer_id,
order_number,
order_date,
recent_order_date,
first_order_date,
case when first_order_number = order_number then 'New'
	when date_diff(order_date, recent_order_date, DAY) <= 365 then 'Repeat'
	when date_diff(order_date, recent_order_date, DAY) > 365 then 'Reactivated'
 else '' end as order_type,
quantity,
revenue,
1 as orders,
first_order_revenue,
lifetime_revenue
FROM

(

	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	quantity,
	revenue,
	lag(order_date) over w1 recent_order_date,
	first_value(order_date) over w1 first_order_date,
	first_value(order_number) over w1 first_order_number,
	first_value(revenue) over w1 first_order_revenue,
	sum(revenue) over w2 lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`transaction_by_order_number`
	WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc),
	w2 as (PARTITION BY store, customer_id)
)
  );

    
2018-07-30 14:07:22,855: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10647f438>]}
2018-07-30 14:07:24,452: 14:07:24 | 13 of 23 OK created table model template.customers_by_transaction.... [OK in 3.73s]
2018-07-30 14:07:24,453: 14:07:24 | 14 of 23 START table model template.agg_transactions................. [RUN]
2018-07-30 14:07:24,453: Compiling model.shopify_cohort_analysis.agg_transactions
2018-07-30 14:07:24,460: Writing injected SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 14:07:24,462: Acquiring new bigquery connection "agg_transactions".
2018-07-30 14:07:24,462: Re-using an available connection from the pool.
2018-07-30 14:07:24,599: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 14:07:24,599: Fetching data for query agg_transactions:
create or replace table `template`.`agg_transactions`
  
  as (
    with ga_transaction as (

	SELECT
	date, 
	store,
	transactionid,
	channel,
	platform,
	url,
	campaign
	FROM `growth-engines-pipeline`.`template`.`ga_transactions`
),

customers_by_transaction as (
	
	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	first_order_date,
	recent_order_date,
	order_type,
	quantity,
	revenue,
	orders,
	first_order_revenue,
	lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`customers_by_transaction`
)

SELECT
store,
customer_id,
order_number,
transactionid,
order_date,
first_order_date,
format_date("%Y-%m", first_order_date) AS first_order_month,
order_type,
first_order_revenue,
lifetime_revenue,
first_value(channel) over w1 as first_order_channel,
first_value(platform) over w1 as first_order_platform,
channel,
platform,
url,
campaign,
quantity,
revenue,
orders
FROM (

	SELECT
	a.store,
	a.customer_id,
	a.order_number,
	b.transactionid,
	a.order_date, 
	a.first_order_date, 
	a.order_type,
	a.first_order_revenue,
	a.lifetime_revenue,
	b.channel,
	b.platform,
	b.url,
	b.campaign,
	a.quantity,
	a.revenue,
	a.orders
	FROM customers_by_transaction a
	LEFT JOIN ga_transaction b
	ON (
	    a.store = b.store AND
	    a.order_number = b.transactionid
	)	
)
WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc)
  );

    
2018-07-30 14:07:32,625: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10841a470>]}
2018-07-30 14:07:33,420: 14:07:33 | 14 of 23 OK created table model template.agg_transactions............ [OK in 8.17s]
2018-07-30 14:07:33,420: 14:07:33 | 15 of 23 START table model template.monthly_cohort_stats............. [RUN]
2018-07-30 14:07:33,421: Compiling model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 14:07:33,421: 14:07:33 | 16 of 23 START table model template.customers_proc_qoq............... [RUN]
2018-07-30 14:07:33,421: 14:07:33 | 17 of 23 START table model template.customers_proc_yoy............... [RUN]
2018-07-30 14:07:33,429: Writing injected SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 14:07:33,429: Compiling model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 14:07:33,429: Compiling model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 14:07:33,437: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 14:07:33,444: Acquiring new bigquery connection "monthly_cohort_stats".
2018-07-30 14:07:33,450: Re-using an available connection from the pool.
2018-07-30 14:07:33,449: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 14:07:33,457: Acquiring new bigquery connection "customers_proc_qoq".
2018-07-30 14:07:33,457: Re-using an available connection from the pool.
2018-07-30 14:07:33,463: Acquiring new bigquery connection "customers_proc_yoy".
2018-07-30 14:07:33,464: Re-using an available connection from the pool.
2018-07-30 14:07:33,779: Writing runtime SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 14:07:33,799: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 14:07:33,804: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 14:07:33,805: Fetching data for query monthly_cohort_stats:
create or replace table `template`.`monthly_cohort_stats`
  
  as (
    WITH transactions AS (

  SELECT 
  store, 
  order_number,
  order_date,
  order_type,
  first_order_month,
  unix_date(order_date) d, 
  customer_id, 
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (

  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT 
date_in_range date,
store, 
order_type,
first_order_channel,
first_order_platform,
first_order_month,
channel,
platform,
url,
campaign,
count(distinct(customer_id)) buyers,
sum(orders) orders,
sum(quantity) quantity,
sum(revenue) revenue
FROM daterange
JOIN transactions
ON transactions.d >= daterange.unix_date_in_range_bom 
AND transactions.d <= daterange.unix_date_in_range
GROUP BY date, store, order_type, 
first_order_channel, first_order_platform, first_order_month, channel, platform, url, campaign
  );

    
2018-07-30 14:07:33,806: Fetching data for query customers_proc_qoq:
create or replace table `template`.`customers_proc_qoq`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 90 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 90 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 90 window_end_unix_date, 
    unix_date_in_range - 180 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 180 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 90 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 14:07:33,806: Fetching data for query customers_proc_yoy:
create or replace table `template`.`customers_proc_yoy`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 365 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 365 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 365 window_end_unix_date, 
    unix_date_in_range - 730 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 730 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 365 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 14:07:39,877: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10647f438>]}
2018-07-30 14:07:40,611: 14:07:40 | 15 of 23 OK created table model template.monthly_cohort_stats........ [OK in 6.46s]
2018-07-30 14:07:46,325: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1084482e8>]}
2018-07-30 14:07:46,626: 14:07:46 | 16 of 23 OK created table model template.customers_proc_qoq.......... [OK in 12.90s]
2018-07-30 14:07:57,449: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108448940>]}
2018-07-30 14:07:57,742: 14:07:57 | 17 of 23 OK created table model template.customers_proc_yoy.......... [OK in 24.02s]
2018-07-30 14:07:57,743: 14:07:57 | 18 of 23 START table model template.customers_proc................... [RUN]
2018-07-30 14:07:57,743: Compiling model.shopify_cohort_analysis.customers_proc
2018-07-30 14:07:57,752: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 14:07:57,753: Acquiring new bigquery connection "customers_proc".
2018-07-30 14:07:57,753: Re-using an available connection from the pool.
2018-07-30 14:07:57,907: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 14:07:57,908: Fetching data for query customers_proc:
create or replace table `template`.`customers_proc`
  
  as (
    SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_qoq`

UNION ALL

SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_yoy`
  );

    
2018-07-30 14:08:27,556: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10841a470>]}
2018-07-30 14:08:29,176: 14:08:29 | 18 of 23 OK created table model template.customers_proc.............. [OK in 29.81s]
2018-07-30 14:08:29,177: 14:08:29 | 19 of 23 START table model template.segment_proc_buyers.............. [RUN]
2018-07-30 14:08:29,178: Compiling model.shopify_cohort_analysis.segment_proc_buyers
2018-07-30 14:08:29,195: Writing injected SQL for node "model.shopify_cohort_analysis.segment_proc_buyers"
2018-07-30 14:08:29,199: Acquiring new bigquery connection "segment_proc_buyers".
2018-07-30 14:08:29,199: Re-using an available connection from the pool.
2018-07-30 14:08:29,357: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_proc_buyers"
2018-07-30 14:08:29,375: Fetching data for query segment_proc_buyers:
create or replace table `template`.`segment_proc_buyers`
  
  as (
    SELECT
store,
period,
customer_id,
date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct,
case when first_order_unix_date >= window_start_unix_date then 'New'
	else 'Existing' end as newness_segment,
case when revenue >= revenue_90pct then 'Top 10%'
	when revenue <= revenue_10pct then 'Bottom 10%'
	else 'Middle 80%' end as revenue_segment,
case when frequency = 1 then '1'
	when frequency = 2 then '2'
	when frequency > 2 then '3+'
	else null end as frequency_segment
FROM `growth-engines-pipeline`.`template`.`customers_proc`
  );

    
2018-07-30 14:09:00,541: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10510ef60>]}
2018-07-30 14:09:00,862: 14:09:00 | 19 of 23 OK created table model template.segment_proc_buyers......... [OK in 31.36s]
2018-07-30 14:09:00,863: 14:09:00 | 20 of 23 START table model template.segment_stats_buyers_agg......... [RUN]
2018-07-30 14:09:00,863: Compiling model.shopify_cohort_analysis.segment_stats_buyers_agg
2018-07-30 14:09:00,876: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_agg"
2018-07-30 14:09:00,877: Acquiring new bigquery connection "segment_stats_buyers_agg".
2018-07-30 14:09:00,878: Re-using an available connection from the pool.
2018-07-30 14:09:01,410: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_agg"
2018-07-30 14:09:01,411: Fetching data for query segment_stats_buyers_agg:
create or replace table `template`.`segment_stats_buyers_agg`
  
  as (
    WITH ty as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Year'

),

this_month_1yr as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	'' as revenue_segment,
	'' as frequency_segment,
	'' as newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	revenue_segment as revenue_segment_prev,
	frequency_segment as frequency_segment_prev,
	newness_segment as newness_segment_prev,
	recency_days as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Previous Year'

),

this_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,	
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Quarter'

),

last_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	'' as revenue_segment,
	'' as frequency_segment,
	'' as newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	revenue_segment as revenue_segment_prev,
	frequency_segment as frequency_segment_prev,
	newness_segment as newness_segment_prev,
	recency_days as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev		
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Previous Quarter'

)

SELECT
store,
period,
date, 
customer_id,
1 as buyers,
first_order_channel,
first_order_platform,	
case when max(revenue_segment) != '' then max(revenue_segment) 
	when max(revenue_segment_prev) != '' then 'Dormant'
	else '' end as revenue_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(revenue_segment_prev) end as revenue_segment_prev,
case when max(frequency_segment) != '' then max(frequency_segment) 
	when max(frequency_segment_prev) != '' then 'Dormant'
	else '' end as frequency_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(frequency_segment_prev) end as frequency_segment_prev,
ifnull(sum(recency), 0) recency,
ifnull(sum(frequency), 0) frequency,
ifnull(sum(revenue), 0) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else 0 end as aov,
ifnull(sum(recency_prev), 0) recency_prev,
ifnull(sum(frequency_prev), 0) frequency_prev,
ifnull(sum(revenue_prev), 0) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else 0 end as aov_prev,
case when max(newness_segment_prev) != '' then 1 else 0 end as retention_eligible,
case when max(newness_segment_prev) != '' and max(newness_segment) != '' then 1 else 0 end as retention_success
FROM
(
	SELECT * FROM ty
	UNION ALL
	SELECT * FROM this_month_1yr
	UNION ALL
	SELECT * FROM this_quarter
	UNION ALL
	SELECT * FROM last_quarter

)
GROUP BY store, period, date, customer_id, first_order_channel, first_order_platform
  );

    
2018-07-30 14:09:28,522: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10841a470>]}
2018-07-30 14:09:29,768: 14:09:29 | 20 of 23 OK created table model template.segment_stats_buyers_agg.... [OK in 27.66s]
2018-07-30 14:09:29,769: 14:09:29 | 21 of 23 START table model template.segment_stats_buyers_view........ [RUN]
2018-07-30 14:09:29,769: Compiling model.shopify_cohort_analysis.segment_stats_buyers_view
2018-07-30 14:09:29,784: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_view"
2018-07-30 14:09:29,786: Acquiring new bigquery connection "segment_stats_buyers_view".
2018-07-30 14:09:29,786: Re-using an available connection from the pool.
2018-07-30 14:09:30,340: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_view"
2018-07-30 14:09:30,341: Fetching data for query segment_stats_buyers_view:
create or replace table `template`.`segment_stats_buyers_view`
  
  as (
    SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type
  );

    
2018-07-30 14:09:34,857: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10510ef60>]}
2018-07-30 14:09:35,650: 14:09:35 | 21 of 23 OK created table model template.segment_stats_buyers_view... [OK in 5.09s]
2018-07-30 14:09:35,651: 14:09:35 | 22 of 23 START table model template.buyer_segment_stats.............. [RUN]
2018-07-30 14:09:35,652: Compiling model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 14:09:35,663: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 14:09:35,664: Acquiring new bigquery connection "buyer_segment_stats".
2018-07-30 14:09:35,665: Re-using an available connection from the pool.
2018-07-30 14:09:35,826: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 14:09:35,826: Fetching data for query buyer_segment_stats:
create or replace table `template`.`buyer_segment_stats`
  
  as (
    SELECT
store,
period,
date,
view,
view_segment,
segment_type,
segment,
segment_prev,
buyers,
total_view_buyers,
case when total_view_buyers > 0 then buyers / total_view_buyers else null end as pct_of_view_segment_buyers,
recency,
frequency,
revenue,
total_view_revenue,
case when total_view_revenue > 0 then revenue / total_view_revenue else null end as pct_of_view_segment_revenue,
aov,
recency_prev,
frequency_prev,
revenue_prev,
aov_prev,
retention_rate
FROM (

	SELECT
	store,
	period,
	date,
	view,
	view_segment,
	segment_type,
	segment,
	segment_prev,
	buyers,
	sum(buyers) over w1 as total_view_buyers,
	recency,
	frequency,
	revenue,
	sum(revenue) over w1 as total_view_revenue,
	aov,
	recency_prev,
	frequency_prev,
	revenue_prev,
	aov_prev,
	retention_rate
	FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_view`
	where revenue_segment != ''
	and revenue_segment_prev != ''
	GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type
	WINDOW w1 as (PARTITION BY store, period, date, segment_type, view, view_segment)
)
  );

    
2018-07-30 14:09:36,306: Bad request while running:
create dataset
2018-07-30 14:09:36,308: 400 GET https://www.googleapis.com/bigquery/v2/projects/growth-engines-pipeline/queries/d9d50381-ec74-4f8f-a04d-ed662259a98a?maxResults=0: Unrecognized name: revenue_segment at [51:15]
2018-07-30 14:09:36,309: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108484be0>]}
2018-07-30 14:09:36,606: 14:09:36 | 22 of 23 ERROR creating table model template.buyer_segment_stats..... [ERROR in 0.66s]
2018-07-30 14:09:36,607: 14:09:36 | 23 of 23 START table model template.buyer_segment_lists.............. [RUN]
2018-07-30 14:09:36,608: Compiling model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 14:09:36,614: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 14:09:36,616: Acquiring new bigquery connection "buyer_segment_lists".
2018-07-30 14:09:36,616: Re-using an available connection from the pool.
2018-07-30 14:09:36,748: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 14:09:36,749: Fetching data for query buyer_segment_lists:
create or replace table `template`.`buyer_segment_lists`
  
  as (
    SELECT
a.store,
period,
date,
customer_id,
b.first_name,
b.last_name,
b.email,
recency,
frequency,
revenue,
aov,
revenue_segment,
frequency_segment
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg` a
LEFT JOIN `growth-engines-pipeline`.`template`.`agg_customers` b
ON (
	a.store = b.store AND
	a.customer_id = b.id
)
where ( revenue_segment != '' or frequency_segment != '' )
  );

    
2018-07-30 14:10:07,434: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea3ff158-6c65-4444-8886-d568d8691f26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10510ef60>]}
2018-07-30 14:10:07,763: 14:10:07 | 23 of 23 OK created table model template.buyer_segment_lists......... [OK in 30.83s]
2018-07-30 14:10:07,861: 14:10:07 | 
2018-07-30 14:10:07,861: 14:10:07 | Finished running 23 table models in 225.66s.
2018-07-30 14:10:07,862: Connection 'master' was left open.
2018-07-30 14:10:07,862: 
2018-07-30 14:10:07,862: Completed with 1 errors:
2018-07-30 14:10:07,863: 
2018-07-30 14:10:07,863: Database Error in model buyer_segment_stats (models/math/buyer-segmentation/buyer_segment_stats.sql)
2018-07-30 14:10:07,863:   Unrecognized name: revenue_segment at [51:15]
2018-07-30 14:10:07,863:   compiled SQL at target/run/shopify_cohort_analysis/math/buyer-segmentation/buyer_segment_stats.sql
2018-07-30 14:10:07,864: 
Done. PASS=22 ERROR=1 SKIP=0 TOTAL=23
2018-07-30 14:10:07,864: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1083b7780>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1083b71d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1083b7080>]}
2018-07-30 14:10:08,167: Flushing usage events
2018-07-30 14:10:08,347: sys:1: ResourceWarning: unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55453), raddr=('172.217.2.13', 443)>

2018-07-30 14:10:08,348: sys:1: ResourceWarning: unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55452), raddr=('172.217.1.202', 443)>

2018-07-30 14:10:08,348: sys:1: ResourceWarning: unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55451), raddr=('172.217.2.13', 443)>

2018-07-30 14:10:08,348: sys:1: ResourceWarning: unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55459), raddr=('172.217.12.10', 443)>

2018-07-30 14:10:08,348: sys:1: ResourceWarning: unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55457), raddr=('172.217.1.202', 443)>

2018-07-30 14:10:08,349: sys:1: ResourceWarning: unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55454), raddr=('172.217.2.13', 443)>

2018-07-30 14:10:08,349: sys:1: ResourceWarning: unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55458), raddr=('172.217.12.10', 443)>

2018-07-30 14:10:08,349: sys:1: ResourceWarning: unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55460), raddr=('172.217.12.10', 443)>

2018-07-30 14:10:08,349: sys:1: ResourceWarning: unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55455), raddr=('172.217.2.13', 443)>

2018-07-30 14:10:08,349: sys:1: ResourceWarning: unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55456), raddr=('172.217.2.13', 443)>

2018-07-30 14:11:51,400: Tracking: tracking
2018-07-30 14:11:51,402: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ba26be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ba26b00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ba26e80>]}
2018-07-30 14:11:52,439: Loading dependency project from /usr/local/Cellar/dbt/0.10.1/libexec/lib/python3.6/site-packages/dbt/include
2018-07-30 14:11:52,500: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/shopify-cohort-analysis/dbt_modules
2018-07-30 14:11:52,510: Parsing get_column_values.sql
2018-07-30 14:11:52,539: Parsing get_url_parameter.sql
2018-07-30 14:11:52,549: Parsing split_part.sql
2018-07-30 14:11:52,559: Parsing table_exists.sql
2018-07-30 14:11:52,587: Parsing core.sql
2018-07-30 14:11:52,620: Parsing adapters/bigquery.sql
2018-07-30 14:11:52,637: Parsing adapters/common.sql
2018-07-30 14:11:52,683: Parsing adapters/redshift.sql
2018-07-30 14:11:52,724: Parsing adapters/snowflake.sql
2018-07-30 14:11:52,729: Parsing etc/bigquery.sql
2018-07-30 14:11:52,733: Parsing etc/datetime.sql
2018-07-30 14:11:52,762: Parsing etc/get_custom_schema.sql
2018-07-30 14:11:52,770: Parsing materializations/helpers.sql
2018-07-30 14:11:52,799: Parsing materializations/archive/archive.sql
2018-07-30 14:11:52,847: Parsing materializations/incremental/incremental.sql
2018-07-30 14:11:52,882: Parsing materializations/seed/bigquery.sql
2018-07-30 14:11:52,890: Parsing materializations/seed/seed.sql
2018-07-30 14:11:52,943: Parsing materializations/table/bigquery_table.sql
2018-07-30 14:11:52,976: Parsing materializations/table/table.sql
2018-07-30 14:11:53,014: Parsing materializations/view/bigquery_view.sql
2018-07-30 14:11:53,028: Parsing materializations/view/view.sql
2018-07-30 14:11:53,051: Parsing schema_tests/accepted_values.sql
2018-07-30 14:11:53,059: Parsing schema_tests/not_null.sql
2018-07-30 14:11:53,067: Parsing schema_tests/relationships.sql
2018-07-30 14:11:53,075: Parsing schema_tests/unique.sql
2018-07-30 14:11:53,141: Parsing model.shopify_cohort_analysis.all_dates
2018-07-30 14:11:53,146: Parsing model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 14:11:53,151: Parsing model.shopify_cohort_analysis.monthend_dates
2018-07-30 14:11:53,154: Parsing model.shopify_cohort_analysis.stores_proc
2018-07-30 14:11:53,159: Parsing model.shopify_cohort_analysis.ga_transactions
2018-07-30 14:11:53,177: Parsing model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 14:11:53,185: Parsing model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 14:11:53,191: Parsing model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 14:11:53,202: Parsing model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 14:11:53,211: Parsing model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 14:11:53,218: Parsing model.shopify_cohort_analysis.agg_customers
2018-07-30 14:11:53,220: Parsing model.shopify_cohort_analysis.agg_transactions
2018-07-30 14:11:53,223: Parsing model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 14:11:53,226: Parsing model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 14:11:53,229: Parsing model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 14:11:53,234: Parsing model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 14:11:53,237: Parsing model.shopify_cohort_analysis.customers_proc
2018-07-30 14:11:53,240: Parsing model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 14:11:53,244: Parsing model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 14:11:53,249: Parsing model.shopify_cohort_analysis.segment_proc_buyers
2018-07-30 14:11:53,252: Parsing model.shopify_cohort_analysis.segment_stats_buyers_agg
2018-07-30 14:11:53,257: Parsing model.shopify_cohort_analysis.segment_stats_buyers_view
2018-07-30 14:11:53,264: Parsing model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 14:11:53,288: Found 23 models, 0 tests, 0 archives, 0 analyses, 62 macros, 0 operations, 0 seed files
2018-07-30 14:11:53,303: 
2018-07-30 14:11:53,313: Acquiring new bigquery connection "master".
2018-07-30 14:11:53,314: Opening a new connection (0 currently allocated)
2018-07-30 14:11:54,939: 14:11:54 | Concurrency: 4 threads (target='template')
2018-07-30 14:11:54,939: 14:11:54 | 
2018-07-30 14:11:55,015: 14:11:55 | 1 of 23 START table model template.mappings_ga_proc.................. [RUN]
2018-07-30 14:11:55,015: Compiling model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 14:11:55,015: 14:11:55 | 2 of 23 START table model template.stores_proc....................... [RUN]
2018-07-30 14:11:55,021: Compiling model.shopify_cohort_analysis.stores_proc
2018-07-30 14:11:55,025: Writing injected SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 14:11:55,015: 14:11:55 | 3 of 23 START table model template.all_dates......................... [RUN]
2018-07-30 14:11:55,029: Compiling model.shopify_cohort_analysis.all_dates
2018-07-30 14:11:55,028: Writing injected SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 14:11:55,034: Writing injected SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 14:11:55,015: 14:11:55 | 4 of 23 START table model template.monthend_dates.................... [RUN]
2018-07-30 14:11:55,034: Compiling model.shopify_cohort_analysis.monthend_dates
2018-07-30 14:11:55,040: Writing injected SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 14:11:55,042: Acquiring new bigquery connection "stores_proc".
2018-07-30 14:11:55,042: Opening a new connection (1 currently allocated)
2018-07-30 14:11:55,044: Acquiring new bigquery connection "all_dates".
2018-07-30 14:11:55,047: Acquiring new bigquery connection "monthend_dates".
2018-07-30 14:11:55,048: Acquiring new bigquery connection "mappings_ga_proc".
2018-07-30 14:11:55,050: Opening a new connection (2 currently allocated)
2018-07-30 14:11:55,063: Opening a new connection (3 currently allocated)
2018-07-30 14:11:55,068: Opening a new connection (4 currently allocated)
2018-07-30 14:11:56,218: Writing runtime SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 14:11:56,241: Writing runtime SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 14:11:56,245: Writing runtime SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 14:11:56,246: Fetching data for query monthend_dates:
create or replace table `template`.`monthend_dates`
  
  as (
    SELECT
date_in_range,
date_in_range_bom,
date_in_range_bom_mom,
unix_date_in_range,
unix_date_in_range_bom,
unix_date(date_in_range_bom_mom) unix_date_in_range_bom_mom,
yyyymm,
date_in_range_yoy,
unix_date(date_in_range_yoy) unix_date_in_range_yoy

FROM
(
	SELECT 
	date_in_range,
	date_in_range_bom,
	date_sub(date_in_range_bom, INTERVAL 1 MONTH) date_in_range_bom_mom,
	date_sub(date_in_range, INTERVAL 1 YEAR) date_in_range_yoy,
	unix_date_in_range,
	unix_date(date_in_range_bom) unix_date_in_range_bom,
	yyyymm,
	first_value(date_in_range) over (partition by yyyymm order by date_in_range desc) monthend_date_in_range
	FROM
	( 
		SELECT 
		date_in_range,
		date_trunc( date_in_range, MONTH) date_in_range_bom,
		unix_date(date_in_range) unix_date_in_range,
		format_date("%Y-%m", date_in_range) AS yyyymm
		FROM UNNEST(
		    GENERATE_DATE_ARRAY(DATE('2016-01-31'), CURRENT_DATE(), INTERVAL 1 DAY)
		) AS date_in_range
	)
)
where date_in_range = monthend_date_in_range
  );

    
2018-07-30 14:11:56,246: Fetching data for query mappings_ga_proc:
create or replace table `template`.`mappings_ga_proc`
  
  as (
    select 
store,
account,
store_name,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client store,
account,
client_name store_name,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.mappings_ga` 

) 

WHERE lv = time_of_entry
group by store, account, store_name, source, medium, platform_n, channel_n, time_of_entry
  );

    
2018-07-30 14:11:56,247: Fetching data for query stores_proc:
create or replace table `template`.`stores_proc`
  
  as (
    select 
store,
store_name,
account,
platform,
max(time_of_entry) time_of_entry

from  ( 

SELECT  
client store,
client_name store_name,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.accounts` 
where client_name != ''

) 

WHERE lv = time_of_entry
group by store, store_name, account, platform
  );

    
2018-07-30 14:11:56,363: Writing runtime SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 14:11:56,364: Fetching data for query all_dates:
create or replace table `template`.`all_dates`
  
  as (
    SELECT 
date_in_range,
unix_date(date_in_range) unix_date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
  );

    
2018-07-30 14:11:57,896: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bb635c0>]}
2018-07-30 14:11:57,925: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bbbf518>]}
2018-07-30 14:11:58,166: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bb63f98>]}
2018-07-30 14:11:58,206: 14:11:58 | 3 of 23 OK created table model template.all_dates.................... [OK in 2.87s]
2018-07-30 14:11:58,449: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bb6c748>]}
2018-07-30 14:11:58,518: 14:11:58 | 4 of 23 OK created table model template.monthend_dates............... [OK in 2.89s]
2018-07-30 14:11:58,830: 14:11:58 | 2 of 23 OK created table model template.stores_proc.................. [OK in 3.15s]
2018-07-30 14:11:59,131: 14:11:59 | 1 of 23 OK created table model template.mappings_ga_proc............. [OK in 3.43s]
2018-07-30 14:11:59,131: 14:11:59 | 5 of 23 START table model template.shopify_discounts_proc............ [RUN]
2018-07-30 14:11:59,132: Compiling model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 14:11:59,132: 14:11:59 | 6 of 23 START table model template.shopify_customers_proc............ [RUN]
2018-07-30 14:11:59,145: Compiling model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 14:11:59,132: 14:11:59 | 7 of 23 START table model template.shopify_refunds_proc.............. [RUN]
2018-07-30 14:11:59,155: Acquiring new bigquery connection "shopify_discounts_proc".
2018-07-30 14:11:59,161: Compiling model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 14:11:59,164: Acquiring new bigquery connection "shopify_customers_proc".
2018-07-30 14:11:59,165: Re-using an available connection from the pool.
2018-07-30 14:11:59,182: Fetching data for query shopify_discounts_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:11:59,182: Acquiring new bigquery connection "shopify_refunds_proc".
2018-07-30 14:11:59,188: Re-using an available connection from the pool.
2018-07-30 14:11:59,188: Fetching data for query shopify_customers_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:11:59,190: Re-using an available connection from the pool.
2018-07-30 14:11:59,190: Fetching data for query shopify_refunds_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:12:00,718: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 14:12:00,759: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 14:12:00,851: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 14:12:00,851: Fetching data for query shopify_customers_proc:
create or replace table `template`.`shopify_customers_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`





with customers as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	created_at,
	id,
	first_name,
	last_name,
	email,
	_sdc_sequence,
	first_value(_sdc_sequence) over (partition by id order by _sdc_sequence desc) lv
	FROM `growth-engines-pipeline.shopify_lucadanni.customers` 
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
id,
first_name,
last_name,
email
FROM customers a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence


  );

    
2018-07-30 14:12:00,900: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 14:12:00,904: Fetching data for query shopify_discounts_proc:
create or replace table `template`.`shopify_discounts_proc`
  
  as (
    



with orders as (

	
		SELECT
		'lucadanni' store_name,
		created_at,
		order_number,
		code discount_code,
		type discount_type,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(discount_codes)
		where source_name != 'shopify_draft_order'
	
	
	

)

SELECT
store_name,
order_number,
discount_code,
discount_type
FROM orders
where lv = _sdc_sequence


  );

    
2018-07-30 14:12:01,206: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 14:12:01,349: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 14:12:01,349: Fetching data for query shopify_refunds_proc:
create or replace table `template`.`shopify_refunds_proc`
  
  as (
    



with refunds as (

	
	SELECT
	'lucadanni' store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal,
	line_item.variant_id variant_id,
	line_item.id refund_id,
 	_sdc_sequence
	FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
	cross join unnest(refunds), unnest(refund_line_items)
  	where financial_status like '%refund%'
	
	

)

SELECT * 
FROM 
	(
    SELECT
    store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal refund_amount,
	variant_id,
	refund_id,
 	_sdc_sequence,
    first_value(_sdc_sequence) OVER (PARTITION BY order_number, line_item_id ORDER BY _sdc_sequence DESC) lv
    FROM refunds
   	) 
WHERE lv = _sdc_sequence


  );

    
2018-07-30 14:12:02,868: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087757b8>]}
2018-07-30 14:12:03,164: 14:12:03 | 7 of 23 OK created table model template.shopify_refunds_proc......... [OK in 3.71s]
2018-07-30 14:12:03,352: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bb6c748>]}
2018-07-30 14:12:03,648: 14:12:03 | 5 of 23 OK created table model template.shopify_discounts_proc....... [OK in 4.22s]
2018-07-30 14:12:05,643: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bb70358>]}
2018-07-30 14:12:06,451: 14:12:06 | 6 of 23 OK created table model template.shopify_customers_proc....... [OK in 6.50s]
2018-07-30 14:12:06,453: 14:12:06 | 8 of 23 START table model template.agg_customers..................... [RUN]
2018-07-30 14:12:06,453: Compiling model.shopify_cohort_analysis.agg_customers
2018-07-30 14:12:06,460: 14:12:06 | 9 of 23 START table model template.ga_transactions................... [RUN]
2018-07-30 14:12:06,460: Compiling model.shopify_cohort_analysis.ga_transactions
2018-07-30 14:12:06,478: 14:12:06 | 10 of 23 START table model template.shopify_products_proc............ [RUN]
2018-07-30 14:12:06,479: Compiling model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 14:12:06,536: Writing injected SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 14:12:06,539: Acquiring new bigquery connection "ga_transactions".
2018-07-30 14:12:06,545: Acquiring new bigquery connection "shopify_products_proc".
2018-07-30 14:12:06,549: Acquiring new bigquery connection "agg_customers".
2018-07-30 14:12:06,549: Re-using an available connection from the pool.
2018-07-30 14:12:06,549: Fetching data for query ga_transactions:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Google Analytics'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:12:06,549: Re-using an available connection from the pool.
2018-07-30 14:12:06,550: Fetching data for query shopify_products_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:12:06,550: Re-using an available connection from the pool.
2018-07-30 14:12:06,766: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 14:12:06,768: Fetching data for query agg_customers:
create or replace table `template`.`agg_customers`
  
  as (
    SELECT 
account,
store,
id,
created_at,
first_name,
last_name,
email,
split(email,'@')[SAFE_ORDINAL(2)] email_domain
FROM
`growth-engines-pipeline`.`template`.`shopify_customers_proc`
  );

    
2018-07-30 14:12:07,403: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 14:12:07,545: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 14:12:07,546: Fetching data for query shopify_products_proc:
create or replace table `template`.`shopify_products_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`





with products as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	product_name,
	lower(product_type) product_type,
	product_id,
	sku,
	id variant_id,
	cast(created_at as date) created_at,
	_sdc_sequence,
	first_value(_sdc_sequence) OVER (PARTITION BY product_id ORDER BY _sdc_sequence DESC) lv
	FROM (
		SELECT
		variants,
		product_type,
		title product_name,
		_sdc_sequence
		FROM `growth-engines-pipeline.shopify_lucadanni.products` 
		)
	cross join unnest(variants)
	
	

)

SELECT
b.account,
b.store,
b.platform,
max(product_type) product_type,
product_id,
variant_id,
sku,
created_at,
product_name
FROM products a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence
group by product_id, account, store, platform, sku, variant_id, created_at, product_name


  );

    
2018-07-30 14:12:07,910: Writing injected SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 14:12:08,036: Writing runtime SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 14:12:08,037: Fetching data for query ga_transactions:
create or replace table `template`.`ga_transactions`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`,`growth-engines-pipeline`.`template`.`mappings_ga_proc`




with ga_report as (

	    
	    	
		   	SELECT
		   	'yandy' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_yandy.report` 

		     UNION ALL 
	   
	    	
		   	SELECT
		   	'lucadanni' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_lucadanni.report` 

		    
	   

)


SELECT  
date,
b.store store,
c.source source,
c.medium medium,
a.campaign campaign,
concat(a.source, ' / ', a.medium) source_medium,  
case when c.platform is null then "Unmapped" else c.platform end as platform,
case when c.channel is null then "Unmapped" else c.channel end as channel,
url,
transactionid
FROM (

	SELECT 
	store_name,
	lookup_platform,
	date,
	transactionid,
	max(url) url,
	max(source) source,
	max(medium) medium,
	max(campaign) campaign
	FROM ga_report
	where lv = _sdc_sequence
	group by store_name, lookup_platform, date, transactionid

) a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name 
	AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`mappings_ga_proc` c
ON ( a.source = c.source
  AND a.medium = c.medium 
  AND a.store_name = c.store_name )


  );

    
2018-07-30 14:12:10,043: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc56080>]}
2018-07-30 14:12:10,328: 14:12:10 | 10 of 23 OK created table model template.shopify_products_proc....... [OK in 3.56s]
2018-07-30 14:12:10,824: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10927fc18>]}
2018-07-30 14:12:11,115: 14:12:11 | 8 of 23 OK created table model template.agg_customers................ [OK in 4.37s]
2018-07-30 14:12:34,654: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc49d68>]}
2018-07-30 14:12:35,320: 14:12:35 | 9 of 23 OK created table model template.ga_transactions.............. [OK in 28.19s]
2018-07-30 14:12:35,321: 14:12:35 | 11 of 23 START table model template.shopify_orders_proc.............. [RUN]
2018-07-30 14:12:35,321: Compiling model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 14:12:35,337: Acquiring new bigquery connection "shopify_orders_proc".
2018-07-30 14:12:35,337: Re-using an available connection from the pool.
2018-07-30 14:12:35,337: Fetching data for query shopify_orders_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:12:35,975: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 14:12:36,105: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 14:12:36,106: Fetching data for query shopify_orders_proc:
create or replace table `template`.`shopify_orders_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`, `growth-engines-pipeline`.`template`.`shopify_discounts_proc`





with orders as (

	
	SELECT 
	store_name,
	lookup_platform,
	created_at,
	order_number,
	quantity,
	price, 
	total_order_price_undiscounted,
	total_discounts,
	total_order_shipping_price,
	total_order_price_incl_shipping,
	checkout_id,
	product_id, 
	landing_site,
	sku, 
	variant_title, 
	variant_id,
	line_item_id,
	customer_id,
	_sdc_sequence,
	lv
	FROM (

		SELECT
		'lucadanni' store_name,
		'Shopify' as lookup_platform,
		created_at,
		order_number,
		quantity,
		cast(pre_tax_price as float64) price, 
		total_line_items_price total_order_price_undiscounted,
		total_discounts,
		cast(discounted_price as float64) total_order_shipping_price,
		total_price_usd total_order_price_incl_shipping,
		checkout_id,
		product_id, 
		landing_site,
		sku, 
		variant_title, 
		variant_id,
		_id line_item_id,
		customer.id customer_id,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(line_items), unnest(shipping_lines)
		where source_name != 'shopify_draft_order'
	)
	
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
a.order_number,
a.quantity prelim_quantity,
c.quantity refund_quantity,
case when c.quantity is not null then a.quantity - c.quantity else a.quantity end as quantity,
price prelim_revenue, 
total_order_price_undiscounted,
total_discounts,
trim(lower(d.discount_code)) discount_code,
d.discount_type,
total_order_shipping_price,
total_order_price_incl_shipping,
refund_amount,
case when refund_amount is not null then price - refund_amount else price end as revenue,
a.checkout_id,
a.product_id, 
landing_site,
sku, 
variant_title, 
a.variant_id,
a.line_item_id,	
customer_id
FROM orders a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_refunds_proc` c
ON ( a.order_number = c.order_number
	AND a.line_item_id = c.line_item_id
	AND a.store_name = c.store_name )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_discounts_proc` d
ON ( a.order_number = d.order_number 
    AND a.store_name = d.store_name )  	
where a.lv = a._sdc_sequence


  );

    
2018-07-30 14:12:47,127: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bb70358>]}
2018-07-30 14:12:47,418: 14:12:47 | 11 of 23 OK created table model template.shopify_orders_proc......... [OK in 11.81s]
2018-07-30 14:12:47,419: 14:12:47 | 12 of 23 START table model template.transaction_by_order_number...... [RUN]
2018-07-30 14:12:47,419: Compiling model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 14:12:47,430: Writing injected SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 14:12:47,437: Acquiring new bigquery connection "transaction_by_order_number".
2018-07-30 14:12:47,438: Re-using an available connection from the pool.
2018-07-30 14:12:47,577: Writing runtime SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 14:12:47,578: Fetching data for query transaction_by_order_number:
create or replace table `template`.`transaction_by_order_number`
  
  as (
    SELECT
store,
cast(created_at as date) order_date,
order_number,
customer_id,
sum(quantity) quantity,
sum(revenue) revenue,
max(total_order_shipping_price) shipping_price
FROM
`growth-engines-pipeline`.`template`.`shopify_orders_proc`
GROUP BY store, order_date, order_number, customer_id
  );

    
2018-07-30 14:12:51,561: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bb8ce48>]}
2018-07-30 14:12:52,228: 14:12:52 | 12 of 23 OK created table model template.transaction_by_order_number. [OK in 4.14s]
2018-07-30 14:12:52,229: 14:12:52 | 13 of 23 START table model template.customers_by_transaction......... [RUN]
2018-07-30 14:12:52,229: Compiling model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 14:12:52,236: Writing injected SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 14:12:52,238: Acquiring new bigquery connection "customers_by_transaction".
2018-07-30 14:12:52,238: Re-using an available connection from the pool.
2018-07-30 14:12:52,527: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 14:12:52,528: Fetching data for query customers_by_transaction:
create or replace table `template`.`customers_by_transaction`
  
  as (
    SELECT
store,
customer_id,
order_number,
order_date,
recent_order_date,
first_order_date,
case when first_order_number = order_number then 'New'
	when date_diff(order_date, recent_order_date, DAY) <= 365 then 'Repeat'
	when date_diff(order_date, recent_order_date, DAY) > 365 then 'Reactivated'
 else '' end as order_type,
quantity,
revenue,
1 as orders,
first_order_revenue,
lifetime_revenue
FROM

(

	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	quantity,
	revenue,
	lag(order_date) over w1 recent_order_date,
	first_value(order_date) over w1 first_order_date,
	first_value(order_number) over w1 first_order_number,
	first_value(revenue) over w1 first_order_revenue,
	sum(revenue) over w2 lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`transaction_by_order_number`
	WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc),
	w2 as (PARTITION BY store, customer_id)
)
  );

    
2018-07-30 14:12:55,893: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bb70358>]}
2018-07-30 14:12:57,138: 14:12:57 | 13 of 23 OK created table model template.customers_by_transaction.... [OK in 3.66s]
2018-07-30 14:12:57,139: 14:12:57 | 14 of 23 START table model template.agg_transactions................. [RUN]
2018-07-30 14:12:57,139: Compiling model.shopify_cohort_analysis.agg_transactions
2018-07-30 14:12:57,151: Writing injected SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 14:12:57,154: Acquiring new bigquery connection "agg_transactions".
2018-07-30 14:12:57,154: Re-using an available connection from the pool.
2018-07-30 14:12:57,282: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 14:12:57,283: Fetching data for query agg_transactions:
create or replace table `template`.`agg_transactions`
  
  as (
    with ga_transaction as (

	SELECT
	date, 
	store,
	transactionid,
	channel,
	platform,
	url,
	campaign
	FROM `growth-engines-pipeline`.`template`.`ga_transactions`
),

customers_by_transaction as (
	
	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	first_order_date,
	recent_order_date,
	order_type,
	quantity,
	revenue,
	orders,
	first_order_revenue,
	lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`customers_by_transaction`
)

SELECT
store,
customer_id,
order_number,
transactionid,
order_date,
first_order_date,
format_date("%Y-%m", first_order_date) AS first_order_month,
order_type,
first_order_revenue,
lifetime_revenue,
first_value(channel) over w1 as first_order_channel,
first_value(platform) over w1 as first_order_platform,
channel,
platform,
url,
campaign,
quantity,
revenue,
orders
FROM (

	SELECT
	a.store,
	a.customer_id,
	a.order_number,
	b.transactionid,
	a.order_date, 
	a.first_order_date, 
	a.order_type,
	a.first_order_revenue,
	a.lifetime_revenue,
	b.channel,
	b.platform,
	b.url,
	b.campaign,
	a.quantity,
	a.revenue,
	a.orders
	FROM customers_by_transaction a
	LEFT JOIN ga_transaction b
	ON (
	    a.store = b.store AND
	    a.order_number = b.transactionid
	)	
)
WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc)
  );

    
2018-07-30 14:13:06,012: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bb8ce48>]}
2018-07-30 14:13:06,313: 14:13:06 | 14 of 23 OK created table model template.agg_transactions............ [OK in 8.87s]
2018-07-30 14:13:06,314: 14:13:06 | 15 of 23 START table model template.monthly_cohort_stats............. [RUN]
2018-07-30 14:13:06,314: 14:13:06 | 16 of 23 START table model template.customers_proc_qoq............... [RUN]
2018-07-30 14:13:06,314: Compiling model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 14:13:06,314: 14:13:06 | 17 of 23 START table model template.customers_proc_yoy............... [RUN]
2018-07-30 14:13:06,315: Compiling model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 14:13:06,320: Compiling model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 14:13:06,330: Writing injected SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 14:13:06,353: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 14:13:06,358: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 14:13:06,361: Acquiring new bigquery connection "monthly_cohort_stats".
2018-07-30 14:13:06,361: Re-using an available connection from the pool.
2018-07-30 14:13:06,363: Acquiring new bigquery connection "customers_proc_yoy".
2018-07-30 14:13:06,364: Acquiring new bigquery connection "customers_proc_qoq".
2018-07-30 14:13:06,365: Re-using an available connection from the pool.
2018-07-30 14:13:06,369: Re-using an available connection from the pool.
2018-07-30 14:13:06,527: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 14:13:06,539: Writing runtime SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 14:13:06,555: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 14:13:06,555: Fetching data for query monthly_cohort_stats:
create or replace table `template`.`monthly_cohort_stats`
  
  as (
    WITH transactions AS (

  SELECT 
  store, 
  order_number,
  order_date,
  order_type,
  first_order_month,
  unix_date(order_date) d, 
  customer_id, 
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (

  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT 
date_in_range date,
store, 
order_type,
first_order_channel,
first_order_platform,
first_order_month,
channel,
platform,
url,
campaign,
count(distinct(customer_id)) buyers,
sum(orders) orders,
sum(quantity) quantity,
sum(revenue) revenue
FROM daterange
JOIN transactions
ON transactions.d >= daterange.unix_date_in_range_bom 
AND transactions.d <= daterange.unix_date_in_range
GROUP BY date, store, order_type, 
first_order_channel, first_order_platform, first_order_month, channel, platform, url, campaign
  );

    
2018-07-30 14:13:06,557: Fetching data for query customers_proc_qoq:
create or replace table `template`.`customers_proc_qoq`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 90 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 90 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 90 window_end_unix_date, 
    unix_date_in_range - 180 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 180 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 90 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 14:13:06,563: Fetching data for query customers_proc_yoy:
create or replace table `template`.`customers_proc_yoy`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 365 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 365 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 365 window_end_unix_date, 
    unix_date_in_range - 730 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 730 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 365 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 14:13:11,241: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bb70358>]}
2018-07-30 14:13:11,908: 14:13:11 | 15 of 23 OK created table model template.monthly_cohort_stats........ [OK in 4.93s]
2018-07-30 14:13:20,086: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc49da0>]}
2018-07-30 14:13:20,877: 14:13:20 | 16 of 23 OK created table model template.customers_proc_qoq.......... [OK in 13.77s]
2018-07-30 14:13:31,721: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bcbb0f0>]}
2018-07-30 14:13:32,024: 14:13:32 | 17 of 23 OK created table model template.customers_proc_yoy.......... [OK in 25.40s]
2018-07-30 14:13:32,025: 14:13:32 | 18 of 23 START table model template.customers_proc................... [RUN]
2018-07-30 14:13:32,025: Compiling model.shopify_cohort_analysis.customers_proc
2018-07-30 14:13:32,042: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 14:13:32,047: Acquiring new bigquery connection "customers_proc".
2018-07-30 14:13:32,047: Re-using an available connection from the pool.
2018-07-30 14:13:32,193: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 14:13:32,194: Fetching data for query customers_proc:
create or replace table `template`.`customers_proc`
  
  as (
    SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_qoq`

UNION ALL

SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_yoy`
  );

    
2018-07-30 14:13:58,446: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109002860>]}
2018-07-30 14:14:00,318: 14:14:00 | 18 of 23 OK created table model template.customers_proc.............. [OK in 26.42s]
2018-07-30 14:14:00,319: 14:14:00 | 19 of 23 START table model template.segment_proc_buyers.............. [RUN]
2018-07-30 14:14:00,319: Compiling model.shopify_cohort_analysis.segment_proc_buyers
2018-07-30 14:14:00,329: Writing injected SQL for node "model.shopify_cohort_analysis.segment_proc_buyers"
2018-07-30 14:14:00,331: Acquiring new bigquery connection "segment_proc_buyers".
2018-07-30 14:14:00,331: Re-using an available connection from the pool.
2018-07-30 14:14:00,851: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_proc_buyers"
2018-07-30 14:14:00,851: Fetching data for query segment_proc_buyers:
create or replace table `template`.`segment_proc_buyers`
  
  as (
    SELECT
store,
period,
customer_id,
date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct,
case when first_order_unix_date >= window_start_unix_date then 'New'
	else 'Existing' end as newness_segment,
case when revenue >= revenue_90pct then 'Top 10%'
	when revenue <= revenue_10pct then 'Bottom 10%'
	else 'Middle 80%' end as revenue_segment,
case when frequency = 1 then '1'
	when frequency = 2 then '2'
	when frequency > 2 then '3+'
	else null end as frequency_segment
FROM `growth-engines-pipeline`.`template`.`customers_proc`
  );

    
2018-07-30 14:14:30,721: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1090027f0>]}
2018-07-30 14:14:31,021: 14:14:31 | 19 of 23 OK created table model template.segment_proc_buyers......... [OK in 30.40s]
2018-07-30 14:14:31,022: 14:14:31 | 20 of 23 START table model template.segment_stats_buyers_agg......... [RUN]
2018-07-30 14:14:31,022: Compiling model.shopify_cohort_analysis.segment_stats_buyers_agg
2018-07-30 14:14:31,033: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_agg"
2018-07-30 14:14:31,038: Acquiring new bigquery connection "segment_stats_buyers_agg".
2018-07-30 14:14:31,038: Re-using an available connection from the pool.
2018-07-30 14:14:31,160: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_agg"
2018-07-30 14:14:31,161: Fetching data for query segment_stats_buyers_agg:
create or replace table `template`.`segment_stats_buyers_agg`
  
  as (
    WITH ty as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Year'

),

this_month_1yr as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	'' as revenue_segment,
	'' as frequency_segment,
	'' as newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	revenue_segment as revenue_segment_prev,
	frequency_segment as frequency_segment_prev,
	newness_segment as newness_segment_prev,
	recency_days as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Previous Year'

),

this_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,	
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Quarter'

),

last_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	'' as revenue_segment,
	'' as frequency_segment,
	'' as newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	revenue_segment as revenue_segment_prev,
	frequency_segment as frequency_segment_prev,
	newness_segment as newness_segment_prev,
	recency_days as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev		
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Previous Quarter'

)

SELECT
store,
period,
date, 
customer_id,
1 as buyers,
first_order_channel,
first_order_platform,	
case when max(revenue_segment) != '' then max(revenue_segment) 
	when max(revenue_segment_prev) != '' then 'Dormant'
	else '' end as revenue_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(revenue_segment_prev) end as revenue_segment_prev,
case when max(frequency_segment) != '' then max(frequency_segment) 
	when max(frequency_segment_prev) != '' then 'Dormant'
	else '' end as frequency_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(frequency_segment_prev) end as frequency_segment_prev,
max(newness_segment) newness_segment,	
max(newness_segment_prev) newness_segment_prev,
ifnull(sum(recency), 0) recency,
ifnull(sum(frequency), 0) frequency,
ifnull(sum(revenue), 0) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else 0 end as aov,
ifnull(sum(recency_prev), 0) recency_prev,
ifnull(sum(frequency_prev), 0) frequency_prev,
ifnull(sum(revenue_prev), 0) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else 0 end as aov_prev,
case when max(newness_segment_prev) != '' then 1 else 0 end as retention_eligible,
case when max(newness_segment_prev) != '' and max(newness_segment) != '' then 1 else 0 end as retention_success
FROM
(
	SELECT * FROM ty
	UNION ALL
	SELECT * FROM this_month_1yr
	UNION ALL
	SELECT * FROM this_quarter
	UNION ALL
	SELECT * FROM last_quarter

)
GROUP BY store, period, date, customer_id, first_order_channel, first_order_platform
  );

    
2018-07-30 14:14:59,898: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109002320>]}
2018-07-30 14:15:01,114: 14:15:01 | 20 of 23 OK created table model template.segment_stats_buyers_agg.... [OK in 28.88s]
2018-07-30 14:15:01,115: 14:15:01 | 21 of 23 START table model template.segment_stats_buyers_view........ [RUN]
2018-07-30 14:15:01,115: Compiling model.shopify_cohort_analysis.segment_stats_buyers_view
2018-07-30 14:15:01,131: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_view"
2018-07-30 14:15:01,135: Acquiring new bigquery connection "segment_stats_buyers_view".
2018-07-30 14:15:01,135: Re-using an available connection from the pool.
2018-07-30 14:15:01,260: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_view"
2018-07-30 14:15:01,260: Fetching data for query segment_stats_buyers_view:
create or replace table `template`.`segment_stats_buyers_view`
  
  as (
    SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
where revenue_segment != ''
and revenue_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
where frequency_segment != ''
and frequency_segment_prev != ''
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type
  );

    
2018-07-30 14:15:04,714: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1090027f0>]}
2018-07-30 14:15:05,502: 14:15:05 | 21 of 23 OK created table model template.segment_stats_buyers_view... [OK in 3.60s]
2018-07-30 14:15:05,503: 14:15:05 | 22 of 23 START table model template.buyer_segment_stats.............. [RUN]
2018-07-30 14:15:05,504: Compiling model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 14:15:05,517: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 14:15:05,519: Acquiring new bigquery connection "buyer_segment_stats".
2018-07-30 14:15:05,519: Re-using an available connection from the pool.
2018-07-30 14:15:05,675: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 14:15:05,676: Fetching data for query buyer_segment_stats:
create or replace table `template`.`buyer_segment_stats`
  
  as (
    SELECT
store,
period,
date,
view,
view_segment,
segment_type,
segment,
segment_prev,
buyers,
total_view_buyers,
case when total_view_buyers > 0 then buyers / total_view_buyers else null end as pct_of_view_segment_buyers,
recency,
frequency,
revenue,
total_view_revenue,
case when total_view_revenue > 0 then revenue / total_view_revenue else null end as pct_of_view_segment_revenue,
aov,
recency_prev,
frequency_prev,
revenue_prev,
aov_prev,
retention_rate
FROM (

	SELECT
	store,
	period,
	date,
	view,
	view_segment,
	segment_type,
	segment,
	segment_prev,
	buyers,
	sum(buyers) over w1 as total_view_buyers,
	recency,
	frequency,
	revenue,
	sum(revenue) over w1 as total_view_revenue,
	aov,
	recency_prev,
	frequency_prev,
	revenue_prev,
	aov_prev,
	retention_rate
	FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_view`
	WINDOW w1 as (PARTITION BY store, period, date, segment_type, view, view_segment)
)
  );

    
2018-07-30 14:15:07,877: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109002320>]}
2018-07-30 14:15:08,181: 14:15:08 | 22 of 23 OK created table model template.buyer_segment_stats......... [OK in 2.37s]
2018-07-30 14:15:08,182: 14:15:08 | 23 of 23 START table model template.buyer_segment_lists.............. [RUN]
2018-07-30 14:15:08,182: Compiling model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 14:15:08,195: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 14:15:08,197: Acquiring new bigquery connection "buyer_segment_lists".
2018-07-30 14:15:08,197: Re-using an available connection from the pool.
2018-07-30 14:15:08,339: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 14:15:08,339: Fetching data for query buyer_segment_lists:
create or replace table `template`.`buyer_segment_lists`
  
  as (
    SELECT
a.store,
period,
date,
customer_id,
b.first_name,
b.last_name,
b.email,
recency,
frequency,
revenue,
aov,
revenue_segment,
frequency_segment
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg` a
LEFT JOIN `growth-engines-pipeline`.`template`.`agg_customers` b
ON (
	a.store = b.store AND
	a.customer_id = b.id
)
where ( revenue_segment != '' or frequency_segment != '' )
  );

    
2018-07-30 14:15:45,506: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bde9d486-d683-466d-b96e-37e781d8a66f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1090027f0>]}
2018-07-30 14:15:45,827: 14:15:45 | 23 of 23 OK created table model template.buyer_segment_lists......... [OK in 37.32s]
2018-07-30 14:15:45,902: 14:15:45 | 
2018-07-30 14:15:45,902: 14:15:45 | Finished running 23 table models in 232.60s.
2018-07-30 14:15:45,903: Connection 'master' was left open.
2018-07-30 14:15:45,903: 
2018-07-30 14:15:45,903: Completed successfully
2018-07-30 14:15:45,904: 
Done. PASS=23 ERROR=0 SKIP=0 TOTAL=23
2018-07-30 14:15:45,905: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bb29518>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10baf4128>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10baf45c0>]}
2018-07-30 14:15:46,281: Flushing usage events
2018-07-30 14:15:46,492: sys:1: ResourceWarning: unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55500), raddr=('172.217.2.10', 443)>

2018-07-30 14:15:46,493: sys:1: ResourceWarning: unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55499), raddr=('172.217.1.205', 443)>

2018-07-30 14:15:46,493: sys:1: ResourceWarning: unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55505), raddr=('172.217.1.202', 443)>

2018-07-30 14:15:46,493: sys:1: ResourceWarning: unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55506), raddr=('172.217.1.202', 443)>

2018-07-30 14:15:46,494: sys:1: ResourceWarning: unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55508), raddr=('172.217.1.202', 443)>

2018-07-30 14:15:46,495: sys:1: ResourceWarning: unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55501), raddr=('172.217.1.205', 443)>

2018-07-30 14:15:46,495: sys:1: ResourceWarning: unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55502), raddr=('172.217.1.205', 443)>

2018-07-30 14:15:46,496: sys:1: ResourceWarning: unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55507), raddr=('172.217.1.202', 443)>

2018-07-30 14:15:46,496: sys:1: ResourceWarning: unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55503), raddr=('172.217.1.205', 443)>

2018-07-30 14:15:46,497: sys:1: ResourceWarning: unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55504), raddr=('172.217.1.205', 443)>

2018-07-30 14:16:59,915: Tracking: tracking
2018-07-30 14:16:59,921: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10514a4e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10514ac50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10514ac88>]}
2018-07-30 14:17:00,832: Loading dependency project from /usr/local/Cellar/dbt/0.10.1/libexec/lib/python3.6/site-packages/dbt/include
2018-07-30 14:17:00,860: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/shopify-cohort-analysis/dbt_modules
2018-07-30 14:17:00,870: Parsing get_column_values.sql
2018-07-30 14:17:00,897: Parsing get_url_parameter.sql
2018-07-30 14:17:00,904: Parsing split_part.sql
2018-07-30 14:17:00,916: Parsing table_exists.sql
2018-07-30 14:17:00,932: Parsing core.sql
2018-07-30 14:17:00,950: Parsing adapters/bigquery.sql
2018-07-30 14:17:00,959: Parsing adapters/common.sql
2018-07-30 14:17:00,988: Parsing adapters/redshift.sql
2018-07-30 14:17:01,017: Parsing adapters/snowflake.sql
2018-07-30 14:17:01,025: Parsing etc/bigquery.sql
2018-07-30 14:17:01,030: Parsing etc/datetime.sql
2018-07-30 14:17:01,074: Parsing etc/get_custom_schema.sql
2018-07-30 14:17:01,086: Parsing materializations/helpers.sql
2018-07-30 14:17:01,121: Parsing materializations/archive/archive.sql
2018-07-30 14:17:01,183: Parsing materializations/incremental/incremental.sql
2018-07-30 14:17:01,232: Parsing materializations/seed/bigquery.sql
2018-07-30 14:17:01,245: Parsing materializations/seed/seed.sql
2018-07-30 14:17:01,293: Parsing materializations/table/bigquery_table.sql
2018-07-30 14:17:01,325: Parsing materializations/table/table.sql
2018-07-30 14:17:01,358: Parsing materializations/view/bigquery_view.sql
2018-07-30 14:17:01,378: Parsing materializations/view/view.sql
2018-07-30 14:17:01,413: Parsing schema_tests/accepted_values.sql
2018-07-30 14:17:01,422: Parsing schema_tests/not_null.sql
2018-07-30 14:17:01,426: Parsing schema_tests/relationships.sql
2018-07-30 14:17:01,432: Parsing schema_tests/unique.sql
2018-07-30 14:17:01,499: Parsing model.shopify_cohort_analysis.all_dates
2018-07-30 14:17:01,504: Parsing model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 14:17:01,508: Parsing model.shopify_cohort_analysis.monthend_dates
2018-07-30 14:17:01,510: Parsing model.shopify_cohort_analysis.stores_proc
2018-07-30 14:17:01,513: Parsing model.shopify_cohort_analysis.ga_transactions
2018-07-30 14:17:01,523: Parsing model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 14:17:01,530: Parsing model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 14:17:01,539: Parsing model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 14:17:01,550: Parsing model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 14:17:01,561: Parsing model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 14:17:01,570: Parsing model.shopify_cohort_analysis.agg_customers
2018-07-30 14:17:01,576: Parsing model.shopify_cohort_analysis.agg_transactions
2018-07-30 14:17:01,582: Parsing model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 14:17:01,590: Parsing model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 14:17:01,595: Parsing model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 14:17:01,600: Parsing model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 14:17:01,603: Parsing model.shopify_cohort_analysis.customers_proc
2018-07-30 14:17:01,611: Parsing model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 14:17:01,617: Parsing model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 14:17:01,626: Parsing model.shopify_cohort_analysis.segment_proc_buyers
2018-07-30 14:17:01,630: Parsing model.shopify_cohort_analysis.segment_stats_buyers_agg
2018-07-30 14:17:01,641: Parsing model.shopify_cohort_analysis.segment_stats_buyers_view
2018-07-30 14:17:01,654: Parsing model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 14:17:01,683: Found 23 models, 0 tests, 0 archives, 0 analyses, 62 macros, 0 operations, 0 seed files
2018-07-30 14:17:01,696: 
2018-07-30 14:17:01,711: Acquiring new bigquery connection "master".
2018-07-30 14:17:01,711: Opening a new connection (0 currently allocated)
2018-07-30 14:17:02,986: 14:17:02 | Concurrency: 4 threads (target='template')
2018-07-30 14:17:02,986: 14:17:02 | 
2018-07-30 14:17:03,077: 14:17:03 | 1 of 23 START table model template.stores_proc....................... [RUN]
2018-07-30 14:17:03,077: Compiling model.shopify_cohort_analysis.stores_proc
2018-07-30 14:17:03,077: 14:17:03 | 2 of 23 START table model template.monthend_dates.................... [RUN]
2018-07-30 14:17:03,084: Compiling model.shopify_cohort_analysis.monthend_dates
2018-07-30 14:17:03,094: Writing injected SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 14:17:03,095: Writing injected SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 14:17:03,077: 14:17:03 | 3 of 23 START table model template.all_dates......................... [RUN]
2018-07-30 14:17:03,077: 14:17:03 | 4 of 23 START table model template.mappings_ga_proc.................. [RUN]
2018-07-30 14:17:03,096: Compiling model.shopify_cohort_analysis.all_dates
2018-07-30 14:17:03,096: Compiling model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 14:17:03,103: Writing injected SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 14:17:03,113: Acquiring new bigquery connection "monthend_dates".
2018-07-30 14:17:03,119: Opening a new connection (1 currently allocated)
2018-07-30 14:17:03,115: Acquiring new bigquery connection "all_dates".
2018-07-30 14:17:03,131: Opening a new connection (2 currently allocated)
2018-07-30 14:17:03,130: Writing injected SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 14:17:03,119: Acquiring new bigquery connection "stores_proc".
2018-07-30 14:17:03,137: Opening a new connection (3 currently allocated)
2018-07-30 14:17:03,142: Acquiring new bigquery connection "mappings_ga_proc".
2018-07-30 14:17:03,153: Opening a new connection (4 currently allocated)
2018-07-30 14:17:03,632: Writing runtime SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 14:17:03,656: Writing runtime SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 14:17:03,679: Writing runtime SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 14:17:03,679: Fetching data for query all_dates:
create or replace table `template`.`all_dates`
  
  as (
    SELECT 
date_in_range,
unix_date(date_in_range) unix_date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
  );

    
2018-07-30 14:17:03,686: Fetching data for query stores_proc:
create or replace table `template`.`stores_proc`
  
  as (
    select 
store,
store_name,
account,
platform,
max(time_of_entry) time_of_entry

from  ( 

SELECT  
client store,
client_name store_name,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.accounts` 
where client_name != ''

) 

WHERE lv = time_of_entry
group by store, store_name, account, platform
  );

    
2018-07-30 14:17:03,693: Writing runtime SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 14:17:03,694: Fetching data for query mappings_ga_proc:
create or replace table `template`.`mappings_ga_proc`
  
  as (
    select 
store,
account,
store_name,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client store,
account,
client_name store_name,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.mappings_ga` 

) 

WHERE lv = time_of_entry
group by store, account, store_name, source, medium, platform_n, channel_n, time_of_entry
  );

    
2018-07-30 14:17:03,703: Fetching data for query monthend_dates:
create or replace table `template`.`monthend_dates`
  
  as (
    SELECT
date_in_range,
date_in_range_bom,
date_in_range_bom_mom,
unix_date_in_range,
unix_date_in_range_bom,
unix_date(date_in_range_bom_mom) unix_date_in_range_bom_mom,
yyyymm,
date_in_range_yoy,
unix_date(date_in_range_yoy) unix_date_in_range_yoy

FROM
(
	SELECT 
	date_in_range,
	date_in_range_bom,
	date_sub(date_in_range_bom, INTERVAL 1 MONTH) date_in_range_bom_mom,
	date_sub(date_in_range, INTERVAL 1 YEAR) date_in_range_yoy,
	unix_date_in_range,
	unix_date(date_in_range_bom) unix_date_in_range_bom,
	yyyymm,
	first_value(date_in_range) over (partition by yyyymm order by date_in_range desc) monthend_date_in_range
	FROM
	( 
		SELECT 
		date_in_range,
		date_trunc( date_in_range, MONTH) date_in_range_bom,
		unix_date(date_in_range) unix_date_in_range,
		format_date("%Y-%m", date_in_range) AS yyyymm
		FROM UNNEST(
		    GENERATE_DATE_ARRAY(DATE('2016-01-31'), CURRENT_DATE(), INTERVAL 1 DAY)
		) AS date_in_range
	)
)
where date_in_range = monthend_date_in_range
  );

    
2018-07-30 14:17:05,593: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105285668>]}
2018-07-30 14:17:05,598: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105285b70>]}
2018-07-30 14:17:05,602: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052854a8>]}
2018-07-30 14:17:05,808: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105285160>]}
2018-07-30 14:17:06,274: 14:17:06 | 2 of 23 OK created table model template.monthend_dates............... [OK in 2.51s]
2018-07-30 14:17:06,902: 14:17:06 | 3 of 23 OK created table model template.all_dates.................... [OK in 2.50s]
2018-07-30 14:17:07,571: 14:17:07 | 4 of 23 OK created table model template.mappings_ga_proc............. [OK in 2.51s]
2018-07-30 14:17:08,393: 14:17:08 | 1 of 23 OK created table model template.stores_proc.................. [OK in 2.73s]
2018-07-30 14:17:08,393: 14:17:08 | 5 of 23 START table model template.shopify_refunds_proc.............. [RUN]
2018-07-30 14:17:08,394: 14:17:08 | 6 of 23 START table model template.shopify_discounts_proc............ [RUN]
2018-07-30 14:17:08,394: Compiling model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 14:17:08,394: 14:17:08 | 7 of 23 START table model template.shopify_customers_proc............ [RUN]
2018-07-30 14:17:08,395: Compiling model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 14:17:08,400: Compiling model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 14:17:08,412: Acquiring new bigquery connection "shopify_discounts_proc".
2018-07-30 14:17:08,418: Re-using an available connection from the pool.
2018-07-30 14:17:08,418: Fetching data for query shopify_discounts_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:17:08,423: Acquiring new bigquery connection "shopify_refunds_proc".
2018-07-30 14:17:08,424: Re-using an available connection from the pool.
2018-07-30 14:17:08,424: Fetching data for query shopify_refunds_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:17:08,431: Acquiring new bigquery connection "shopify_customers_proc".
2018-07-30 14:17:08,433: Re-using an available connection from the pool.
2018-07-30 14:17:08,433: Fetching data for query shopify_customers_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:17:10,454: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 14:17:10,600: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 14:17:10,601: Fetching data for query shopify_discounts_proc:
create or replace table `template`.`shopify_discounts_proc`
  
  as (
    



with orders as (

	
		SELECT
		'lucadanni' store_name,
		created_at,
		order_number,
		code discount_code,
		type discount_type,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(discount_codes)
		where source_name != 'shopify_draft_order'
	
	
	

)

SELECT
store_name,
order_number,
discount_code,
discount_type
FROM orders
where lv = _sdc_sequence


  );

    
2018-07-30 14:17:10,607: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 14:17:10,762: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 14:17:10,762: Fetching data for query shopify_refunds_proc:
create or replace table `template`.`shopify_refunds_proc`
  
  as (
    



with refunds as (

	
	SELECT
	'lucadanni' store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal,
	line_item.variant_id variant_id,
	line_item.id refund_id,
 	_sdc_sequence
	FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
	cross join unnest(refunds), unnest(refund_line_items)
  	where financial_status like '%refund%'
	
	

)

SELECT * 
FROM 
	(
    SELECT
    store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal refund_amount,
	variant_id,
	refund_id,
 	_sdc_sequence,
    first_value(_sdc_sequence) OVER (PARTITION BY order_number, line_item_id ORDER BY _sdc_sequence DESC) lv
    FROM refunds
   	) 
WHERE lv = _sdc_sequence


  );

    
2018-07-30 14:17:10,949: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 14:17:11,092: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 14:17:11,092: Fetching data for query shopify_customers_proc:
create or replace table `template`.`shopify_customers_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`





with customers as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	created_at,
	id,
	first_name,
	last_name,
	email,
	_sdc_sequence,
	first_value(_sdc_sequence) over (partition by id order by _sdc_sequence desc) lv
	FROM `growth-engines-pipeline.shopify_lucadanni.customers` 
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
id,
first_name,
last_name,
email
FROM customers a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence


  );

    
2018-07-30 14:17:12,771: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105380828>]}
2018-07-30 14:17:13,162: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105284898>]}
2018-07-30 14:17:13,166: 14:17:13 | 5 of 23 OK created table model template.shopify_refunds_proc......... [OK in 4.38s]
2018-07-30 14:17:13,466: 14:17:13 | 6 of 23 OK created table model template.shopify_discounts_proc....... [OK in 4.77s]
2018-07-30 14:17:15,581: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052185c0>]}
2018-07-30 14:17:16,199: 14:17:16 | 7 of 23 OK created table model template.shopify_customers_proc....... [OK in 7.18s]
2018-07-30 14:17:16,199: 14:17:16 | 8 of 23 START table model template.agg_customers..................... [RUN]
2018-07-30 14:17:16,200: Compiling model.shopify_cohort_analysis.agg_customers
2018-07-30 14:17:16,199: 14:17:16 | 9 of 23 START table model template.shopify_products_proc............. [RUN]
2018-07-30 14:17:16,206: Writing injected SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 14:17:16,207: Compiling model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 14:17:16,200: 14:17:16 | 10 of 23 START table model template.ga_transactions.................. [RUN]
2018-07-30 14:17:16,208: Compiling model.shopify_cohort_analysis.ga_transactions
2018-07-30 14:17:16,222: Acquiring new bigquery connection "agg_customers".
2018-07-30 14:17:16,230: Re-using an available connection from the pool.
2018-07-30 14:17:16,224: Acquiring new bigquery connection "shopify_products_proc".
2018-07-30 14:17:16,230: Acquiring new bigquery connection "ga_transactions".
2018-07-30 14:17:16,230: Re-using an available connection from the pool.
2018-07-30 14:17:16,231: Fetching data for query shopify_products_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:17:16,231: Re-using an available connection from the pool.
2018-07-30 14:17:16,235: Fetching data for query ga_transactions:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Google Analytics'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:17:16,538: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 14:17:16,541: Fetching data for query agg_customers:
create or replace table `template`.`agg_customers`
  
  as (
    SELECT 
account,
store,
id,
created_at,
first_name,
last_name,
email,
split(email,'@')[SAFE_ORDINAL(2)] email_domain
FROM
`growth-engines-pipeline`.`template`.`shopify_customers_proc`
  );

    
2018-07-30 14:17:17,328: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 14:17:17,509: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 14:17:17,510: Fetching data for query shopify_products_proc:
create or replace table `template`.`shopify_products_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`





with products as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	product_name,
	lower(product_type) product_type,
	product_id,
	sku,
	id variant_id,
	cast(created_at as date) created_at,
	_sdc_sequence,
	first_value(_sdc_sequence) OVER (PARTITION BY product_id ORDER BY _sdc_sequence DESC) lv
	FROM (
		SELECT
		variants,
		product_type,
		title product_name,
		_sdc_sequence
		FROM `growth-engines-pipeline.shopify_lucadanni.products` 
		)
	cross join unnest(variants)
	
	

)

SELECT
b.account,
b.store,
b.platform,
max(product_type) product_type,
product_id,
variant_id,
sku,
created_at,
product_name
FROM products a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence
group by product_id, account, store, platform, sku, variant_id, created_at, product_name


  );

    
2018-07-30 14:17:18,090: Writing injected SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 14:17:18,260: Writing runtime SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 14:17:18,261: Fetching data for query ga_transactions:
create or replace table `template`.`ga_transactions`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`,`growth-engines-pipeline`.`template`.`mappings_ga_proc`




with ga_report as (

	    
	    	
		   	SELECT
		   	'yandy' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_yandy.report` 

		     UNION ALL 
	   
	    	
		   	SELECT
		   	'lucadanni' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_lucadanni.report` 

		    
	   

)


SELECT  
date,
b.store store,
c.source source,
c.medium medium,
a.campaign campaign,
concat(a.source, ' / ', a.medium) source_medium,  
case when c.platform is null then "Unmapped" else c.platform end as platform,
case when c.channel is null then "Unmapped" else c.channel end as channel,
url,
transactionid
FROM (

	SELECT 
	store_name,
	lookup_platform,
	date,
	transactionid,
	max(url) url,
	max(source) source,
	max(medium) medium,
	max(campaign) campaign
	FROM ga_report
	where lv = _sdc_sequence
	group by store_name, lookup_platform, date, transactionid

) a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name 
	AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`mappings_ga_proc` c
ON ( a.source = c.source
  AND a.medium = c.medium 
  AND a.store_name = c.store_name )


  );

    
2018-07-30 14:17:19,635: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053ad748>]}
2018-07-30 14:17:19,931: 14:17:19 | 9 of 23 OK created table model template.shopify_products_proc........ [OK in 3.43s]
2018-07-30 14:17:20,860: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102986c18>]}
2018-07-30 14:17:21,177: 14:17:21 | 8 of 23 OK created table model template.agg_customers................ [OK in 4.66s]
2018-07-30 14:17:43,103: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053ad198>]}
2018-07-30 14:17:43,866: 14:17:43 | 10 of 23 OK created table model template.ga_transactions............. [OK in 26.89s]
2018-07-30 14:17:43,867: 14:17:43 | 11 of 23 START table model template.shopify_orders_proc.............. [RUN]
2018-07-30 14:17:43,868: Compiling model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 14:17:43,884: Acquiring new bigquery connection "shopify_orders_proc".
2018-07-30 14:17:43,884: Re-using an available connection from the pool.
2018-07-30 14:17:43,884: Fetching data for query shopify_orders_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:17:44,835: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 14:17:45,009: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 14:17:45,009: Fetching data for query shopify_orders_proc:
create or replace table `template`.`shopify_orders_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`, `growth-engines-pipeline`.`template`.`shopify_discounts_proc`





with orders as (

	
	SELECT 
	store_name,
	lookup_platform,
	created_at,
	order_number,
	quantity,
	price, 
	total_order_price_undiscounted,
	total_discounts,
	total_order_shipping_price,
	total_order_price_incl_shipping,
	checkout_id,
	product_id, 
	landing_site,
	sku, 
	variant_title, 
	variant_id,
	line_item_id,
	customer_id,
	_sdc_sequence,
	lv
	FROM (

		SELECT
		'lucadanni' store_name,
		'Shopify' as lookup_platform,
		created_at,
		order_number,
		quantity,
		cast(pre_tax_price as float64) price, 
		total_line_items_price total_order_price_undiscounted,
		total_discounts,
		cast(discounted_price as float64) total_order_shipping_price,
		total_price_usd total_order_price_incl_shipping,
		checkout_id,
		product_id, 
		landing_site,
		sku, 
		variant_title, 
		variant_id,
		_id line_item_id,
		customer.id customer_id,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(line_items), unnest(shipping_lines)
		where source_name != 'shopify_draft_order'
	)
	
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
a.order_number,
a.quantity prelim_quantity,
c.quantity refund_quantity,
case when c.quantity is not null then a.quantity - c.quantity else a.quantity end as quantity,
price prelim_revenue, 
total_order_price_undiscounted,
total_discounts,
trim(lower(d.discount_code)) discount_code,
d.discount_type,
total_order_shipping_price,
total_order_price_incl_shipping,
refund_amount,
case when refund_amount is not null then price - refund_amount else price end as revenue,
a.checkout_id,
a.product_id, 
landing_site,
sku, 
variant_title, 
a.variant_id,
a.line_item_id,	
customer_id
FROM orders a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_refunds_proc` c
ON ( a.order_number = c.order_number
	AND a.line_item_id = c.line_item_id
	AND a.store_name = c.store_name )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_discounts_proc` d
ON ( a.order_number = d.order_number 
    AND a.store_name = d.store_name )  	
where a.lv = a._sdc_sequence


  );

    
2018-07-30 14:17:56,000: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052185c0>]}
2018-07-30 14:17:56,310: 14:17:56 | 11 of 23 OK created table model template.shopify_orders_proc......... [OK in 12.13s]
2018-07-30 14:17:56,310: 14:17:56 | 12 of 23 START table model template.transaction_by_order_number...... [RUN]
2018-07-30 14:17:56,311: Compiling model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 14:17:56,321: Writing injected SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 14:17:56,325: Acquiring new bigquery connection "transaction_by_order_number".
2018-07-30 14:17:56,325: Re-using an available connection from the pool.
2018-07-30 14:17:56,518: Writing runtime SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 14:17:56,518: Fetching data for query transaction_by_order_number:
create or replace table `template`.`transaction_by_order_number`
  
  as (
    SELECT
store,
cast(created_at as date) order_date,
order_number,
customer_id,
sum(quantity) quantity,
sum(revenue) revenue,
max(total_order_shipping_price) shipping_price
FROM
`growth-engines-pipeline`.`template`.`shopify_orders_proc`
GROUP BY store, order_date, order_number, customer_id
  );

    
2018-07-30 14:18:00,945: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053ad198>]}
2018-07-30 14:18:02,670: 14:18:02 | 12 of 23 OK created table model template.transaction_by_order_number. [OK in 4.63s]
2018-07-30 14:18:02,671: 14:18:02 | 13 of 23 START table model template.customers_by_transaction......... [RUN]
2018-07-30 14:18:02,672: Compiling model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 14:18:02,679: Writing injected SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 14:18:02,682: Acquiring new bigquery connection "customers_by_transaction".
2018-07-30 14:18:02,682: Re-using an available connection from the pool.
2018-07-30 14:18:02,854: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 14:18:02,855: Fetching data for query customers_by_transaction:
create or replace table `template`.`customers_by_transaction`
  
  as (
    SELECT
store,
customer_id,
order_number,
order_date,
recent_order_date,
first_order_date,
case when first_order_number = order_number then 'New'
	when date_diff(order_date, recent_order_date, DAY) <= 365 then 'Repeat'
	when date_diff(order_date, recent_order_date, DAY) > 365 then 'Reactivated'
 else '' end as order_type,
quantity,
revenue,
1 as orders,
first_order_revenue,
lifetime_revenue
FROM

(

	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	quantity,
	revenue,
	lag(order_date) over w1 recent_order_date,
	first_value(order_date) over w1 first_order_date,
	first_value(order_number) over w1 first_order_number,
	first_value(revenue) over w1 first_order_revenue,
	sum(revenue) over w2 lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`transaction_by_order_number`
	WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc),
	w2 as (PARTITION BY store, customer_id)
)
  );

    
2018-07-30 14:18:07,277: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052f1b00>]}
2018-07-30 14:18:07,566: 14:18:07 | 13 of 23 OK created table model template.customers_by_transaction.... [OK in 4.60s]
2018-07-30 14:18:07,567: 14:18:07 | 14 of 23 START table model template.agg_transactions................. [RUN]
2018-07-30 14:18:07,567: Compiling model.shopify_cohort_analysis.agg_transactions
2018-07-30 14:18:07,580: Writing injected SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 14:18:07,583: Acquiring new bigquery connection "agg_transactions".
2018-07-30 14:18:07,583: Re-using an available connection from the pool.
2018-07-30 14:18:07,712: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 14:18:07,713: Fetching data for query agg_transactions:
create or replace table `template`.`agg_transactions`
  
  as (
    with ga_transaction as (

	SELECT
	date, 
	store,
	transactionid,
	channel,
	platform,
	url,
	campaign
	FROM `growth-engines-pipeline`.`template`.`ga_transactions`
),

customers_by_transaction as (
	
	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	first_order_date,
	recent_order_date,
	order_type,
	quantity,
	revenue,
	orders,
	first_order_revenue,
	lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`customers_by_transaction`
)

SELECT
store,
customer_id,
order_number,
transactionid,
order_date,
first_order_date,
format_date("%Y-%m", first_order_date) AS first_order_month,
order_type,
first_order_revenue,
lifetime_revenue,
first_value(channel) over w1 as first_order_channel,
first_value(platform) over w1 as first_order_platform,
channel,
platform,
url,
campaign,
quantity,
revenue,
orders
FROM (

	SELECT
	a.store,
	a.customer_id,
	a.order_number,
	b.transactionid,
	a.order_date, 
	a.first_order_date, 
	a.order_type,
	a.first_order_revenue,
	a.lifetime_revenue,
	b.channel,
	b.platform,
	b.url,
	b.campaign,
	a.quantity,
	a.revenue,
	a.orders
	FROM customers_by_transaction a
	LEFT JOIN ga_transaction b
	ON (
	    a.store = b.store AND
	    a.order_number = b.transactionid
	)	
)
WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc)
  );

    
2018-07-30 14:18:15,736: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053ad198>]}
2018-07-30 14:18:16,153: 14:18:16 | 14 of 23 OK created table model template.agg_transactions............ [OK in 8.17s]
2018-07-30 14:18:16,154: 14:18:16 | 15 of 23 START table model template.customers_proc_qoq............... [RUN]
2018-07-30 14:18:16,154: 14:18:16 | 16 of 23 START table model template.monthly_cohort_stats............. [RUN]
2018-07-30 14:18:16,155: 14:18:16 | 17 of 23 START table model template.customers_proc_yoy............... [RUN]
2018-07-30 14:18:16,155: Compiling model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 14:18:16,156: Compiling model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 14:18:16,156: Compiling model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 14:18:16,168: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 14:18:16,174: Writing injected SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 14:18:16,186: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 14:18:16,188: Acquiring new bigquery connection "customers_proc_qoq".
2018-07-30 14:18:16,188: Re-using an available connection from the pool.
2018-07-30 14:18:16,190: Acquiring new bigquery connection "monthly_cohort_stats".
2018-07-30 14:18:16,191: Acquiring new bigquery connection "customers_proc_yoy".
2018-07-30 14:18:16,192: Re-using an available connection from the pool.
2018-07-30 14:18:16,194: Re-using an available connection from the pool.
2018-07-30 14:18:16,388: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 14:18:16,396: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 14:18:16,397: Fetching data for query customers_proc_yoy:
create or replace table `template`.`customers_proc_yoy`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 365 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 365 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 365 window_end_unix_date, 
    unix_date_in_range - 730 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 730 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 365 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 14:18:16,397: Fetching data for query customers_proc_qoq:
create or replace table `template`.`customers_proc_qoq`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 90 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 90 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 90 window_end_unix_date, 
    unix_date_in_range - 180 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 180 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 90 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 14:18:16,412: Writing runtime SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 14:18:16,413: Fetching data for query monthly_cohort_stats:
create or replace table `template`.`monthly_cohort_stats`
  
  as (
    WITH transactions AS (

  SELECT 
  store, 
  order_number,
  order_date,
  order_type,
  first_order_month,
  unix_date(order_date) d, 
  customer_id, 
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (

  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT 
date_in_range date,
store, 
order_type,
first_order_channel,
first_order_platform,
first_order_month,
channel,
platform,
url,
campaign,
count(distinct(customer_id)) buyers,
sum(orders) orders,
sum(quantity) quantity,
sum(revenue) revenue
FROM daterange
JOIN transactions
ON transactions.d >= daterange.unix_date_in_range_bom 
AND transactions.d <= daterange.unix_date_in_range
GROUP BY date, store, order_type, 
first_order_channel, first_order_platform, first_order_month, channel, platform, url, campaign
  );

    
2018-07-30 14:18:21,277: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105218128>]}
2018-07-30 14:18:22,524: 14:18:22 | 16 of 23 OK created table model template.monthly_cohort_stats........ [OK in 5.12s]
2018-07-30 14:18:28,937: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052f1b00>]}
2018-07-30 14:18:29,332: 14:18:29 | 15 of 23 OK created table model template.customers_proc_qoq.......... [OK in 12.78s]
2018-07-30 14:18:42,150: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052aa358>]}
2018-07-30 14:18:42,996: 14:18:42 | 17 of 23 OK created table model template.customers_proc_yoy.......... [OK in 25.99s]
2018-07-30 14:18:42,997: 14:18:42 | 18 of 23 START table model template.customers_proc................... [RUN]
2018-07-30 14:18:42,997: Compiling model.shopify_cohort_analysis.customers_proc
2018-07-30 14:18:43,010: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 14:18:43,012: Acquiring new bigquery connection "customers_proc".
2018-07-30 14:18:43,013: Re-using an available connection from the pool.
2018-07-30 14:18:43,242: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 14:18:43,242: Fetching data for query customers_proc:
create or replace table `template`.`customers_proc`
  
  as (
    SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_qoq`

UNION ALL

SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_yoy`
  );

    
2018-07-30 14:19:13,142: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10514a630>]}
2018-07-30 14:19:14,502: 14:19:14 | 18 of 23 OK created table model template.customers_proc.............. [OK in 30.14s]
2018-07-30 14:19:14,503: 14:19:14 | 19 of 23 START table model template.segment_proc_buyers.............. [RUN]
2018-07-30 14:19:14,503: Compiling model.shopify_cohort_analysis.segment_proc_buyers
2018-07-30 14:19:14,513: Writing injected SQL for node "model.shopify_cohort_analysis.segment_proc_buyers"
2018-07-30 14:19:14,515: Acquiring new bigquery connection "segment_proc_buyers".
2018-07-30 14:19:14,515: Re-using an available connection from the pool.
2018-07-30 14:19:15,085: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_proc_buyers"
2018-07-30 14:19:15,086: Fetching data for query segment_proc_buyers:
create or replace table `template`.`segment_proc_buyers`
  
  as (
    SELECT
store,
period,
customer_id,
date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct,
case when first_order_unix_date >= window_start_unix_date then 'New'
	else 'Existing' end as newness_segment,
case when revenue >= revenue_90pct then 'Top 10%'
	when revenue <= revenue_10pct then 'Bottom 10%'
	else 'Middle 80%' end as revenue_segment,
case when frequency = 1 then '1'
	when frequency = 2 then '2'
	when frequency > 2 then '3+'
	else null end as frequency_segment
FROM `growth-engines-pipeline`.`template`.`customers_proc`
  );

    
2018-07-30 14:19:43,383: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102683080>]}
2018-07-30 14:19:44,711: 14:19:44 | 19 of 23 OK created table model template.segment_proc_buyers......... [OK in 28.88s]
2018-07-30 14:19:44,712: 14:19:44 | 20 of 23 START table model template.segment_stats_buyers_agg......... [RUN]
2018-07-30 14:19:44,712: Compiling model.shopify_cohort_analysis.segment_stats_buyers_agg
2018-07-30 14:19:44,726: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_agg"
2018-07-30 14:19:44,729: Acquiring new bigquery connection "segment_stats_buyers_agg".
2018-07-30 14:19:44,729: Re-using an available connection from the pool.
2018-07-30 14:19:44,916: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_agg"
2018-07-30 14:19:44,917: Fetching data for query segment_stats_buyers_agg:
create or replace table `template`.`segment_stats_buyers_agg`
  
  as (
    WITH ty as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Year'

),

this_month_1yr as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	'' as revenue_segment,
	'' as frequency_segment,
	'' as newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	revenue_segment as revenue_segment_prev,
	frequency_segment as frequency_segment_prev,
	newness_segment as newness_segment_prev,
	recency_days as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Previous Year'

),

this_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,	
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	'' as revenue_segment_prev,
	'' as frequency_segment_prev,
	'' as newness_segment_prev,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Quarter'

),

last_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	'' as revenue_segment,
	'' as frequency_segment,
	'' as newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	revenue_segment as revenue_segment_prev,
	frequency_segment as frequency_segment_prev,
	newness_segment as newness_segment_prev,
	recency_days as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev		
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Previous Quarter'

)

SELECT
store,
period,
date, 
customer_id,
1 as buyers,
first_order_channel,
first_order_platform,	
case when max(revenue_segment) != '' then max(revenue_segment) 
	when max(revenue_segment_prev) != '' then 'Dormant'
	else '' end as revenue_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(revenue_segment_prev) end as revenue_segment_prev,
case when max(frequency_segment) != '' then max(frequency_segment) 
	when max(frequency_segment_prev) != '' then 'Dormant'
	else '' end as frequency_segment,
case when max(newness_segment) = 'New' then 'New since prior period' 
	else max(frequency_segment_prev) end as frequency_segment_prev,
max(newness_segment) newness_segment,	
max(newness_segment_prev) newness_segment_prev,
ifnull(sum(recency), 0) recency,
ifnull(sum(frequency), 0) frequency,
ifnull(sum(revenue), 0) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else 0 end as aov,
ifnull(sum(recency_prev), 0) recency_prev,
ifnull(sum(frequency_prev), 0) frequency_prev,
ifnull(sum(revenue_prev), 0) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else 0 end as aov_prev,
case when max(newness_segment_prev) != '' then 1 else 0 end as retention_eligible,
case when max(newness_segment_prev) != '' and max(newness_segment) != '' then 1 else 0 end as retention_success
FROM
(
	SELECT * FROM ty
	UNION ALL
	SELECT * FROM this_month_1yr
	UNION ALL
	SELECT * FROM this_quarter
	UNION ALL
	SELECT * FROM last_quarter

)
GROUP BY store, period, date, customer_id, first_order_channel, first_order_platform
  );

    
2018-07-30 14:20:10,732: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10514a630>]}
2018-07-30 14:20:11,913: 14:20:11 | 20 of 23 OK created table model template.segment_stats_buyers_agg.... [OK in 26.02s]
2018-07-30 14:20:11,915: 14:20:11 | 21 of 23 START table model template.segment_stats_buyers_view........ [RUN]
2018-07-30 14:20:11,915: Compiling model.shopify_cohort_analysis.segment_stats_buyers_view
2018-07-30 14:20:11,928: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_view"
2018-07-30 14:20:11,930: Acquiring new bigquery connection "segment_stats_buyers_view".
2018-07-30 14:20:11,930: Re-using an available connection from the pool.
2018-07-30 14:20:12,277: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_view"
2018-07-30 14:20:12,278: Fetching data for query segment_stats_buyers_view:
create or replace table `template`.`segment_stats_buyers_view`
  
  as (
    SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
revenue_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
frequency_segment_prev as segment_prev,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, segment_prev, view, view_segment, segment_type
  );

    
2018-07-30 14:20:17,537: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1026530b8>]}
2018-07-30 14:20:19,196: 14:20:19 | 21 of 23 OK created table model template.segment_stats_buyers_view... [OK in 5.62s]
2018-07-30 14:20:19,197: 14:20:19 | 22 of 23 START table model template.buyer_segment_stats.............. [RUN]
2018-07-30 14:20:19,197: Compiling model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 14:20:19,206: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 14:20:19,208: Acquiring new bigquery connection "buyer_segment_stats".
2018-07-30 14:20:19,208: Re-using an available connection from the pool.
2018-07-30 14:20:19,479: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 14:20:19,479: Fetching data for query buyer_segment_stats:
create or replace table `template`.`buyer_segment_stats`
  
  as (
    SELECT
store,
period,
date,
view,
view_segment,
segment_type,
segment,
segment_prev,
buyers,
total_view_buyers,
case when total_view_buyers > 0 then buyers / total_view_buyers else null end as pct_of_view_segment_buyers,
recency,
frequency,
revenue,
total_view_revenue,
case when total_view_revenue > 0 then revenue / total_view_revenue else null end as pct_of_view_segment_revenue,
aov,
recency_prev,
frequency_prev,
revenue_prev,
aov_prev,
retention_rate
FROM (

	SELECT
	store,
	period,
	date,
	view,
	view_segment,
	segment_type,
	segment,
	segment_prev,
	buyers,
	sum(buyers) over w1 as total_view_buyers,
	recency,
	frequency,
	revenue,
	sum(revenue) over w1 as total_view_revenue,
	aov,
	recency_prev,
	frequency_prev,
	revenue_prev,
	aov_prev,
	retention_rate
	FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_view`
	WINDOW w1 as (PARTITION BY store, period, date, segment_type, view, view_segment)
)
  );

    
2018-07-30 14:20:22,216: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10514a630>]}
2018-07-30 14:20:22,763: 14:20:22 | 22 of 23 OK created table model template.buyer_segment_stats......... [OK in 3.02s]
2018-07-30 14:20:22,765: 14:20:22 | 23 of 23 START table model template.buyer_segment_lists.............. [RUN]
2018-07-30 14:20:22,765: Compiling model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 14:20:22,773: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 14:20:22,775: Acquiring new bigquery connection "buyer_segment_lists".
2018-07-30 14:20:22,775: Re-using an available connection from the pool.
2018-07-30 14:20:22,953: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 14:20:22,954: Fetching data for query buyer_segment_lists:
create or replace table `template`.`buyer_segment_lists`
  
  as (
    SELECT
a.store,
period,
date,
customer_id,
b.first_name,
b.last_name,
b.email,
recency,
frequency,
revenue,
aov,
revenue_segment,
frequency_segment
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg` a
LEFT JOIN `growth-engines-pipeline`.`template`.`agg_customers` b
ON (
	a.store = b.store AND
	a.customer_id = b.id
)
where ( revenue_segment != '' or frequency_segment != '' )
  );

    
2018-07-30 14:20:56,283: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dda610eb-b67b-4a63-8e98-439db46fdffd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1026530b8>]}
2018-07-30 14:20:56,793: 14:20:56 | 23 of 23 OK created table model template.buyer_segment_lists......... [OK in 33.52s]
2018-07-30 14:20:56,837: 14:20:56 | 
2018-07-30 14:20:56,837: 14:20:56 | Finished running 23 table models in 235.14s.
2018-07-30 14:20:56,838: Connection 'master' was left open.
2018-07-30 14:20:56,839: 
2018-07-30 14:20:56,839: Completed successfully
2018-07-30 14:20:56,839: 
Done. PASS=23 ERROR=0 SKIP=0 TOTAL=23
2018-07-30 14:20:56,840: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10514a4e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10524b4e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105250a90>]}
2018-07-30 14:20:57,475: Flushing usage events
2018-07-30 14:20:57,645: sys:1: ResourceWarning: unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55548), raddr=('172.217.1.205', 443)>

2018-07-30 14:20:57,645: sys:1: ResourceWarning: unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55546), raddr=('172.217.3.10', 443)>

2018-07-30 14:20:57,646: sys:1: ResourceWarning: unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55545), raddr=('172.217.1.205', 443)>

2018-07-30 14:20:57,646: sys:1: ResourceWarning: unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55554), raddr=('172.217.11.234', 443)>

2018-07-30 14:20:57,647: sys:1: ResourceWarning: unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55555), raddr=('172.217.11.234', 443)>

2018-07-30 14:20:57,647: sys:1: ResourceWarning: unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55552), raddr=('172.217.11.234', 443)>

2018-07-30 14:20:57,648: sys:1: ResourceWarning: unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55549), raddr=('172.217.1.205', 443)>

2018-07-30 14:20:57,648: sys:1: ResourceWarning: unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55553), raddr=('172.217.11.234', 443)>

2018-07-30 14:20:57,649: sys:1: ResourceWarning: unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55550), raddr=('172.217.1.205', 443)>

2018-07-30 14:20:57,649: sys:1: ResourceWarning: unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55551), raddr=('172.217.1.205', 443)>

2018-07-30 14:44:45,491: Tracking: tracking
2018-07-30 14:44:45,504: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e53cda0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e53cc18>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e53cf28>]}
2018-07-30 14:44:46,529: Loading dependency project from /usr/local/Cellar/dbt/0.10.1/libexec/lib/python3.6/site-packages/dbt/include
2018-07-30 14:44:46,576: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/shopify-cohort-analysis/dbt_modules
2018-07-30 14:44:46,582: Parsing get_column_values.sql
2018-07-30 14:44:46,610: Parsing get_url_parameter.sql
2018-07-30 14:44:46,622: Parsing split_part.sql
2018-07-30 14:44:46,633: Parsing table_exists.sql
2018-07-30 14:44:46,647: Parsing core.sql
2018-07-30 14:44:46,681: Parsing adapters/bigquery.sql
2018-07-30 14:44:46,701: Parsing adapters/common.sql
2018-07-30 14:44:46,741: Parsing adapters/redshift.sql
2018-07-30 14:44:46,778: Parsing adapters/snowflake.sql
2018-07-30 14:44:46,789: Parsing etc/bigquery.sql
2018-07-30 14:44:46,794: Parsing etc/datetime.sql
2018-07-30 14:44:46,835: Parsing etc/get_custom_schema.sql
2018-07-30 14:44:46,849: Parsing materializations/helpers.sql
2018-07-30 14:44:46,885: Parsing materializations/archive/archive.sql
2018-07-30 14:44:46,975: Parsing materializations/incremental/incremental.sql
2018-07-30 14:44:47,040: Parsing materializations/seed/bigquery.sql
2018-07-30 14:44:47,049: Parsing materializations/seed/seed.sql
2018-07-30 14:44:47,124: Parsing materializations/table/bigquery_table.sql
2018-07-30 14:44:47,166: Parsing materializations/table/table.sql
2018-07-30 14:44:47,194: Parsing materializations/view/bigquery_view.sql
2018-07-30 14:44:47,210: Parsing materializations/view/view.sql
2018-07-30 14:44:47,237: Parsing schema_tests/accepted_values.sql
2018-07-30 14:44:47,244: Parsing schema_tests/not_null.sql
2018-07-30 14:44:47,249: Parsing schema_tests/relationships.sql
2018-07-30 14:44:47,256: Parsing schema_tests/unique.sql
2018-07-30 14:44:47,347: Parsing model.shopify_cohort_analysis.all_dates
2018-07-30 14:44:47,350: Parsing model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 14:44:47,354: Parsing model.shopify_cohort_analysis.monthend_dates
2018-07-30 14:44:47,356: Parsing model.shopify_cohort_analysis.stores_proc
2018-07-30 14:44:47,359: Parsing model.shopify_cohort_analysis.ga_transactions
2018-07-30 14:44:47,373: Parsing model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 14:44:47,422: Parsing model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 14:44:47,437: Parsing model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 14:44:47,452: Parsing model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 14:44:47,463: Parsing model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 14:44:47,473: Parsing model.shopify_cohort_analysis.agg_customers
2018-07-30 14:44:47,477: Parsing model.shopify_cohort_analysis.agg_transactions
2018-07-30 14:44:47,482: Parsing model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 14:44:47,486: Parsing model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 14:44:47,489: Parsing model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 14:44:47,493: Parsing model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 14:44:47,497: Parsing model.shopify_cohort_analysis.customers_proc
2018-07-30 14:44:47,503: Parsing model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 14:44:47,508: Parsing model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 14:44:47,514: Parsing model.shopify_cohort_analysis.segment_proc_buyers
2018-07-30 14:44:47,517: Parsing model.shopify_cohort_analysis.segment_stats_buyers_agg
2018-07-30 14:44:47,524: Parsing model.shopify_cohort_analysis.segment_stats_buyers_view
2018-07-30 14:44:47,556: Parsing model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 14:44:47,581: Found 23 models, 0 tests, 0 archives, 0 analyses, 62 macros, 0 operations, 0 seed files
2018-07-30 14:44:47,592: 
2018-07-30 14:44:47,602: Acquiring new bigquery connection "master".
2018-07-30 14:44:47,602: Opening a new connection (0 currently allocated)
2018-07-30 14:44:49,791: 14:44:49 | Concurrency: 4 threads (target='template')
2018-07-30 14:44:49,791: 14:44:49 | 
2018-07-30 14:44:49,956: 14:44:49 | 1 of 23 START table model template.stores_proc....................... [RUN]
2018-07-30 14:44:49,958: Compiling model.shopify_cohort_analysis.stores_proc
2018-07-30 14:44:49,957: 14:44:49 | 2 of 23 START table model template.mappings_ga_proc.................. [RUN]
2018-07-30 14:44:49,964: Compiling model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 14:44:49,957: 14:44:49 | 3 of 23 START table model template.monthend_dates.................... [RUN]
2018-07-30 14:44:49,971: Writing injected SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 14:44:49,957: 14:44:49 | 4 of 23 START table model template.all_dates......................... [RUN]
2018-07-30 14:44:49,982: Compiling model.shopify_cohort_analysis.all_dates
2018-07-30 14:44:49,981: Writing injected SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 14:44:49,978: Compiling model.shopify_cohort_analysis.monthend_dates
2018-07-30 14:44:49,997: Writing injected SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 14:44:50,002: Acquiring new bigquery connection "all_dates".
2018-07-30 14:44:50,002: Opening a new connection (1 currently allocated)
2018-07-30 14:44:50,010: Acquiring new bigquery connection "mappings_ga_proc".
2018-07-30 14:44:50,010: Opening a new connection (2 currently allocated)
2018-07-30 14:44:50,015: Acquiring new bigquery connection "stores_proc".
2018-07-30 14:44:50,020: Writing injected SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 14:44:50,020: Opening a new connection (3 currently allocated)
2018-07-30 14:44:50,032: Acquiring new bigquery connection "monthend_dates".
2018-07-30 14:44:50,035: Opening a new connection (4 currently allocated)
2018-07-30 14:44:51,415: Writing runtime SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 14:44:51,452: Fetching data for query all_dates:
create or replace table `template`.`all_dates`
  
  as (
    SELECT 
date_in_range,
unix_date(date_in_range) unix_date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
  );

    
2018-07-30 14:44:51,471: Writing runtime SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 14:44:51,477: Fetching data for query monthend_dates:
create or replace table `template`.`monthend_dates`
  
  as (
    SELECT
date_in_range,
date_in_range_bom,
date_in_range_bom_mom,
unix_date_in_range,
unix_date_in_range_bom,
unix_date(date_in_range_bom_mom) unix_date_in_range_bom_mom,
yyyymm,
date_in_range_yoy,
unix_date(date_in_range_yoy) unix_date_in_range_yoy

FROM
(
	SELECT 
	date_in_range,
	date_in_range_bom,
	date_sub(date_in_range_bom, INTERVAL 1 MONTH) date_in_range_bom_mom,
	date_sub(date_in_range, INTERVAL 1 YEAR) date_in_range_yoy,
	unix_date_in_range,
	unix_date(date_in_range_bom) unix_date_in_range_bom,
	yyyymm,
	first_value(date_in_range) over (partition by yyyymm order by date_in_range desc) monthend_date_in_range
	FROM
	( 
		SELECT 
		date_in_range,
		date_trunc( date_in_range, MONTH) date_in_range_bom,
		unix_date(date_in_range) unix_date_in_range,
		format_date("%Y-%m", date_in_range) AS yyyymm
		FROM UNNEST(
		    GENERATE_DATE_ARRAY(DATE('2016-01-31'), CURRENT_DATE(), INTERVAL 1 DAY)
		) AS date_in_range
	)
)
where date_in_range = monthend_date_in_range
  );

    
2018-07-30 14:44:51,473: Writing runtime SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 14:44:51,515: Writing runtime SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 14:44:51,516: Fetching data for query mappings_ga_proc:
create or replace table `template`.`mappings_ga_proc`
  
  as (
    select 
store,
account,
store_name,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client store,
account,
client_name store_name,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.mappings_ga` 

) 

WHERE lv = time_of_entry
group by store, account, store_name, source, medium, platform_n, channel_n, time_of_entry
  );

    
2018-07-30 14:44:51,517: Fetching data for query stores_proc:
create or replace table `template`.`stores_proc`
  
  as (
    select 
store,
store_name,
account,
platform,
max(time_of_entry) time_of_entry

from  ( 

SELECT  
client store,
client_name store_name,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.accounts` 
where client_name != ''

) 

WHERE lv = time_of_entry
group by store, store_name, account, platform
  );

    
2018-07-30 14:44:53,194: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee423a69-3968-4b53-b8c4-6038f13c6848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e642860>]}
2018-07-30 14:44:53,224: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee423a69-3968-4b53-b8c4-6038f13c6848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e89cb70>]}
2018-07-30 14:44:53,498: 14:44:53 | 4 of 23 OK created table model template.all_dates.................... [OK in 3.21s]
2018-07-30 14:44:53,519: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee423a69-3968-4b53-b8c4-6038f13c6848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e7d7b70>]}
2018-07-30 14:44:53,557: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee423a69-3968-4b53-b8c4-6038f13c6848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e786e48>]}
2018-07-30 14:44:53,802: 14:44:53 | 3 of 23 OK created table model template.monthend_dates............... [OK in 3.25s]
2018-07-30 14:44:54,134: 14:44:54 | 1 of 23 OK created table model template.stores_proc.................. [OK in 3.56s]
2018-07-30 14:44:54,469: 14:44:54 | 2 of 23 OK created table model template.mappings_ga_proc............. [OK in 3.59s]
2018-07-30 14:44:54,470: 14:44:54 | 5 of 23 START table model template.shopify_customers_proc............ [RUN]
2018-07-30 14:44:54,471: Compiling model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 14:44:54,475: 14:44:54 | 6 of 23 START table model template.shopify_discounts_proc............ [RUN]
2018-07-30 14:44:54,476: Compiling model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 14:44:54,475: 14:44:54 | 7 of 23 START table model template.shopify_refunds_proc.............. [RUN]
2018-07-30 14:44:54,487: Compiling model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 14:44:54,508: Acquiring new bigquery connection "shopify_discounts_proc".
2018-07-30 14:44:54,512: Acquiring new bigquery connection "shopify_customers_proc".
2018-07-30 14:44:54,523: Re-using an available connection from the pool.
2018-07-30 14:44:54,523: Fetching data for query shopify_customers_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:44:54,521: Acquiring new bigquery connection "shopify_refunds_proc".
2018-07-30 14:44:54,527: Re-using an available connection from the pool.
2018-07-30 14:44:54,528: Fetching data for query shopify_discounts_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:44:54,528: Re-using an available connection from the pool.
2018-07-30 14:44:54,528: Fetching data for query shopify_refunds_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:44:56,040: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 14:44:56,186: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 14:44:56,187: Fetching data for query shopify_customers_proc:
create or replace table `template`.`shopify_customers_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`





with customers as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	created_at,
	id,
	first_name,
	last_name,
	email,
	_sdc_sequence,
	first_value(_sdc_sequence) over (partition by id order by _sdc_sequence desc) lv
	FROM `growth-engines-pipeline.shopify_lucadanni.customers` 
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
id,
first_name,
last_name,
email
FROM customers a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence


  );

    
2018-07-30 14:44:56,296: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 14:44:56,472: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 14:44:56,472: Fetching data for query shopify_refunds_proc:
create or replace table `template`.`shopify_refunds_proc`
  
  as (
    



with refunds as (

	
	SELECT
	'lucadanni' store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal,
	line_item.variant_id variant_id,
	line_item.id refund_id,
 	_sdc_sequence
	FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
	cross join unnest(refunds), unnest(refund_line_items)
  	where financial_status like '%refund%'
	
	

)

SELECT * 
FROM 
	(
    SELECT
    store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal refund_amount,
	variant_id,
	refund_id,
 	_sdc_sequence,
    first_value(_sdc_sequence) OVER (PARTITION BY order_number, line_item_id ORDER BY _sdc_sequence DESC) lv
    FROM refunds
   	) 
WHERE lv = _sdc_sequence


  );

    
2018-07-30 14:44:56,585: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 14:44:56,721: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 14:44:56,722: Fetching data for query shopify_discounts_proc:
create or replace table `template`.`shopify_discounts_proc`
  
  as (
    



with orders as (

	
		SELECT
		'lucadanni' store_name,
		created_at,
		order_number,
		code discount_code,
		type discount_type,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(discount_codes)
		where source_name != 'shopify_draft_order'
	
	
	

)

SELECT
store_name,
order_number,
discount_code,
discount_type
FROM orders
where lv = _sdc_sequence


  );

    
2018-07-30 14:44:58,652: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee423a69-3968-4b53-b8c4-6038f13c6848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e7b4080>]}
2018-07-30 14:44:59,900: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee423a69-3968-4b53-b8c4-6038f13c6848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e85b048>]}
2018-07-30 14:44:59,901: 14:44:59 | 7 of 23 OK created table model template.shopify_refunds_proc......... [OK in 4.17s]
2018-07-30 14:45:00,561: 14:45:00 | 6 of 23 OK created table model template.shopify_discounts_proc....... [OK in 5.42s]
2018-07-30 14:45:00,840: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee423a69-3968-4b53-b8c4-6038f13c6848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e76ebe0>]}
2018-07-30 14:45:01,131: 14:45:01 | 5 of 23 OK created table model template.shopify_customers_proc....... [OK in 6.37s]
2018-07-30 14:45:01,131: 14:45:01 | 8 of 23 START table model template.ga_transactions................... [RUN]
2018-07-30 14:45:01,132: 14:45:01 | 9 of 23 START table model template.agg_customers..................... [RUN]
2018-07-30 14:45:01,132: Compiling model.shopify_cohort_analysis.ga_transactions
2018-07-30 14:45:01,132: 14:45:01 | 10 of 23 START table model template.shopify_products_proc............ [RUN]
2018-07-30 14:45:01,133: Compiling model.shopify_cohort_analysis.agg_customers
2018-07-30 14:45:01,144: Compiling model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 14:45:01,153: Acquiring new bigquery connection "ga_transactions".
2018-07-30 14:45:01,185: Acquiring new bigquery connection "shopify_products_proc".
2018-07-30 14:45:01,190: Writing injected SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 14:45:01,193: Acquiring new bigquery connection "agg_customers".
2018-07-30 14:45:01,194: Re-using an available connection from the pool.
2018-07-30 14:45:01,194: Fetching data for query ga_transactions:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Google Analytics'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:45:01,197: Re-using an available connection from the pool.
2018-07-30 14:45:01,198: Fetching data for query shopify_products_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:45:01,201: Re-using an available connection from the pool.
2018-07-30 14:45:01,341: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 14:45:01,346: Fetching data for query agg_customers:
create or replace table `template`.`agg_customers`
  
  as (
    SELECT 
account,
store,
id,
created_at,
first_name,
last_name,
email,
split(email,'@')[SAFE_ORDINAL(2)] email_domain
FROM
`growth-engines-pipeline`.`template`.`shopify_customers_proc`
  );

    
2018-07-30 14:45:01,945: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 14:45:02,091: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 14:45:02,091: Fetching data for query shopify_products_proc:
create or replace table `template`.`shopify_products_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`





with products as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	product_name,
	lower(product_type) product_type,
	product_id,
	sku,
	id variant_id,
	cast(created_at as date) created_at,
	_sdc_sequence,
	first_value(_sdc_sequence) OVER (PARTITION BY product_id ORDER BY _sdc_sequence DESC) lv
	FROM (
		SELECT
		variants,
		product_type,
		title product_name,
		_sdc_sequence
		FROM `growth-engines-pipeline.shopify_lucadanni.products` 
		)
	cross join unnest(variants)
	
	

)

SELECT
b.account,
b.store,
b.platform,
max(product_type) product_type,
product_id,
variant_id,
sku,
created_at,
product_name
FROM products a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence
group by product_id, account, store, platform, sku, variant_id, created_at, product_name


  );

    
2018-07-30 14:45:02,690: Writing injected SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 14:45:02,842: Writing runtime SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 14:45:02,844: Fetching data for query ga_transactions:
create or replace table `template`.`ga_transactions`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`,`growth-engines-pipeline`.`template`.`mappings_ga_proc`




with ga_report as (

	    
	    	
		   	SELECT
		   	'yandy' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_yandy.report` 

		     UNION ALL 
	   
	    	
		   	SELECT
		   	'lucadanni' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_lucadanni.report` 

		    
	   

)


SELECT  
date,
b.store store,
c.source source,
c.medium medium,
a.campaign campaign,
concat(a.source, ' / ', a.medium) source_medium,  
case when c.platform is null then "Unmapped" else c.platform end as platform,
case when c.channel is null then "Unmapped" else c.channel end as channel,
url,
transactionid
FROM (

	SELECT 
	store_name,
	lookup_platform,
	date,
	transactionid,
	max(url) url,
	max(source) source,
	max(medium) medium,
	max(campaign) campaign
	FROM ga_report
	where lv = _sdc_sequence
	group by store_name, lookup_platform, date, transactionid

) a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name 
	AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`mappings_ga_proc` c
ON ( a.source = c.source
  AND a.medium = c.medium 
  AND a.store_name = c.store_name )


  );

    
2018-07-30 14:45:04,247: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee423a69-3968-4b53-b8c4-6038f13c6848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e7b0710>]}
2018-07-30 14:45:04,570: 14:45:04 | 10 of 23 OK created table model template.shopify_products_proc....... [OK in 3.10s]
2018-07-30 14:45:05,274: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee423a69-3968-4b53-b8c4-6038f13c6848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e85b2e8>]}
2018-07-30 14:45:05,567: 14:45:05 | 9 of 23 OK created table model template.agg_customers................ [OK in 4.14s]
2018-07-30 14:45:29,909: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee423a69-3968-4b53-b8c4-6038f13c6848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce7ff98>]}
2018-07-30 14:45:30,239: 14:45:30 | 8 of 23 OK created table model template.ga_transactions.............. [OK in 28.78s]
2018-07-30 14:45:30,241: 14:45:30 | 11 of 23 START table model template.shopify_orders_proc.............. [RUN]
2018-07-30 14:45:30,241: Compiling model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 14:45:30,262: Acquiring new bigquery connection "shopify_orders_proc".
2018-07-30 14:45:30,262: Re-using an available connection from the pool.
2018-07-30 14:45:30,262: Fetching data for query shopify_orders_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:45:31,064: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 14:45:31,207: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 14:45:31,208: Fetching data for query shopify_orders_proc:
create or replace table `template`.`shopify_orders_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`, `growth-engines-pipeline`.`template`.`shopify_discounts_proc`





with orders as (

	
	SELECT 
	store_name,
	lookup_platform,
	created_at,
	order_number,
	quantity,
	price, 
	total_order_price_undiscounted,
	total_discounts,
	total_order_shipping_price,
	total_order_price_incl_shipping,
	checkout_id,
	product_id, 
	landing_site,
	sku, 
	variant_title, 
	variant_id,
	line_item_id,
	customer_id,
	_sdc_sequence,
	lv
	FROM (

		SELECT
		'lucadanni' store_name,
		'Shopify' as lookup_platform,
		created_at,
		order_number,
		quantity,
		cast(pre_tax_price as float64) price, 
		total_line_items_price total_order_price_undiscounted,
		total_discounts,
		cast(discounted_price as float64) total_order_shipping_price,
		total_price_usd total_order_price_incl_shipping,
		checkout_id,
		product_id, 
		landing_site,
		sku, 
		variant_title, 
		variant_id,
		_id line_item_id,
		customer.id customer_id,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(line_items), unnest(shipping_lines)
		where source_name != 'shopify_draft_order'
	)
	
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
a.order_number,
a.quantity prelim_quantity,
c.quantity refund_quantity,
case when c.quantity is not null then a.quantity - c.quantity else a.quantity end as quantity,
price prelim_revenue, 
total_order_price_undiscounted,
total_discounts,
trim(lower(d.discount_code)) discount_code,
d.discount_type,
total_order_shipping_price,
total_order_price_incl_shipping,
refund_amount,
case when refund_amount is not null then price - refund_amount else price end as revenue,
a.checkout_id,
a.product_id, 
landing_site,
sku, 
variant_title, 
a.variant_id,
a.line_item_id,	
customer_id
FROM orders a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_refunds_proc` c
ON ( a.order_number = c.order_number
	AND a.line_item_id = c.line_item_id
	AND a.store_name = c.store_name )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_discounts_proc` d
ON ( a.order_number = d.order_number 
    AND a.store_name = d.store_name )  	
where a.lv = a._sdc_sequence


  );

    
2018-07-30 14:45:40,345: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee423a69-3968-4b53-b8c4-6038f13c6848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e76ebe0>]}
2018-07-30 14:45:40,705: 14:45:40 | 11 of 23 OK created table model template.shopify_orders_proc......... [OK in 10.10s]
2018-07-30 14:45:40,706: 14:45:40 | 12 of 23 START table model template.transaction_by_order_number...... [RUN]
2018-07-30 14:45:40,706: Compiling model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 14:45:40,720: Writing injected SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 14:45:40,734: Acquiring new bigquery connection "transaction_by_order_number".
2018-07-30 14:45:40,734: Re-using an available connection from the pool.
2018-07-30 14:45:40,917: Writing runtime SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 14:45:40,918: Fetching data for query transaction_by_order_number:
create or replace table `template`.`transaction_by_order_number`
  
  as (
    SELECT
store,
cast(created_at as date) order_date,
order_number,
customer_id,
sum(quantity) quantity,
sum(revenue) revenue,
max(total_order_shipping_price) shipping_price
FROM
`growth-engines-pipeline`.`template`.`shopify_orders_proc`
GROUP BY store, order_date, order_number, customer_id
  );

    
2018-07-30 14:45:45,592: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee423a69-3968-4b53-b8c4-6038f13c6848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce7ff98>]}
2018-07-30 14:45:46,384: 14:45:46 | 12 of 23 OK created table model template.transaction_by_order_number. [OK in 4.89s]
2018-07-30 14:45:46,384: 14:45:46 | 13 of 23 START table model template.customers_by_transaction......... [RUN]
2018-07-30 14:45:46,385: Compiling model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 14:45:46,391: Writing injected SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 14:45:46,393: Acquiring new bigquery connection "customers_by_transaction".
2018-07-30 14:45:46,393: Re-using an available connection from the pool.
2018-07-30 14:45:46,568: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 14:45:46,569: Fetching data for query customers_by_transaction:
create or replace table `template`.`customers_by_transaction`
  
  as (
    SELECT
store,
customer_id,
order_number,
order_date,
recent_order_date,
first_order_date,
case when first_order_number = order_number then 'New'
	when date_diff(order_date, recent_order_date, DAY) <= 365 then 'Repeat'
	when date_diff(order_date, recent_order_date, DAY) > 365 then 'Reactivated'
 else '' end as order_type,
quantity,
revenue,
1 as orders,
first_order_revenue,
lifetime_revenue
FROM

(

	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	quantity,
	revenue,
	lag(order_date) over w1 recent_order_date,
	first_value(order_date) over w1 first_order_date,
	first_value(order_number) over w1 first_order_number,
	first_value(revenue) over w1 first_order_revenue,
	sum(revenue) over w2 lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`transaction_by_order_number`
	WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc),
	w2 as (PARTITION BY store, customer_id)
)
  );

    
2018-07-30 14:45:50,089: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee423a69-3968-4b53-b8c4-6038f13c6848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e76ebe0>]}
2018-07-30 14:45:50,962: 14:45:50 | 13 of 23 OK created table model template.customers_by_transaction.... [OK in 3.70s]
2018-07-30 14:45:50,963: 14:45:50 | 14 of 23 START table model template.agg_transactions................. [RUN]
2018-07-30 14:45:50,963: Compiling model.shopify_cohort_analysis.agg_transactions
2018-07-30 14:45:50,971: Writing injected SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 14:45:50,973: Acquiring new bigquery connection "agg_transactions".
2018-07-30 14:45:50,973: Re-using an available connection from the pool.
2018-07-30 14:45:51,108: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 14:45:51,109: Fetching data for query agg_transactions:
create or replace table `template`.`agg_transactions`
  
  as (
    with ga_transaction as (

	SELECT
	date, 
	store,
	transactionid,
	channel,
	platform,
	url,
	campaign
	FROM `growth-engines-pipeline`.`template`.`ga_transactions`
),

customers_by_transaction as (
	
	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	first_order_date,
	recent_order_date,
	order_type,
	quantity,
	revenue,
	orders,
	first_order_revenue,
	lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`customers_by_transaction`
)

SELECT
store,
customer_id,
order_number,
transactionid,
order_date,
first_order_date,
format_date("%Y-%m", first_order_date) AS first_order_month,
order_type,
first_order_revenue,
lifetime_revenue,
first_value(channel) over w1 as first_order_channel,
first_value(platform) over w1 as first_order_platform,
channel,
platform,
url,
campaign,
quantity,
revenue,
orders
FROM (

	SELECT
	a.store,
	a.customer_id,
	a.order_number,
	b.transactionid,
	a.order_date, 
	a.first_order_date, 
	a.order_type,
	a.first_order_revenue,
	a.lifetime_revenue,
	b.channel,
	b.platform,
	b.url,
	b.campaign,
	a.quantity,
	a.revenue,
	a.orders
	FROM customers_by_transaction a
	LEFT JOIN ga_transaction b
	ON (
	    a.store = b.store AND
	    a.order_number = b.transactionid
	)	
)
WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc)
  );

    
2018-07-30 14:45:59,832: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee423a69-3968-4b53-b8c4-6038f13c6848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce7ff98>]}
2018-07-30 14:46:00,160: 14:46:00 | 14 of 23 OK created table model template.agg_transactions............ [OK in 8.87s]
2018-07-30 14:46:00,161: 14:46:00 | 15 of 23 START table model template.customers_proc_qoq............... [RUN]
2018-07-30 14:46:00,161: Compiling model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 14:46:00,176: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 14:46:00,172: 14:46:00 | 16 of 23 START table model template.customers_proc_yoy............... [RUN]
2018-07-30 14:46:00,172: 14:46:00 | 17 of 23 START table model template.monthly_cohort_stats............. [RUN]
2018-07-30 14:46:00,177: Compiling model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 14:46:00,177: Compiling model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 14:46:00,183: Writing injected SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 14:46:00,190: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 14:46:00,192: Acquiring new bigquery connection "customers_proc_qoq".
2018-07-30 14:46:00,194: Acquiring new bigquery connection "monthly_cohort_stats".
2018-07-30 14:46:00,194: Re-using an available connection from the pool.
2018-07-30 14:46:00,199: Acquiring new bigquery connection "customers_proc_yoy".
2018-07-30 14:46:00,199: Re-using an available connection from the pool.
2018-07-30 14:46:00,202: Re-using an available connection from the pool.
2018-07-30 14:46:00,349: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 14:46:00,355: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 14:46:00,373: Writing runtime SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 14:46:00,374: Fetching data for query customers_proc_qoq:
create or replace table `template`.`customers_proc_qoq`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 90 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 90 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 90 window_end_unix_date, 
    unix_date_in_range - 180 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 180 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 90 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 14:46:00,374: Fetching data for query customers_proc_yoy:
create or replace table `template`.`customers_proc_yoy`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 365 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 365 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 365 window_end_unix_date, 
    unix_date_in_range - 730 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 730 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 365 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 14:46:00,378: Fetching data for query monthly_cohort_stats:
create or replace table `template`.`monthly_cohort_stats`
  
  as (
    WITH transactions AS (

  SELECT 
  store, 
  order_number,
  order_date,
  order_type,
  first_order_month,
  unix_date(order_date) d, 
  customer_id, 
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (

  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT 
date_in_range date,
store, 
order_type,
first_order_channel,
first_order_platform,
first_order_month,
channel,
platform,
url,
campaign,
count(distinct(customer_id)) buyers,
sum(orders) orders,
sum(quantity) quantity,
sum(revenue) revenue
FROM daterange
JOIN transactions
ON transactions.d >= daterange.unix_date_in_range_bom 
AND transactions.d <= daterange.unix_date_in_range
GROUP BY date, store, order_type, 
first_order_channel, first_order_platform, first_order_month, channel, platform, url, campaign
  );

    
2018-07-30 14:46:05,244: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee423a69-3968-4b53-b8c4-6038f13c6848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e874978>]}
2018-07-30 14:46:06,035: 14:46:06 | 17 of 23 OK created table model template.monthly_cohort_stats........ [OK in 5.07s]
2018-07-30 14:46:12,347: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee423a69-3968-4b53-b8c4-6038f13c6848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e76ebe0>]}
2018-07-30 14:46:12,662: 14:46:12 | 15 of 23 OK created table model template.customers_proc_qoq.......... [OK in 12.19s]
2018-07-30 14:46:26,903: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee423a69-3968-4b53-b8c4-6038f13c6848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e85ba20>]}
2018-07-30 14:46:27,212: 14:46:27 | 16 of 23 OK created table model template.customers_proc_yoy.......... [OK in 26.73s]
2018-07-30 14:46:27,213: 14:46:27 | 18 of 23 START table model template.customers_proc................... [RUN]
2018-07-30 14:46:27,214: Compiling model.shopify_cohort_analysis.customers_proc
2018-07-30 14:46:27,222: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 14:46:27,225: Acquiring new bigquery connection "customers_proc".
2018-07-30 14:46:27,225: Re-using an available connection from the pool.
2018-07-30 14:46:27,382: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 14:46:27,383: Fetching data for query customers_proc:
create or replace table `template`.`customers_proc`
  
  as (
    SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_qoq`

UNION ALL

SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_yoy`
  );

    
2018-07-30 14:46:57,674: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee423a69-3968-4b53-b8c4-6038f13c6848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce7ff98>]}
2018-07-30 14:46:58,572: 14:46:58 | 18 of 23 OK created table model template.customers_proc.............. [OK in 30.46s]
2018-07-30 14:46:58,573: 14:46:58 | 19 of 23 START table model template.segment_proc_buyers.............. [RUN]
2018-07-30 14:46:58,573: Compiling model.shopify_cohort_analysis.segment_proc_buyers
2018-07-30 14:46:58,584: Writing injected SQL for node "model.shopify_cohort_analysis.segment_proc_buyers"
2018-07-30 14:46:58,589: Acquiring new bigquery connection "segment_proc_buyers".
2018-07-30 14:46:58,589: Re-using an available connection from the pool.
2018-07-30 14:46:58,715: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_proc_buyers"
2018-07-30 14:46:58,716: Fetching data for query segment_proc_buyers:
create or replace table `template`.`segment_proc_buyers`
  
  as (
    SELECT
store,
period,
customer_id,
date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct,
case when first_order_unix_date >= window_start_unix_date then 'New'
	else 'Existing' end as newness_segment,
case when revenue >= revenue_90pct then 'Top 10%'
	when revenue <= revenue_10pct then 'Bottom 10%'
	else 'Middle 80%' end as revenue_segment,
case when frequency = 1 then '1'
	when frequency = 2 then '2'
	when frequency > 2 then '3+'
	else null end as frequency_segment
FROM `growth-engines-pipeline`.`template`.`customers_proc`
  );

    
2018-07-30 14:47:25,562: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee423a69-3968-4b53-b8c4-6038f13c6848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e66dc18>]}
2018-07-30 14:47:25,879: 14:47:25 | 19 of 23 OK created table model template.segment_proc_buyers......... [OK in 26.99s]
2018-07-30 14:47:25,880: 14:47:25 | 20 of 23 START table model template.segment_stats_buyers_agg......... [RUN]
2018-07-30 14:47:25,880: Compiling model.shopify_cohort_analysis.segment_stats_buyers_agg
2018-07-30 14:47:25,891: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_agg"
2018-07-30 14:47:25,895: Acquiring new bigquery connection "segment_stats_buyers_agg".
2018-07-30 14:47:25,895: Re-using an available connection from the pool.
2018-07-30 14:47:26,050: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_agg"
2018-07-30 14:47:26,050: Fetching data for query segment_stats_buyers_agg:
create or replace table `template`.`segment_stats_buyers_agg`
  
  as (
    WITH ty as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev,
	0 as retention_eligible,
	case when newness_segment = 'Existing' then 1 else 0 end as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Year'

),

this_month_1yr as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment,
	frequency_segment,
	newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	recency_days as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev,
	1 as retention_eligible,
	0 as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Previous Year'

),

this_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,	
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment,
	frequency_segment,
	newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev,
	0 as retention_eligible,
	case when newness_segment = 'Existing' then 1 else 0 end as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Quarter'

),

last_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	recency_days as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev,
	1 as retention_eligible,
	0 as retention_success
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Previous Quarter'

)

SELECT
store,
period,
date, 
customer_id,
1 as buyers,
first_order_channel,
first_order_platform,	
revenue_segment,
frequency_segment,
newness_segment,	
ifnull(sum(recency), 0) recency,
ifnull(sum(frequency), 0) frequency,
ifnull(sum(revenue), 0) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else 0 end as aov,
ifnull(sum(recency_prev), 0) recency_prev,
ifnull(sum(frequency_prev), 0) frequency_prev,
ifnull(sum(revenue_prev), 0) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else 0 end as aov_prev,
sum(retention_eligible) retention_eligible,
sum(retention_success) retention_success
FROM
(
	SELECT * FROM ty
	UNION ALL
	SELECT * FROM this_month_1yr
	UNION ALL
	SELECT * FROM this_quarter
	UNION ALL
	SELECT * FROM last_quarter

)
GROUP BY store, period, date, customer_id, first_order_channel, first_order_platform,
revenue_segment, frequency_segment, newne
  );

    
2018-07-30 14:47:26,634: Bad request while running:
create dataset
2018-07-30 14:47:26,634: 400 GET https://www.googleapis.com/bigquery/v2/projects/growth-engines-pipeline/queries/803bbb36-3409-4af5-8d37-c5bd6ff1fe30?maxResults=0: Unrecognized name: newne at [137:37]
2018-07-30 14:47:26,635: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee423a69-3968-4b53-b8c4-6038f13c6848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e7a9b38>]}
2018-07-30 14:47:26,927: 14:47:26 | 20 of 23 ERROR creating table model template.segment_stats_buyers_agg [ERROR in 0.75s]
2018-07-30 14:47:26,928: 14:47:26 | 21 of 23 SKIP relation template.segment_stats_buyers_view............ [SKIP]
2018-07-30 14:47:26,929: 14:47:26 | 22 of 23 SKIP relation template.buyer_segment_stats.................. [SKIP]
2018-07-30 14:47:26,929: 14:47:26 | 23 of 23 SKIP relation template.buyer_segment_lists.................. [SKIP]
2018-07-30 14:47:27,025: 14:47:27 | 
2018-07-30 14:47:27,025: 14:47:27 | Finished running 23 table models in 159.43s.
2018-07-30 14:47:27,026: Connection 'master' was left open.
2018-07-30 14:47:27,026: 
2018-07-30 14:47:27,026: Completed with 1 errors:
2018-07-30 14:47:27,027: 
2018-07-30 14:47:27,027: Database Error in model segment_stats_buyers_agg (models/math/buyer-segmentation/segment_stats_buyers_agg.sql)
2018-07-30 14:47:27,027:   Unrecognized name: newne at [137:37]
2018-07-30 14:47:27,027:   compiled SQL at target/run/shopify_cohort_analysis/math/buyer-segmentation/segment_stats_buyers_agg.sql
2018-07-30 14:47:27,028: 
Done. PASS=19 ERROR=1 SKIP=3 TOTAL=23
2018-07-30 14:47:27,028: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e53cda0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e63e4e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e7d79e8>]}
2018-07-30 14:47:27,316: Flushing usage events
2018-07-30 14:47:27,608: sys:1: ResourceWarning: unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55713), raddr=('172.217.11.234', 443)>

2018-07-30 14:47:27,609: sys:1: ResourceWarning: unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55705), raddr=('172.217.2.13', 443)>

2018-07-30 14:47:27,609: sys:1: ResourceWarning: unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55719), raddr=('172.217.11.234', 443)>

2018-07-30 14:47:27,610: sys:1: ResourceWarning: unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55721), raddr=('172.217.11.234', 443)>

2018-07-30 14:47:27,610: sys:1: ResourceWarning: unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55720), raddr=('172.217.11.234', 443)>

2018-07-30 14:47:27,611: sys:1: ResourceWarning: unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55718), raddr=('172.217.11.234', 443)>

2018-07-30 14:47:27,611: sys:1: ResourceWarning: unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55715), raddr=('172.217.2.13', 443)>

2018-07-30 14:47:27,611: sys:1: ResourceWarning: unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55714), raddr=('172.217.2.13', 443)>

2018-07-30 14:47:27,612: sys:1: ResourceWarning: unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55717), raddr=('172.217.2.13', 443)>

2018-07-30 14:47:27,612: sys:1: ResourceWarning: unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 55716), raddr=('172.217.2.13', 443)>

2018-07-30 14:48:34,321: Tracking: tracking
2018-07-30 14:48:34,323: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0cd278>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0cd588>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0cdf28>]}
2018-07-30 14:48:36,217: Loading dependency project from /usr/local/Cellar/dbt/0.10.1/libexec/lib/python3.6/site-packages/dbt/include
2018-07-30 14:48:36,253: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/shopify-cohort-analysis/dbt_modules
2018-07-30 14:48:36,260: Parsing get_column_values.sql
2018-07-30 14:48:36,277: Parsing get_url_parameter.sql
2018-07-30 14:48:36,284: Parsing split_part.sql
2018-07-30 14:48:36,294: Parsing table_exists.sql
2018-07-30 14:48:36,304: Parsing core.sql
2018-07-30 14:48:36,319: Parsing adapters/bigquery.sql
2018-07-30 14:48:36,329: Parsing adapters/common.sql
2018-07-30 14:48:36,361: Parsing adapters/redshift.sql
2018-07-30 14:48:36,385: Parsing adapters/snowflake.sql
2018-07-30 14:48:36,391: Parsing etc/bigquery.sql
2018-07-30 14:48:36,395: Parsing etc/datetime.sql
2018-07-30 14:48:36,425: Parsing etc/get_custom_schema.sql
2018-07-30 14:48:36,439: Parsing materializations/helpers.sql
2018-07-30 14:48:36,466: Parsing materializations/archive/archive.sql
2018-07-30 14:48:36,508: Parsing materializations/incremental/incremental.sql
2018-07-30 14:48:36,552: Parsing materializations/seed/bigquery.sql
2018-07-30 14:48:36,566: Parsing materializations/seed/seed.sql
2018-07-30 14:48:36,629: Parsing materializations/table/bigquery_table.sql
2018-07-30 14:48:36,675: Parsing materializations/table/table.sql
2018-07-30 14:48:36,717: Parsing materializations/view/bigquery_view.sql
2018-07-30 14:48:36,732: Parsing materializations/view/view.sql
2018-07-30 14:48:36,755: Parsing schema_tests/accepted_values.sql
2018-07-30 14:48:36,762: Parsing schema_tests/not_null.sql
2018-07-30 14:48:36,766: Parsing schema_tests/relationships.sql
2018-07-30 14:48:36,772: Parsing schema_tests/unique.sql
2018-07-30 14:48:36,818: Parsing model.shopify_cohort_analysis.all_dates
2018-07-30 14:48:36,823: Parsing model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 14:48:36,828: Parsing model.shopify_cohort_analysis.monthend_dates
2018-07-30 14:48:36,832: Parsing model.shopify_cohort_analysis.stores_proc
2018-07-30 14:48:36,835: Parsing model.shopify_cohort_analysis.ga_transactions
2018-07-30 14:48:36,850: Parsing model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 14:48:36,863: Parsing model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 14:48:36,872: Parsing model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 14:48:36,884: Parsing model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 14:48:36,893: Parsing model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 14:48:36,899: Parsing model.shopify_cohort_analysis.agg_customers
2018-07-30 14:48:36,902: Parsing model.shopify_cohort_analysis.agg_transactions
2018-07-30 14:48:36,905: Parsing model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 14:48:36,908: Parsing model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 14:48:36,911: Parsing model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 14:48:36,914: Parsing model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 14:48:36,918: Parsing model.shopify_cohort_analysis.customers_proc
2018-07-30 14:48:36,922: Parsing model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 14:48:36,926: Parsing model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 14:48:36,931: Parsing model.shopify_cohort_analysis.segment_proc_buyers
2018-07-30 14:48:36,934: Parsing model.shopify_cohort_analysis.segment_stats_buyers_agg
2018-07-30 14:48:36,939: Parsing model.shopify_cohort_analysis.segment_stats_buyers_view
2018-07-30 14:48:36,950: Parsing model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 14:48:36,974: Found 23 models, 0 tests, 0 archives, 0 analyses, 62 macros, 0 operations, 0 seed files
2018-07-30 14:48:36,981: 
2018-07-30 14:48:36,990: Acquiring new bigquery connection "master".
2018-07-30 14:48:36,991: Opening a new connection (0 currently allocated)
2018-07-30 14:48:38,208: 14:48:38 | Concurrency: 4 threads (target='template')
2018-07-30 14:48:38,209: 14:48:38 | 
2018-07-30 14:48:38,302: 14:48:38 | 1 of 23 START table model template.monthend_dates.................... [RUN]
2018-07-30 14:48:38,303: 14:48:38 | 2 of 23 START table model template.all_dates......................... [RUN]
2018-07-30 14:48:38,303: 14:48:38 | 3 of 23 START table model template.stores_proc....................... [RUN]
2018-07-30 14:48:38,303: 14:48:38 | 4 of 23 START table model template.mappings_ga_proc.................. [RUN]
2018-07-30 14:48:38,303: Compiling model.shopify_cohort_analysis.monthend_dates
2018-07-30 14:48:38,304: Compiling model.shopify_cohort_analysis.all_dates
2018-07-30 14:48:38,304: Compiling model.shopify_cohort_analysis.stores_proc
2018-07-30 14:48:38,304: Compiling model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 14:48:38,311: Writing injected SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 14:48:38,315: Writing injected SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 14:48:38,327: Writing injected SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 14:48:38,328: Writing injected SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 14:48:38,334: Acquiring new bigquery connection "monthend_dates".
2018-07-30 14:48:38,336: Acquiring new bigquery connection "stores_proc".
2018-07-30 14:48:38,336: Opening a new connection (1 currently allocated)
2018-07-30 14:48:38,338: Acquiring new bigquery connection "mappings_ga_proc".
2018-07-30 14:48:38,339: Acquiring new bigquery connection "all_dates".
2018-07-30 14:48:38,341: Opening a new connection (2 currently allocated)
2018-07-30 14:48:38,352: Opening a new connection (3 currently allocated)
2018-07-30 14:48:38,357: Opening a new connection (4 currently allocated)
2018-07-30 14:48:38,874: Writing runtime SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 14:48:38,875: Fetching data for query monthend_dates:
create or replace table `template`.`monthend_dates`
  
  as (
    SELECT
date_in_range,
date_in_range_bom,
date_in_range_bom_mom,
unix_date_in_range,
unix_date_in_range_bom,
unix_date(date_in_range_bom_mom) unix_date_in_range_bom_mom,
yyyymm,
date_in_range_yoy,
unix_date(date_in_range_yoy) unix_date_in_range_yoy

FROM
(
	SELECT 
	date_in_range,
	date_in_range_bom,
	date_sub(date_in_range_bom, INTERVAL 1 MONTH) date_in_range_bom_mom,
	date_sub(date_in_range, INTERVAL 1 YEAR) date_in_range_yoy,
	unix_date_in_range,
	unix_date(date_in_range_bom) unix_date_in_range_bom,
	yyyymm,
	first_value(date_in_range) over (partition by yyyymm order by date_in_range desc) monthend_date_in_range
	FROM
	( 
		SELECT 
		date_in_range,
		date_trunc( date_in_range, MONTH) date_in_range_bom,
		unix_date(date_in_range) unix_date_in_range,
		format_date("%Y-%m", date_in_range) AS yyyymm
		FROM UNNEST(
		    GENERATE_DATE_ARRAY(DATE('2016-01-31'), CURRENT_DATE(), INTERVAL 1 DAY)
		) AS date_in_range
	)
)
where date_in_range = monthend_date_in_range
  );

    
2018-07-30 14:48:38,929: Writing runtime SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 14:48:38,938: Fetching data for query mappings_ga_proc:
create or replace table `template`.`mappings_ga_proc`
  
  as (
    select 
store,
account,
store_name,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client store,
account,
client_name store_name,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.mappings_ga` 

) 

WHERE lv = time_of_entry
group by store, account, store_name, source, medium, platform_n, channel_n, time_of_entry
  );

    
2018-07-30 14:48:38,958: Writing runtime SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 14:48:38,958: Fetching data for query all_dates:
create or replace table `template`.`all_dates`
  
  as (
    SELECT 
date_in_range,
unix_date(date_in_range) unix_date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
  );

    
2018-07-30 14:48:38,994: Writing runtime SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 14:48:38,995: Fetching data for query stores_proc:
create or replace table `template`.`stores_proc`
  
  as (
    select 
store,
store_name,
account,
platform,
max(time_of_entry) time_of_entry

from  ( 

SELECT  
client store,
client_name store_name,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.accounts` 
where client_name != ''

) 

WHERE lv = time_of_entry
group by store, store_name, account, platform
  );

    
2018-07-30 14:48:40,367: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10768bef0>]}
2018-07-30 14:48:40,685: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10768bba8>]}
2018-07-30 14:48:40,702: 14:48:40 | 2 of 23 OK created table model template.all_dates.................... [OK in 2.06s]
2018-07-30 14:48:40,874: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10768b908>]}
2018-07-30 14:48:41,051: 14:48:41 | 1 of 23 OK created table model template.monthend_dates............... [OK in 2.38s]
2018-07-30 14:48:41,261: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10768bf98>]}
2018-07-30 14:48:41,409: 14:48:41 | 4 of 23 OK created table model template.mappings_ga_proc............. [OK in 2.57s]
2018-07-30 14:48:41,797: 14:48:41 | 3 of 23 OK created table model template.stores_proc.................. [OK in 2.96s]
2018-07-30 14:48:41,798: 14:48:41 | 5 of 23 START table model template.shopify_customers_proc............ [RUN]
2018-07-30 14:48:41,798: 14:48:41 | 6 of 23 START table model template.shopify_refunds_proc.............. [RUN]
2018-07-30 14:48:41,799: Compiling model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 14:48:41,798: 14:48:41 | 7 of 23 START table model template.shopify_discounts_proc............ [RUN]
2018-07-30 14:48:41,804: Compiling model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 14:48:41,799: Compiling model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 14:48:41,826: Acquiring new bigquery connection "shopify_customers_proc".
2018-07-30 14:48:41,832: Acquiring new bigquery connection "shopify_discounts_proc".
2018-07-30 14:48:41,833: Re-using an available connection from the pool.
2018-07-30 14:48:41,840: Acquiring new bigquery connection "shopify_refunds_proc".
2018-07-30 14:48:41,840: Fetching data for query shopify_customers_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:48:41,841: Re-using an available connection from the pool.
2018-07-30 14:48:41,842: Fetching data for query shopify_discounts_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:48:41,846: Re-using an available connection from the pool.
2018-07-30 14:48:41,846: Fetching data for query shopify_refunds_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:48:43,367: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 14:48:43,519: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 14:48:43,526: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 14:48:43,527: Fetching data for query shopify_refunds_proc:
create or replace table `template`.`shopify_refunds_proc`
  
  as (
    



with refunds as (

	
	SELECT
	'lucadanni' store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal,
	line_item.variant_id variant_id,
	line_item.id refund_id,
 	_sdc_sequence
	FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
	cross join unnest(refunds), unnest(refund_line_items)
  	where financial_status like '%refund%'
	
	

)

SELECT * 
FROM 
	(
    SELECT
    store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal refund_amount,
	variant_id,
	refund_id,
 	_sdc_sequence,
    first_value(_sdc_sequence) OVER (PARTITION BY order_number, line_item_id ORDER BY _sdc_sequence DESC) lv
    FROM refunds
   	) 
WHERE lv = _sdc_sequence


  );

    
2018-07-30 14:48:43,704: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 14:48:43,705: Fetching data for query shopify_customers_proc:
create or replace table `template`.`shopify_customers_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`





with customers as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	created_at,
	id,
	first_name,
	last_name,
	email,
	_sdc_sequence,
	first_value(_sdc_sequence) over (partition by id order by _sdc_sequence desc) lv
	FROM `growth-engines-pipeline.shopify_lucadanni.customers` 
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
id,
first_name,
last_name,
email
FROM customers a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence


  );

    
2018-07-30 14:48:44,990: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 14:48:45,611: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a1d3a58>]}
2018-07-30 14:48:45,625: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 14:48:45,626: Fetching data for query shopify_discounts_proc:
create or replace table `template`.`shopify_discounts_proc`
  
  as (
    



with orders as (

	
		SELECT
		'lucadanni' store_name,
		created_at,
		order_number,
		code discount_code,
		type discount_type,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(discount_codes)
		where source_name != 'shopify_draft_order'
	
	
	

)

SELECT
store_name,
order_number,
discount_code,
discount_type
FROM orders
where lv = _sdc_sequence


  );

    
2018-07-30 14:48:46,403: 14:48:46 | 6 of 23 OK created table model template.shopify_refunds_proc......... [OK in 3.81s]
2018-07-30 14:48:48,801: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d997b8>]}
2018-07-30 14:48:49,213: 14:48:49 | 7 of 23 OK created table model template.shopify_discounts_proc....... [OK in 7.00s]
2018-07-30 14:48:49,871: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a290940>]}
2018-07-30 14:48:50,237: 14:48:50 | 5 of 23 OK created table model template.shopify_customers_proc....... [OK in 8.07s]
2018-07-30 14:48:50,238: 14:48:50 | 8 of 23 START table model template.ga_transactions................... [RUN]
2018-07-30 14:48:50,239: 14:48:50 | 9 of 23 START table model template.shopify_products_proc............. [RUN]
2018-07-30 14:48:50,239: Compiling model.shopify_cohort_analysis.ga_transactions
2018-07-30 14:48:50,239: 14:48:50 | 10 of 23 START table model template.agg_customers.................... [RUN]
2018-07-30 14:48:50,240: Compiling model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 14:48:50,245: Compiling model.shopify_cohort_analysis.agg_customers
2018-07-30 14:48:50,255: Acquiring new bigquery connection "ga_transactions".
2018-07-30 14:48:50,276: Writing injected SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 14:48:50,277: Acquiring new bigquery connection "shopify_products_proc".
2018-07-30 14:48:50,277: Re-using an available connection from the pool.
2018-07-30 14:48:50,278: Fetching data for query ga_transactions:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Google Analytics'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:48:50,278: Re-using an available connection from the pool.
2018-07-30 14:48:50,280: Acquiring new bigquery connection "agg_customers".
2018-07-30 14:48:50,280: Fetching data for query shopify_products_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:48:50,282: Re-using an available connection from the pool.
2018-07-30 14:48:50,799: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 14:48:50,802: Fetching data for query agg_customers:
create or replace table `template`.`agg_customers`
  
  as (
    SELECT 
account,
store,
id,
created_at,
first_name,
last_name,
email,
split(email,'@')[SAFE_ORDINAL(2)] email_domain
FROM
`growth-engines-pipeline`.`template`.`shopify_customers_proc`
  );

    
2018-07-30 14:48:52,475: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 14:48:53,006: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 14:48:53,010: Writing injected SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 14:48:53,010: Fetching data for query shopify_products_proc:
create or replace table `template`.`shopify_products_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`





with products as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	product_name,
	lower(product_type) product_type,
	product_id,
	sku,
	id variant_id,
	cast(created_at as date) created_at,
	_sdc_sequence,
	first_value(_sdc_sequence) OVER (PARTITION BY product_id ORDER BY _sdc_sequence DESC) lv
	FROM (
		SELECT
		variants,
		product_type,
		title product_name,
		_sdc_sequence
		FROM `growth-engines-pipeline.shopify_lucadanni.products` 
		)
	cross join unnest(variants)
	
	

)

SELECT
b.account,
b.store,
b.platform,
max(product_type) product_type,
product_id,
variant_id,
sku,
created_at,
product_name
FROM products a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence
group by product_id, account, store, platform, sku, variant_id, created_at, product_name


  );

    
2018-07-30 14:48:53,786: Writing runtime SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 14:48:53,787: Fetching data for query ga_transactions:
create or replace table `template`.`ga_transactions`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`,`growth-engines-pipeline`.`template`.`mappings_ga_proc`




with ga_report as (

	    
	    	
		   	SELECT
		   	'yandy' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_yandy.report` 

		     UNION ALL 
	   
	    	
		   	SELECT
		   	'lucadanni' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_lucadanni.report` 

		    
	   

)


SELECT  
date,
b.store store,
c.source source,
c.medium medium,
a.campaign campaign,
concat(a.source, ' / ', a.medium) source_medium,  
case when c.platform is null then "Unmapped" else c.platform end as platform,
case when c.channel is null then "Unmapped" else c.channel end as channel,
url,
transactionid
FROM (

	SELECT 
	store_name,
	lookup_platform,
	date,
	transactionid,
	max(url) url,
	max(source) source,
	max(medium) medium,
	max(campaign) campaign
	FROM ga_report
	where lv = _sdc_sequence
	group by store_name, lookup_platform, date, transactionid

) a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name 
	AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`mappings_ga_proc` c
ON ( a.source = c.source
  AND a.medium = c.medium 
  AND a.store_name = c.store_name )


  );

    
2018-07-30 14:48:55,996: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076d4ef0>]}
2018-07-30 14:48:56,001: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a218908>]}
2018-07-30 14:48:56,564: 14:48:56 | 10 of 23 OK created table model template.agg_customers............... [OK in 5.75s]
2018-07-30 14:48:56,897: 14:48:56 | 9 of 23 OK created table model template.shopify_products_proc........ [OK in 5.76s]
2018-07-30 14:49:19,775: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a2aaf60>]}
2018-07-30 14:49:20,094: 14:49:20 | 8 of 23 OK created table model template.ga_transactions.............. [OK in 29.54s]
2018-07-30 14:49:20,096: 14:49:20 | 11 of 23 START table model template.shopify_orders_proc.............. [RUN]
2018-07-30 14:49:20,096: Compiling model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 14:49:20,116: Acquiring new bigquery connection "shopify_orders_proc".
2018-07-30 14:49:20,116: Re-using an available connection from the pool.
2018-07-30 14:49:20,116: Fetching data for query shopify_orders_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 14:49:22,936: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 14:49:23,600: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 14:49:23,601: Fetching data for query shopify_orders_proc:
create or replace table `template`.`shopify_orders_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`, `growth-engines-pipeline`.`template`.`shopify_discounts_proc`





with orders as (

	
	SELECT 
	store_name,
	lookup_platform,
	created_at,
	order_number,
	quantity,
	price, 
	total_order_price_undiscounted,
	total_discounts,
	total_order_shipping_price,
	total_order_price_incl_shipping,
	checkout_id,
	product_id, 
	landing_site,
	sku, 
	variant_title, 
	variant_id,
	line_item_id,
	customer_id,
	_sdc_sequence,
	lv
	FROM (

		SELECT
		'lucadanni' store_name,
		'Shopify' as lookup_platform,
		created_at,
		order_number,
		quantity,
		cast(pre_tax_price as float64) price, 
		total_line_items_price total_order_price_undiscounted,
		total_discounts,
		cast(discounted_price as float64) total_order_shipping_price,
		total_price_usd total_order_price_incl_shipping,
		checkout_id,
		product_id, 
		landing_site,
		sku, 
		variant_title, 
		variant_id,
		_id line_item_id,
		customer.id customer_id,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(line_items), unnest(shipping_lines)
		where source_name != 'shopify_draft_order'
	)
	
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
a.order_number,
a.quantity prelim_quantity,
c.quantity refund_quantity,
case when c.quantity is not null then a.quantity - c.quantity else a.quantity end as quantity,
price prelim_revenue, 
total_order_price_undiscounted,
total_discounts,
trim(lower(d.discount_code)) discount_code,
d.discount_type,
total_order_shipping_price,
total_order_price_incl_shipping,
refund_amount,
case when refund_amount is not null then price - refund_amount else price end as revenue,
a.checkout_id,
a.product_id, 
landing_site,
sku, 
variant_title, 
a.variant_id,
a.line_item_id,	
customer_id
FROM orders a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_refunds_proc` c
ON ( a.order_number = c.order_number
	AND a.line_item_id = c.line_item_id
	AND a.store_name = c.store_name )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_discounts_proc` d
ON ( a.order_number = d.order_number 
    AND a.store_name = d.store_name )  	
where a.lv = a._sdc_sequence


  );

    
2018-07-30 14:49:33,070: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a259390>]}
2018-07-30 14:49:33,844: 14:49:33 | 11 of 23 OK created table model template.shopify_orders_proc......... [OK in 12.97s]
2018-07-30 14:49:33,845: 14:49:33 | 12 of 23 START table model template.transaction_by_order_number...... [RUN]
2018-07-30 14:49:33,845: Compiling model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 14:49:33,854: Writing injected SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 14:49:33,856: Acquiring new bigquery connection "transaction_by_order_number".
2018-07-30 14:49:33,856: Re-using an available connection from the pool.
2018-07-30 14:49:34,321: Writing runtime SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 14:49:34,322: Fetching data for query transaction_by_order_number:
create or replace table `template`.`transaction_by_order_number`
  
  as (
    SELECT
store,
cast(created_at as date) order_date,
order_number,
customer_id,
sum(quantity) quantity,
sum(revenue) revenue,
max(total_order_shipping_price) shipping_price
FROM
`growth-engines-pipeline`.`template`.`shopify_orders_proc`
GROUP BY store, order_date, order_number, customer_id
  );

    
2018-07-30 14:49:39,537: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a258d30>]}
2018-07-30 14:49:40,966: 14:49:40 | 12 of 23 OK created table model template.transaction_by_order_number. [OK in 5.69s]
2018-07-30 14:49:40,967: 14:49:40 | 13 of 23 START table model template.customers_by_transaction......... [RUN]
2018-07-30 14:49:40,967: Compiling model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 14:49:40,978: Writing injected SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 14:49:40,979: Acquiring new bigquery connection "customers_by_transaction".
2018-07-30 14:49:40,980: Re-using an available connection from the pool.
2018-07-30 14:49:41,637: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 14:49:41,638: Fetching data for query customers_by_transaction:
create or replace table `template`.`customers_by_transaction`
  
  as (
    SELECT
store,
customer_id,
order_number,
order_date,
recent_order_date,
first_order_date,
case when first_order_number = order_number then 'New'
	when date_diff(order_date, recent_order_date, DAY) <= 365 then 'Repeat'
	when date_diff(order_date, recent_order_date, DAY) > 365 then 'Reactivated'
 else '' end as order_type,
quantity,
revenue,
1 as orders,
first_order_revenue,
lifetime_revenue
FROM

(

	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	quantity,
	revenue,
	lag(order_date) over w1 recent_order_date,
	first_value(order_date) over w1 first_order_date,
	first_value(order_number) over w1 first_order_number,
	first_value(revenue) over w1 first_order_revenue,
	sum(revenue) over w2 lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`transaction_by_order_number`
	WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc),
	w2 as (PARTITION BY store, customer_id)
)
  );

    
2018-07-30 14:49:45,611: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a2c8240>]}
2018-07-30 14:49:45,922: 14:49:45 | 13 of 23 OK created table model template.customers_by_transaction.... [OK in 4.64s]
2018-07-30 14:49:45,923: 14:49:45 | 14 of 23 START table model template.agg_transactions................. [RUN]
2018-07-30 14:49:45,924: Compiling model.shopify_cohort_analysis.agg_transactions
2018-07-30 14:49:45,937: Writing injected SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 14:49:45,940: Acquiring new bigquery connection "agg_transactions".
2018-07-30 14:49:45,941: Re-using an available connection from the pool.
2018-07-30 14:49:46,060: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 14:49:46,060: Fetching data for query agg_transactions:
create or replace table `template`.`agg_transactions`
  
  as (
    with ga_transaction as (

	SELECT
	date, 
	store,
	transactionid,
	channel,
	platform,
	url,
	campaign
	FROM `growth-engines-pipeline`.`template`.`ga_transactions`
),

customers_by_transaction as (
	
	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	first_order_date,
	recent_order_date,
	order_type,
	quantity,
	revenue,
	orders,
	first_order_revenue,
	lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`customers_by_transaction`
)

SELECT
store,
customer_id,
order_number,
transactionid,
order_date,
first_order_date,
format_date("%Y-%m", first_order_date) AS first_order_month,
order_type,
first_order_revenue,
lifetime_revenue,
first_value(channel) over w1 as first_order_channel,
first_value(platform) over w1 as first_order_platform,
channel,
platform,
url,
campaign,
quantity,
revenue,
orders
FROM (

	SELECT
	a.store,
	a.customer_id,
	a.order_number,
	b.transactionid,
	a.order_date, 
	a.first_order_date, 
	a.order_type,
	a.first_order_revenue,
	a.lifetime_revenue,
	b.channel,
	b.platform,
	b.url,
	b.campaign,
	a.quantity,
	a.revenue,
	a.orders
	FROM customers_by_transaction a
	LEFT JOIN ga_transaction b
	ON (
	    a.store = b.store AND
	    a.order_number = b.transactionid
	)	
)
WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc)
  );

    
2018-07-30 14:49:54,635: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a2c8e80>]}
2018-07-30 14:49:54,942: 14:49:54 | 14 of 23 OK created table model template.agg_transactions............ [OK in 8.71s]
2018-07-30 14:49:54,943: 14:49:54 | 15 of 23 START table model template.customers_proc_yoy............... [RUN]
2018-07-30 14:49:54,944: Compiling model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 14:49:54,952: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 14:49:54,944: 14:49:54 | 16 of 23 START table model template.customers_proc_qoq............... [RUN]
2018-07-30 14:49:54,952: Compiling model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 14:49:54,944: 14:49:54 | 17 of 23 START table model template.monthly_cohort_stats............. [RUN]
2018-07-30 14:49:54,961: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 14:49:54,962: Compiling model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 14:49:54,963: Acquiring new bigquery connection "customers_proc_yoy".
2018-07-30 14:49:54,971: Writing injected SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 14:49:54,971: Re-using an available connection from the pool.
2018-07-30 14:49:54,972: Acquiring new bigquery connection "customers_proc_qoq".
2018-07-30 14:49:54,973: Re-using an available connection from the pool.
2018-07-30 14:49:54,985: Acquiring new bigquery connection "monthly_cohort_stats".
2018-07-30 14:49:54,986: Re-using an available connection from the pool.
2018-07-30 14:49:55,134: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 14:49:55,141: Fetching data for query customers_proc_yoy:
create or replace table `template`.`customers_proc_yoy`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 365 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 365 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 365 window_end_unix_date, 
    unix_date_in_range - 730 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 730 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 365 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 14:49:55,153: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 14:49:55,154: Fetching data for query customers_proc_qoq:
create or replace table `template`.`customers_proc_qoq`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 90 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 90 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 90 window_end_unix_date, 
    unix_date_in_range - 180 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 180 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 90 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 14:49:55,181: Writing runtime SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 14:49:55,182: Fetching data for query monthly_cohort_stats:
create or replace table `template`.`monthly_cohort_stats`
  
  as (
    WITH transactions AS (

  SELECT 
  store, 
  order_number,
  order_date,
  order_type,
  first_order_month,
  unix_date(order_date) d, 
  customer_id, 
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (

  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT 
date_in_range date,
store, 
order_type,
first_order_channel,
first_order_platform,
first_order_month,
channel,
platform,
url,
campaign,
count(distinct(customer_id)) buyers,
sum(orders) orders,
sum(quantity) quantity,
sum(revenue) revenue
FROM daterange
JOIN transactions
ON transactions.d >= daterange.unix_date_in_range_bom 
AND transactions.d <= daterange.unix_date_in_range
GROUP BY date, store, order_type, 
first_order_channel, first_order_platform, first_order_month, channel, platform, url, campaign
  );

    
2018-07-30 14:49:59,855: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a2398d0>]}
2018-07-30 14:50:00,474: 14:50:00 | 17 of 23 OK created table model template.monthly_cohort_stats........ [OK in 4.89s]
2018-07-30 14:50:07,742: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a258908>]}
2018-07-30 14:50:08,050: 14:50:08 | 16 of 23 OK created table model template.customers_proc_qoq.......... [OK in 12.79s]
2018-07-30 14:50:16,873: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a2c8b38>]}
2018-07-30 14:50:17,171: 14:50:17 | 15 of 23 OK created table model template.customers_proc_yoy.......... [OK in 21.93s]
2018-07-30 14:50:17,172: 14:50:17 | 18 of 23 START table model template.customers_proc................... [RUN]
2018-07-30 14:50:17,172: Compiling model.shopify_cohort_analysis.customers_proc
2018-07-30 14:50:17,184: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 14:50:17,189: Acquiring new bigquery connection "customers_proc".
2018-07-30 14:50:17,189: Re-using an available connection from the pool.
2018-07-30 14:50:17,322: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 14:50:17,323: Fetching data for query customers_proc:
create or replace table `template`.`customers_proc`
  
  as (
    SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_qoq`

UNION ALL

SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_yoy`
  );

    
2018-07-30 14:50:41,612: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10763eeb8>]}
2018-07-30 14:50:42,948: 14:50:42 | 18 of 23 OK created table model template.customers_proc.............. [OK in 24.44s]
2018-07-30 14:50:42,949: 14:50:42 | 19 of 23 START table model template.segment_proc_buyers.............. [RUN]
2018-07-30 14:50:42,950: Compiling model.shopify_cohort_analysis.segment_proc_buyers
2018-07-30 14:50:42,958: Writing injected SQL for node "model.shopify_cohort_analysis.segment_proc_buyers"
2018-07-30 14:50:42,960: Acquiring new bigquery connection "segment_proc_buyers".
2018-07-30 14:50:42,961: Re-using an available connection from the pool.
2018-07-30 14:50:43,105: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_proc_buyers"
2018-07-30 14:50:43,106: Fetching data for query segment_proc_buyers:
create or replace table `template`.`segment_proc_buyers`
  
  as (
    SELECT
store,
period,
customer_id,
date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct,
case when first_order_unix_date >= window_start_unix_date then 'New'
	else 'Existing' end as newness_segment,
case when revenue >= revenue_90pct then 'Top 10%'
	when revenue <= revenue_10pct then 'Bottom 10%'
	else 'Middle 80%' end as revenue_segment,
case when frequency = 1 then '1'
	when frequency = 2 then '2'
	when frequency > 2 then '3+'
	else null end as frequency_segment
FROM `growth-engines-pipeline`.`template`.`customers_proc`
  );

    
2018-07-30 14:51:14,220: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10763e438>]}
2018-07-30 14:51:14,655: 14:51:14 | 19 of 23 OK created table model template.segment_proc_buyers......... [OK in 31.27s]
2018-07-30 14:51:14,655: 14:51:14 | 20 of 23 START table model template.segment_stats_buyers_agg......... [RUN]
2018-07-30 14:51:14,656: Compiling model.shopify_cohort_analysis.segment_stats_buyers_agg
2018-07-30 14:51:14,666: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_agg"
2018-07-30 14:51:14,668: Acquiring new bigquery connection "segment_stats_buyers_agg".
2018-07-30 14:51:14,669: Re-using an available connection from the pool.
2018-07-30 14:51:15,024: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_agg"
2018-07-30 14:51:15,025: Fetching data for query segment_stats_buyers_agg:
create or replace table `template`.`segment_stats_buyers_agg`
  
  as (
    WITH ty as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev,
	0 as retention_eligible,
	case when newness_segment = 'Existing' then 1 else 0 end as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Year'

),

this_month_1yr as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment,
	frequency_segment,
	newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	recency_days as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev,
	1 as retention_eligible,
	0 as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Previous Year'

),

this_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,	
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment,
	frequency_segment,
	newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev,
	0 as retention_eligible,
	case when newness_segment = 'Existing' then 1 else 0 end as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Quarter'

),

last_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	recency_days as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev,
	1 as retention_eligible,
	0 as retention_success
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Previous Quarter'

)

SELECT
store,
period,
date, 
customer_id,
1 as buyers,
first_order_channel,
first_order_platform,	
revenue_segment,
frequency_segment,
newness_segment,	
ifnull(sum(recency), 0) recency,
ifnull(sum(frequency), 0) frequency,
ifnull(sum(revenue), 0) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else 0 end as aov,
ifnull(sum(recency_prev), 0) recency_prev,
ifnull(sum(frequency_prev), 0) frequency_prev,
ifnull(sum(revenue_prev), 0) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else 0 end as aov_prev,
sum(retention_eligible) retention_eligible,
sum(retention_success) retention_success
FROM
(
	SELECT * FROM ty
	UNION ALL
	SELECT * FROM this_month_1yr
	UNION ALL
	SELECT * FROM this_quarter
	UNION ALL
	SELECT * FROM last_quarter

)
GROUP BY store, period, date, customer_id, first_order_channel, first_order_platform,
revenue_segment, frequency_segment, newness_segment
  );

    
2018-07-30 14:51:53,228: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108716048>]}
2018-07-30 14:51:55,150: 14:51:55 | 20 of 23 OK created table model template.segment_stats_buyers_agg.... [OK in 38.57s]
2018-07-30 14:51:55,151: 14:51:55 | 21 of 23 START table model template.segment_stats_buyers_view........ [RUN]
2018-07-30 14:51:55,151: Compiling model.shopify_cohort_analysis.segment_stats_buyers_view
2018-07-30 14:51:55,171: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_view"
2018-07-30 14:51:55,174: Acquiring new bigquery connection "segment_stats_buyers_view".
2018-07-30 14:51:55,175: Re-using an available connection from the pool.
2018-07-30 14:51:56,331: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_view"
2018-07-30 14:51:56,334: Fetching data for query segment_stats_buyers_view:
create or replace table `template`.`segment_stats_buyers_view`
  
  as (
    SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Total' as segment_type,
'Total' as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Total' as segment_type,
'Total' as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Total' as segment_type,
'Total' as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type
  );

    
2018-07-30 14:52:01,108: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a19c5f8>]}
2018-07-30 14:52:01,399: 14:52:01 | 21 of 23 OK created table model template.segment_stats_buyers_view... [OK in 5.96s]
2018-07-30 14:52:01,400: 14:52:01 | 22 of 23 START table model template.buyer_segment_stats.............. [RUN]
2018-07-30 14:52:01,401: Compiling model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 14:52:01,410: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 14:52:01,412: Acquiring new bigquery connection "buyer_segment_stats".
2018-07-30 14:52:01,413: Re-using an available connection from the pool.
2018-07-30 14:52:01,682: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 14:52:01,683: Fetching data for query buyer_segment_stats:
create or replace table `template`.`buyer_segment_stats`
  
  as (
    SELECT
store,
period,
date,
view,
view_segment,
segment_type,
segment,
buyers,
total_view_buyers,
case when total_view_buyers > 0 then buyers / total_view_buyers else null end as pct_of_view_segment_buyers,
recency,
frequency,
revenue,
total_view_revenue,
case when total_view_revenue > 0 then revenue / total_view_revenue else null end as pct_of_view_segment_revenue,
aov,
recency_prev,
frequency_prev,
revenue_prev,
aov_prev,
retention_rate
FROM (

	SELECT
	store,
	period,
	date,
	view,
	view_segment,
	segment_type,
	segment,
	buyers,
	sum(buyers) over w1 as total_view_buyers,
	recency,
	frequency,
	revenue,
	sum(revenue) over w1 as total_view_revenue,
	aov,
	recency_prev,
	frequency_prev,
	revenue_prev,
	aov_prev,
	retention_rate
	FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_view`
	WINDOW w1 as (PARTITION BY store, period, date, segment_type, view, view_segment)
)
  );

    
2018-07-30 14:52:03,555: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108716048>]}
2018-07-30 14:52:04,343: 14:52:04 | 22 of 23 OK created table model template.buyer_segment_stats......... [OK in 2.15s]
2018-07-30 14:52:04,344: 14:52:04 | 23 of 23 START table model template.buyer_segment_lists.............. [RUN]
2018-07-30 14:52:04,345: Compiling model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 14:52:04,359: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 14:52:04,362: Acquiring new bigquery connection "buyer_segment_lists".
2018-07-30 14:52:04,362: Re-using an available connection from the pool.
2018-07-30 14:52:04,515: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 14:52:04,516: Fetching data for query buyer_segment_lists:
create or replace table `template`.`buyer_segment_lists`
  
  as (
    SELECT
a.store,
period,
date,
customer_id,
b.first_name,
b.last_name,
b.email,
recency,
frequency,
revenue,
aov,
revenue_segment,
frequency_segment
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg` a
LEFT JOIN `growth-engines-pipeline`.`template`.`agg_customers` b
ON (
	a.store = b.store AND
	a.customer_id = b.id
)
where ( revenue_segment != '' or frequency_segment != '' )
  );

    
2018-07-30 14:52:36,255: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8aadbbb1-59b7-4624-9aea-8ffc46a2a088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a239cc0>]}
2018-07-30 14:52:36,587: 14:52:36 | 23 of 23 OK created table model template.buyer_segment_lists......... [OK in 31.91s]
2018-07-30 14:52:36,609: 14:52:36 | 
2018-07-30 14:52:36,609: 14:52:36 | Finished running 23 table models in 239.63s.
2018-07-30 14:52:36,609: Connection 'master' was left open.
2018-07-30 14:52:36,610: 
2018-07-30 14:52:36,610: Completed successfully
2018-07-30 14:52:36,610: 
Done. PASS=23 ERROR=0 SKIP=0 TOTAL=23
2018-07-30 14:52:36,611: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a1d0518>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a20a9e8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a20acc0>]}
2018-07-30 14:52:36,911: Flushing usage events
2018-07-30 14:52:37,134: sys:1: ResourceWarning: unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 56249), raddr=('172.217.12.10', 443)>

2018-07-30 14:52:37,135: sys:1: ResourceWarning: unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 56248), raddr=('172.217.2.13', 443)>

2018-07-30 14:52:37,136: sys:1: ResourceWarning: unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 56257), raddr=('172.217.12.10', 443)>

2018-07-30 14:52:37,136: sys:1: ResourceWarning: unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 56254), raddr=('172.217.12.10', 443)>

2018-07-30 14:52:37,139: sys:1: ResourceWarning: unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 56250), raddr=('172.217.2.13', 443)>

2018-07-30 14:52:37,139: sys:1: ResourceWarning: unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 56251), raddr=('172.217.2.13', 443)>

2018-07-30 14:52:37,140: sys:1: ResourceWarning: unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 56255), raddr=('172.217.12.10', 443)>

2018-07-30 14:52:37,141: sys:1: ResourceWarning: unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 56256), raddr=('172.217.12.10', 443)>

2018-07-30 14:52:37,141: sys:1: ResourceWarning: unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 56252), raddr=('172.217.2.13', 443)>

2018-07-30 14:52:37,142: sys:1: ResourceWarning: unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 56253), raddr=('172.217.2.13', 443)>

2018-07-30 15:14:21,706: Tracking: tracking
2018-07-30 15:14:21,708: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1133ed2e8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1133ed400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1133ede80>]}
2018-07-30 15:14:23,275: Loading dependency project from /usr/local/Cellar/dbt/0.10.1/libexec/lib/python3.6/site-packages/dbt/include
2018-07-30 15:14:23,309: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/shopify-cohort-analysis/dbt_modules
2018-07-30 15:14:23,318: Parsing get_column_values.sql
2018-07-30 15:14:23,339: Parsing get_url_parameter.sql
2018-07-30 15:14:23,345: Parsing split_part.sql
2018-07-30 15:14:23,353: Parsing table_exists.sql
2018-07-30 15:14:23,364: Parsing core.sql
2018-07-30 15:14:23,380: Parsing adapters/bigquery.sql
2018-07-30 15:14:23,395: Parsing adapters/common.sql
2018-07-30 15:14:23,428: Parsing adapters/redshift.sql
2018-07-30 15:14:23,448: Parsing adapters/snowflake.sql
2018-07-30 15:14:23,454: Parsing etc/bigquery.sql
2018-07-30 15:14:23,459: Parsing etc/datetime.sql
2018-07-30 15:14:23,490: Parsing etc/get_custom_schema.sql
2018-07-30 15:14:23,498: Parsing materializations/helpers.sql
2018-07-30 15:14:23,518: Parsing materializations/archive/archive.sql
2018-07-30 15:14:23,566: Parsing materializations/incremental/incremental.sql
2018-07-30 15:14:23,609: Parsing materializations/seed/bigquery.sql
2018-07-30 15:14:23,619: Parsing materializations/seed/seed.sql
2018-07-30 15:14:23,687: Parsing materializations/table/bigquery_table.sql
2018-07-30 15:14:23,725: Parsing materializations/table/table.sql
2018-07-30 15:14:23,751: Parsing materializations/view/bigquery_view.sql
2018-07-30 15:14:23,765: Parsing materializations/view/view.sql
2018-07-30 15:14:23,787: Parsing schema_tests/accepted_values.sql
2018-07-30 15:14:23,793: Parsing schema_tests/not_null.sql
2018-07-30 15:14:23,797: Parsing schema_tests/relationships.sql
2018-07-30 15:14:23,804: Parsing schema_tests/unique.sql
2018-07-30 15:14:23,847: Parsing model.shopify_cohort_analysis.all_dates
2018-07-30 15:14:23,850: Parsing model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 15:14:23,853: Parsing model.shopify_cohort_analysis.monthend_dates
2018-07-30 15:14:23,855: Parsing model.shopify_cohort_analysis.stores_proc
2018-07-30 15:14:23,857: Parsing model.shopify_cohort_analysis.ga_transactions
2018-07-30 15:14:23,867: Parsing model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 15:14:23,875: Parsing model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 15:14:23,881: Parsing model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 15:14:23,892: Parsing model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 15:14:23,901: Parsing model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 15:14:23,907: Parsing model.shopify_cohort_analysis.agg_customers
2018-07-30 15:14:23,910: Parsing model.shopify_cohort_analysis.agg_transactions
2018-07-30 15:14:23,914: Parsing model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 15:14:23,916: Parsing model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 15:14:23,919: Parsing model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 15:14:23,922: Parsing model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 15:14:23,925: Parsing model.shopify_cohort_analysis.customers_proc
2018-07-30 15:14:23,929: Parsing model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 15:14:23,933: Parsing model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 15:14:23,938: Parsing model.shopify_cohort_analysis.segment_proc_buyers
2018-07-30 15:14:23,941: Parsing model.shopify_cohort_analysis.segment_stats_buyers_agg
2018-07-30 15:14:23,946: Parsing model.shopify_cohort_analysis.segment_stats_buyers_view
2018-07-30 15:14:23,957: Parsing model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 15:14:23,975: Found 23 models, 0 tests, 0 archives, 0 analyses, 62 macros, 0 operations, 0 seed files
2018-07-30 15:14:23,982: 
2018-07-30 15:14:23,989: Acquiring new bigquery connection "master".
2018-07-30 15:14:23,989: Opening a new connection (0 currently allocated)
2018-07-30 15:14:25,426: 15:14:25 | Concurrency: 4 threads (target='template')
2018-07-30 15:14:25,426: 15:14:25 | 
2018-07-30 15:14:25,494: 15:14:25 | 1 of 23 START table model template.mappings_ga_proc.................. [RUN]
2018-07-30 15:14:25,494: Compiling model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 15:14:25,499: Writing injected SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 15:14:25,494: 15:14:25 | 2 of 23 START table model template.monthend_dates.................... [RUN]
2018-07-30 15:14:25,494: 15:14:25 | 3 of 23 START table model template.all_dates......................... [RUN]
2018-07-30 15:14:25,494: 15:14:25 | 4 of 23 START table model template.stores_proc....................... [RUN]
2018-07-30 15:14:25,500: Compiling model.shopify_cohort_analysis.monthend_dates
2018-07-30 15:14:25,500: Compiling model.shopify_cohort_analysis.all_dates
2018-07-30 15:14:25,500: Compiling model.shopify_cohort_analysis.stores_proc
2018-07-30 15:14:25,506: Writing injected SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 15:14:25,510: Writing injected SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 15:14:25,518: Writing injected SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 15:14:25,520: Acquiring new bigquery connection "monthend_dates".
2018-07-30 15:14:25,522: Acquiring new bigquery connection "mappings_ga_proc".
2018-07-30 15:14:25,522: Opening a new connection (1 currently allocated)
2018-07-30 15:14:25,526: Acquiring new bigquery connection "all_dates".
2018-07-30 15:14:25,529: Acquiring new bigquery connection "stores_proc".
2018-07-30 15:14:25,538: Opening a new connection (2 currently allocated)
2018-07-30 15:14:25,542: Opening a new connection (3 currently allocated)
2018-07-30 15:14:25,546: Opening a new connection (4 currently allocated)
2018-07-30 15:14:25,975: Writing runtime SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 15:14:25,991: Writing runtime SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 15:14:26,002: Writing runtime SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 15:14:26,003: Fetching data for query mappings_ga_proc:
create or replace table `template`.`mappings_ga_proc`
  
  as (
    select 
store,
account,
store_name,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client store,
account,
client_name store_name,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.mappings_ga` 

) 

WHERE lv = time_of_entry
group by store, account, store_name, source, medium, platform_n, channel_n, time_of_entry
  );

    
2018-07-30 15:14:26,009: Fetching data for query monthend_dates:
create or replace table `template`.`monthend_dates`
  
  as (
    SELECT
date_in_range,
date_in_range_bom,
date_in_range_bom_mom,
unix_date_in_range,
unix_date_in_range_bom,
unix_date(date_in_range_bom_mom) unix_date_in_range_bom_mom,
yyyymm,
date_in_range_yoy,
unix_date(date_in_range_yoy) unix_date_in_range_yoy

FROM
(
	SELECT 
	date_in_range,
	date_in_range_bom,
	date_sub(date_in_range_bom, INTERVAL 1 MONTH) date_in_range_bom_mom,
	date_sub(date_in_range, INTERVAL 1 YEAR) date_in_range_yoy,
	unix_date_in_range,
	unix_date(date_in_range_bom) unix_date_in_range_bom,
	yyyymm,
	first_value(date_in_range) over (partition by yyyymm order by date_in_range desc) monthend_date_in_range
	FROM
	( 
		SELECT 
		date_in_range,
		date_trunc( date_in_range, MONTH) date_in_range_bom,
		unix_date(date_in_range) unix_date_in_range,
		format_date("%Y-%m", date_in_range) AS yyyymm
		FROM UNNEST(
		    GENERATE_DATE_ARRAY(DATE('2016-01-31'), CURRENT_DATE(), INTERVAL 1 DAY)
		) AS date_in_range
	)
)
where date_in_range = monthend_date_in_range
  );

    
2018-07-30 15:14:26,015: Writing runtime SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 15:14:26,015: Fetching data for query stores_proc:
create or replace table `template`.`stores_proc`
  
  as (
    select 
store,
store_name,
account,
platform,
max(time_of_entry) time_of_entry

from  ( 

SELECT  
client store,
client_name store_name,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.accounts` 
where client_name != ''

) 

WHERE lv = time_of_entry
group by store, store_name, account, platform
  );

    
2018-07-30 15:14:26,028: Fetching data for query all_dates:
create or replace table `template`.`all_dates`
  
  as (
    SELECT 
date_in_range,
unix_date(date_in_range) unix_date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
  );

    
2018-07-30 15:14:27,802: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113535438>]}
2018-07-30 15:14:27,965: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113535a58>]}
2018-07-30 15:14:28,066: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113583ef0>]}
2018-07-30 15:14:28,084: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113535080>]}
2018-07-30 15:14:28,108: 15:14:28 | 2 of 23 OK created table model template.monthend_dates............... [OK in 2.30s]
2018-07-30 15:14:28,415: 15:14:28 | 4 of 23 OK created table model template.stores_proc.................. [OK in 2.46s]
2018-07-30 15:14:28,719: 15:14:28 | 1 of 23 OK created table model template.mappings_ga_proc............. [OK in 2.57s]
2018-07-30 15:14:29,023: 15:14:29 | 3 of 23 OK created table model template.all_dates.................... [OK in 2.58s]
2018-07-30 15:14:29,024: 15:14:29 | 5 of 23 START table model template.shopify_refunds_proc.............. [RUN]
2018-07-30 15:14:29,024: 15:14:29 | 6 of 23 START table model template.shopify_discounts_proc............ [RUN]
2018-07-30 15:14:29,025: Compiling model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 15:14:29,025: 15:14:29 | 7 of 23 START table model template.shopify_customers_proc............ [RUN]
2018-07-30 15:14:29,025: Compiling model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 15:14:29,032: Compiling model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 15:14:29,046: Acquiring new bigquery connection "shopify_discounts_proc".
2018-07-30 15:14:29,069: Acquiring new bigquery connection "shopify_refunds_proc".
2018-07-30 15:14:29,074: Acquiring new bigquery connection "shopify_customers_proc".
2018-07-30 15:14:29,074: Re-using an available connection from the pool.
2018-07-30 15:14:29,074: Fetching data for query shopify_discounts_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:14:29,074: Re-using an available connection from the pool.
2018-07-30 15:14:29,077: Fetching data for query shopify_refunds_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:14:29,077: Re-using an available connection from the pool.
2018-07-30 15:14:29,078: Fetching data for query shopify_customers_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:14:30,608: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 15:14:30,612: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 15:14:30,977: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 15:14:30,977: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 15:14:30,978: Fetching data for query shopify_refunds_proc:
create or replace table `template`.`shopify_refunds_proc`
  
  as (
    



with refunds as (

	
	SELECT
	'lucadanni' store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal,
	line_item.variant_id variant_id,
	line_item.id refund_id,
 	_sdc_sequence
	FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
	cross join unnest(refunds), unnest(refund_line_items)
  	where financial_status like '%refund%'
	
	

)

SELECT * 
FROM 
	(
    SELECT
    store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal refund_amount,
	variant_id,
	refund_id,
 	_sdc_sequence,
    first_value(_sdc_sequence) OVER (PARTITION BY order_number, line_item_id ORDER BY _sdc_sequence DESC) lv
    FROM refunds
   	) 
WHERE lv = _sdc_sequence


  );

    
2018-07-30 15:14:30,978: Fetching data for query shopify_discounts_proc:
create or replace table `template`.`shopify_discounts_proc`
  
  as (
    



with orders as (

	
		SELECT
		'lucadanni' store_name,
		created_at,
		order_number,
		code discount_code,
		type discount_type,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(discount_codes)
		where source_name != 'shopify_draft_order'
	
	
	

)

SELECT
store_name,
order_number,
discount_code,
discount_type
FROM orders
where lv = _sdc_sequence


  );

    
2018-07-30 15:14:31,308: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 15:14:31,498: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 15:14:31,499: Fetching data for query shopify_customers_proc:
create or replace table `template`.`shopify_customers_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`





with customers as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	created_at,
	id,
	first_name,
	last_name,
	email,
	_sdc_sequence,
	first_value(_sdc_sequence) over (partition by id order by _sdc_sequence desc) lv
	FROM `growth-engines-pipeline.shopify_lucadanni.customers` 
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
id,
first_name,
last_name,
email
FROM customers a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence


  );

    
2018-07-30 15:14:33,214: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113695c50>]}
2018-07-30 15:14:33,544: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11361b550>]}
2018-07-30 15:14:34,118: 15:14:34 | 5 of 23 OK created table model template.shopify_refunds_proc......... [OK in 4.19s]
2018-07-30 15:14:34,419: 15:14:34 | 6 of 23 OK created table model template.shopify_discounts_proc....... [OK in 4.52s]
2018-07-30 15:14:36,528: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113695240>]}
2018-07-30 15:14:36,837: 15:14:36 | 7 of 23 OK created table model template.shopify_customers_proc....... [OK in 7.50s]
2018-07-30 15:14:36,838: 15:14:36 | 8 of 23 START table model template.ga_transactions................... [RUN]
2018-07-30 15:14:36,839: 15:14:36 | 9 of 23 START table model template.agg_customers..................... [RUN]
2018-07-30 15:14:36,839: Compiling model.shopify_cohort_analysis.ga_transactions
2018-07-30 15:14:36,839: 15:14:36 | 10 of 23 START table model template.shopify_products_proc............ [RUN]
2018-07-30 15:14:36,839: Compiling model.shopify_cohort_analysis.agg_customers
2018-07-30 15:14:36,850: Compiling model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 15:14:36,856: Acquiring new bigquery connection "ga_transactions".
2018-07-30 15:14:36,872: Re-using an available connection from the pool.
2018-07-30 15:14:36,873: Fetching data for query ga_transactions:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Google Analytics'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:14:36,867: Writing injected SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 15:14:36,872: Acquiring new bigquery connection "shopify_products_proc".
2018-07-30 15:14:36,881: Re-using an available connection from the pool.
2018-07-30 15:14:36,881: Fetching data for query shopify_products_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:14:36,877: Acquiring new bigquery connection "agg_customers".
2018-07-30 15:14:36,882: Re-using an available connection from the pool.
2018-07-30 15:14:37,033: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 15:14:37,035: Fetching data for query agg_customers:
create or replace table `template`.`agg_customers`
  
  as (
    SELECT 
account,
store,
id,
created_at,
first_name,
last_name,
email,
split(email,'@')[SAFE_ORDINAL(2)] email_domain
FROM
`growth-engines-pipeline`.`template`.`shopify_customers_proc`
  );

    
2018-07-30 15:14:37,588: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 15:14:37,748: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 15:14:37,754: Fetching data for query shopify_products_proc:
create or replace table `template`.`shopify_products_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`





with products as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	product_name,
	lower(product_type) product_type,
	product_id,
	sku,
	id variant_id,
	cast(created_at as date) created_at,
	_sdc_sequence,
	first_value(_sdc_sequence) OVER (PARTITION BY product_id ORDER BY _sdc_sequence DESC) lv
	FROM (
		SELECT
		variants,
		product_type,
		title product_name,
		_sdc_sequence
		FROM `growth-engines-pipeline.shopify_lucadanni.products` 
		)
	cross join unnest(variants)
	
	

)

SELECT
b.account,
b.store,
b.platform,
max(product_type) product_type,
product_id,
variant_id,
sku,
created_at,
product_name
FROM products a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence
group by product_id, account, store, platform, sku, variant_id, created_at, product_name


  );

    
2018-07-30 15:14:38,654: Writing injected SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 15:14:38,821: Writing runtime SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 15:14:38,821: Fetching data for query ga_transactions:
create or replace table `template`.`ga_transactions`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`,`growth-engines-pipeline`.`template`.`mappings_ga_proc`




with ga_report as (

	    
	    	
		   	SELECT
		   	'yandy' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_yandy.report` 

		     UNION ALL 
	   
	    	
		   	SELECT
		   	'lucadanni' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_lucadanni.report` 

		    
	   

)


SELECT  
date,
b.store store,
c.source source,
c.medium medium,
a.campaign campaign,
concat(a.source, ' / ', a.medium) source_medium,  
case when c.platform is null then "Unmapped" else c.platform end as platform,
case when c.channel is null then "Unmapped" else c.channel end as channel,
url,
transactionid
FROM (

	SELECT 
	store_name,
	lookup_platform,
	date,
	transactionid,
	max(url) url,
	max(source) source,
	max(medium) medium,
	max(campaign) campaign
	FROM ga_report
	where lv = _sdc_sequence
	group by store_name, lookup_platform, date, transactionid

) a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name 
	AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`mappings_ga_proc` c
ON ( a.source = c.source
  AND a.medium = c.medium 
  AND a.store_name = c.store_name )


  );

    
2018-07-30 15:14:40,333: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1136239b0>]}
2018-07-30 15:14:40,688: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113695898>]}
2018-07-30 15:14:41,017: 15:14:41 | 10 of 23 OK created table model template.shopify_products_proc....... [OK in 3.48s]
2018-07-30 15:14:41,812: 15:14:41 | 9 of 23 OK created table model template.agg_customers................ [OK in 3.85s]
2018-07-30 15:15:04,363: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134b96a0>]}
2018-07-30 15:15:04,693: 15:15:04 | 8 of 23 OK created table model template.ga_transactions.............. [OK in 27.52s]
2018-07-30 15:15:04,694: 15:15:04 | 11 of 23 START table model template.shopify_orders_proc.............. [RUN]
2018-07-30 15:15:04,695: Compiling model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 15:15:04,731: Acquiring new bigquery connection "shopify_orders_proc".
2018-07-30 15:15:04,731: Re-using an available connection from the pool.
2018-07-30 15:15:04,731: Fetching data for query shopify_orders_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:15:05,445: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 15:15:05,668: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 15:15:05,669: Fetching data for query shopify_orders_proc:
create or replace table `template`.`shopify_orders_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`, `growth-engines-pipeline`.`template`.`shopify_discounts_proc`





with orders as (

	
	SELECT 
	store_name,
	lookup_platform,
	created_at,
	order_number,
	quantity,
	price, 
	total_order_price_undiscounted,
	total_discounts,
	total_order_shipping_price,
	total_order_price_incl_shipping,
	checkout_id,
	product_id, 
	landing_site,
	sku, 
	variant_title, 
	variant_id,
	line_item_id,
	customer_id,
	_sdc_sequence,
	lv
	FROM (

		SELECT
		'lucadanni' store_name,
		'Shopify' as lookup_platform,
		created_at,
		order_number,
		quantity,
		cast(pre_tax_price as float64) price, 
		total_line_items_price total_order_price_undiscounted,
		total_discounts,
		cast(discounted_price as float64) total_order_shipping_price,
		total_price_usd total_order_price_incl_shipping,
		checkout_id,
		product_id, 
		landing_site,
		sku, 
		variant_title, 
		variant_id,
		_id line_item_id,
		customer.id customer_id,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(line_items), unnest(shipping_lines)
		where source_name != 'shopify_draft_order'
	)
	
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
a.order_number,
a.quantity prelim_quantity,
c.quantity refund_quantity,
case when c.quantity is not null then a.quantity - c.quantity else a.quantity end as quantity,
price prelim_revenue, 
total_order_price_undiscounted,
total_discounts,
trim(lower(d.discount_code)) discount_code,
d.discount_type,
total_order_shipping_price,
total_order_price_incl_shipping,
refund_amount,
case when refund_amount is not null then price - refund_amount else price end as revenue,
a.checkout_id,
a.product_id, 
landing_site,
sku, 
variant_title, 
a.variant_id,
a.line_item_id,	
customer_id
FROM orders a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_refunds_proc` c
ON ( a.order_number = c.order_number
	AND a.line_item_id = c.line_item_id
	AND a.store_name = c.store_name )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_discounts_proc` d
ON ( a.order_number = d.order_number 
    AND a.store_name = d.store_name )  	
where a.lv = a._sdc_sequence


  );

    
2018-07-30 15:15:16,584: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113695240>]}
2018-07-30 15:15:16,894: 15:15:16 | 11 of 23 OK created table model template.shopify_orders_proc......... [OK in 11.89s]
2018-07-30 15:15:16,895: 15:15:16 | 12 of 23 START table model template.transaction_by_order_number...... [RUN]
2018-07-30 15:15:16,896: Compiling model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 15:15:16,908: Writing injected SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 15:15:16,913: Acquiring new bigquery connection "transaction_by_order_number".
2018-07-30 15:15:16,913: Re-using an available connection from the pool.
2018-07-30 15:15:17,109: Writing runtime SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 15:15:17,110: Fetching data for query transaction_by_order_number:
create or replace table `template`.`transaction_by_order_number`
  
  as (
    SELECT
store,
cast(created_at as date) order_date,
order_number,
customer_id,
sum(quantity) quantity,
sum(revenue) revenue,
max(total_order_shipping_price) shipping_price
FROM
`growth-engines-pipeline`.`template`.`shopify_orders_proc`
GROUP BY store, order_date, order_number, customer_id
  );

    
2018-07-30 15:15:21,940: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11366a048>]}
2018-07-30 15:15:22,231: 15:15:22 | 12 of 23 OK created table model template.transaction_by_order_number. [OK in 5.04s]
2018-07-30 15:15:22,231: 15:15:22 | 13 of 23 START table model template.customers_by_transaction......... [RUN]
2018-07-30 15:15:22,232: Compiling model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 15:15:22,241: Writing injected SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 15:15:22,243: Acquiring new bigquery connection "customers_by_transaction".
2018-07-30 15:15:22,244: Re-using an available connection from the pool.
2018-07-30 15:15:22,411: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 15:15:22,416: Fetching data for query customers_by_transaction:
create or replace table `template`.`customers_by_transaction`
  
  as (
    SELECT
store,
customer_id,
order_number,
order_date,
recent_order_date,
first_order_date,
case when first_order_number = order_number then 'New'
	when date_diff(order_date, recent_order_date, DAY) <= 365 then 'Repeat'
	when date_diff(order_date, recent_order_date, DAY) > 365 then 'Reactivated'
 else '' end as order_type,
quantity,
revenue,
1 as orders,
first_order_revenue,
lifetime_revenue
FROM

(

	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	quantity,
	revenue,
	lag(order_date) over w1 recent_order_date,
	first_value(order_date) over w1 first_order_date,
	first_value(order_number) over w1 first_order_number,
	first_value(revenue) over w1 first_order_revenue,
	sum(revenue) over w2 lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`transaction_by_order_number`
	WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc),
	w2 as (PARTITION BY store, customer_id)
)
  );

    
2018-07-30 15:15:26,206: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1136464e0>]}
2018-07-30 15:15:27,692: 15:15:27 | 13 of 23 OK created table model template.customers_by_transaction.... [OK in 3.97s]
2018-07-30 15:15:27,693: 15:15:27 | 14 of 23 START table model template.agg_transactions................. [RUN]
2018-07-30 15:15:27,693: Compiling model.shopify_cohort_analysis.agg_transactions
2018-07-30 15:15:27,703: Writing injected SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 15:15:27,707: Acquiring new bigquery connection "agg_transactions".
2018-07-30 15:15:27,707: Re-using an available connection from the pool.
2018-07-30 15:15:27,923: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 15:15:27,926: Fetching data for query agg_transactions:
create or replace table `template`.`agg_transactions`
  
  as (
    with ga_transaction as (

	SELECT
	date, 
	store,
	transactionid,
	channel,
	platform,
	url,
	campaign
	FROM `growth-engines-pipeline`.`template`.`ga_transactions`
),

customers_by_transaction as (
	
	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	first_order_date,
	recent_order_date,
	order_type,
	quantity,
	revenue,
	orders,
	first_order_revenue,
	lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`customers_by_transaction`
)

SELECT
store,
customer_id,
order_number,
transactionid,
order_date,
first_order_date,
format_date("%Y-%m", first_order_date) AS first_order_month,
order_type,
first_order_revenue,
lifetime_revenue,
first_value(channel) over w1 as first_order_channel,
first_value(platform) over w1 as first_order_platform,
channel,
platform,
url,
campaign,
quantity,
revenue,
orders
FROM (

	SELECT
	a.store,
	a.customer_id,
	a.order_number,
	b.transactionid,
	a.order_date, 
	a.first_order_date, 
	a.order_type,
	a.first_order_revenue,
	a.lifetime_revenue,
	b.channel,
	b.platform,
	b.url,
	b.campaign,
	a.quantity,
	a.revenue,
	a.orders
	FROM customers_by_transaction a
	LEFT JOIN ga_transaction b
	ON (
	    a.store = b.store AND
	    a.order_number = b.transactionid
	)	
)
WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc)
  );

    
2018-07-30 15:15:36,620: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11366a048>]}
2018-07-30 15:15:36,997: 15:15:36 | 14 of 23 OK created table model template.agg_transactions............ [OK in 8.93s]
2018-07-30 15:15:36,998: 15:15:36 | 15 of 23 START table model template.customers_proc_qoq............... [RUN]
2018-07-30 15:15:36,998: Compiling model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 15:15:37,009: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 15:15:36,999: 15:15:36 | 16 of 23 START table model template.monthly_cohort_stats............. [RUN]
2018-07-30 15:15:37,009: Compiling model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 15:15:36,999: 15:15:36 | 17 of 23 START table model template.customers_proc_yoy............... [RUN]
2018-07-30 15:15:37,011: Compiling model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 15:15:37,019: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 15:15:37,026: Writing injected SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 15:15:37,029: Acquiring new bigquery connection "customers_proc_qoq".
2018-07-30 15:15:37,032: Acquiring new bigquery connection "monthly_cohort_stats".
2018-07-30 15:15:37,037: Acquiring new bigquery connection "customers_proc_yoy".
2018-07-30 15:15:37,037: Re-using an available connection from the pool.
2018-07-30 15:15:37,038: Re-using an available connection from the pool.
2018-07-30 15:15:37,044: Re-using an available connection from the pool.
2018-07-30 15:15:37,379: Writing runtime SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 15:15:37,384: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 15:15:37,391: Fetching data for query monthly_cohort_stats:
create or replace table `template`.`monthly_cohort_stats`
  
  as (
    WITH transactions AS (

  SELECT 
  store, 
  order_number,
  order_date,
  order_type,
  first_order_month,
  unix_date(order_date) d, 
  customer_id, 
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (

  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT 
date_in_range date,
store, 
order_type,
first_order_channel,
first_order_platform,
first_order_month,
channel,
platform,
url,
campaign,
count(distinct(customer_id)) buyers,
sum(orders) orders,
sum(quantity) quantity,
sum(revenue) revenue
FROM daterange
JOIN transactions
ON transactions.d >= daterange.unix_date_in_range_bom 
AND transactions.d <= daterange.unix_date_in_range
GROUP BY date, store, order_type, 
first_order_channel, first_order_platform, first_order_month, channel, platform, url, campaign
  );

    
2018-07-30 15:15:37,411: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 15:15:37,413: Fetching data for query customers_proc_qoq:
create or replace table `template`.`customers_proc_qoq`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 90 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 90 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 90 window_end_unix_date, 
    unix_date_in_range - 180 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 180 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 90 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 15:15:37,420: Fetching data for query customers_proc_yoy:
create or replace table `template`.`customers_proc_yoy`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 365 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 365 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 365 window_end_unix_date, 
    unix_date_in_range - 730 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 730 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 365 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 15:15:41,838: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113563550>]}
2018-07-30 15:15:42,191: 15:15:42 | 16 of 23 OK created table model template.monthly_cohort_stats........ [OK in 4.83s]
2018-07-30 15:15:50,240: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1136464e0>]}
2018-07-30 15:15:50,813: 15:15:50 | 15 of 23 OK created table model template.customers_proc_qoq.......... [OK in 13.24s]
2018-07-30 15:15:58,976: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a57828>]}
2018-07-30 15:15:59,268: 15:15:59 | 17 of 23 OK created table model template.customers_proc_yoy.......... [OK in 21.97s]
2018-07-30 15:15:59,270: 15:15:59 | 18 of 23 START table model template.customers_proc................... [RUN]
2018-07-30 15:15:59,271: Compiling model.shopify_cohort_analysis.customers_proc
2018-07-30 15:15:59,280: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 15:15:59,283: Acquiring new bigquery connection "customers_proc".
2018-07-30 15:15:59,283: Re-using an available connection from the pool.
2018-07-30 15:15:59,410: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 15:15:59,412: Fetching data for query customers_proc:
create or replace table `template`.`customers_proc`
  
  as (
    SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_qoq`

UNION ALL

SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_yoy`
  );

    
2018-07-30 15:16:25,882: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a621d0>]}
2018-07-30 15:16:27,228: 15:16:27 | 18 of 23 OK created table model template.customers_proc.............. [OK in 26.61s]
2018-07-30 15:16:27,230: 15:16:27 | 19 of 23 START table model template.segment_proc_buyers.............. [RUN]
2018-07-30 15:16:27,231: Compiling model.shopify_cohort_analysis.segment_proc_buyers
2018-07-30 15:16:27,253: Writing injected SQL for node "model.shopify_cohort_analysis.segment_proc_buyers"
2018-07-30 15:16:27,259: Acquiring new bigquery connection "segment_proc_buyers".
2018-07-30 15:16:27,259: Re-using an available connection from the pool.
2018-07-30 15:16:27,408: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_proc_buyers"
2018-07-30 15:16:27,410: Fetching data for query segment_proc_buyers:
create or replace table `template`.`segment_proc_buyers`
  
  as (
    SELECT
store,
period,
customer_id,
date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct,
case when first_order_unix_date >= window_start_unix_date then 'New'
	else 'Existing' end as newness_segment,
case when revenue >= revenue_90pct then 'Top 10%'
	when revenue <= revenue_10pct then 'Bottom 10%'
	else 'Middle 80%' end as revenue_segment,
case when frequency = 1 then '1'
	when frequency = 2 then '2'
	when frequency > 2 then '3+'
	else null end as frequency_segment
FROM `growth-engines-pipeline`.`template`.`customers_proc`
  );

    
2018-07-30 15:16:53,775: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a6aa58>]}
2018-07-30 15:16:55,067: 15:16:55 | 19 of 23 OK created table model template.segment_proc_buyers......... [OK in 26.54s]
2018-07-30 15:16:55,067: 15:16:55 | 20 of 23 START table model template.segment_stats_buyers_agg......... [RUN]
2018-07-30 15:16:55,068: Compiling model.shopify_cohort_analysis.segment_stats_buyers_agg
2018-07-30 15:16:55,087: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_agg"
2018-07-30 15:16:55,089: Acquiring new bigquery connection "segment_stats_buyers_agg".
2018-07-30 15:16:55,089: Re-using an available connection from the pool.
2018-07-30 15:16:55,481: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_agg"
2018-07-30 15:16:55,481: Fetching data for query segment_stats_buyers_agg:
create or replace table `template`.`segment_stats_buyers_agg`
  
  as (
    WITH ty as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev,
	0 as retention_eligible,
	case when newness_segment = 'Existing' then 1 else 0 end as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Year'

),

this_month_1yr as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment,
	frequency_segment,
	newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	recency_days as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev,
	1 as retention_eligible,
	0 as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Previous Year'

),

this_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,	
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment,
	frequency_segment,
	newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev,
	0 as retention_eligible,
	case when newness_segment = 'Existing' then 1 else 0 end as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Quarter'

),

last_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	recency_days as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev,
	1 as retention_eligible,
	0 as retention_success
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Previous Quarter'

)

SELECT
store,
period,
date, 
customer_id,
case when sum(revenue) > 0 then 1 else 0 end as buyers,
first_order_channel,
first_order_platform,	
revenue_segment,
frequency_segment,
newness_segment,	
ifnull(sum(recency), 0) recency,
ifnull(sum(frequency), 0) frequency,
ifnull(sum(revenue), 0) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else 0 end as aov,
ifnull(sum(recency_prev), 0) recency_prev,
ifnull(sum(frequency_prev), 0) frequency_prev,
ifnull(sum(revenue_prev), 0) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else 0 end as aov_prev,
sum(retention_eligible) retention_eligible,
sum(retention_success) retention_success
FROM
(
	SELECT * FROM ty
	UNION ALL
	SELECT * FROM this_month_1yr
	UNION ALL
	SELECT * FROM this_quarter
	UNION ALL
	SELECT * FROM last_quarter

)
GROUP BY store, period, date, customer_id, first_order_channel, first_order_platform,
revenue_segment, frequency_segment, newness_segment
  );

    
2018-07-30 15:17:37,049: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a29898>]}
2018-07-30 15:17:37,467: 15:17:37 | 20 of 23 OK created table model template.segment_stats_buyers_agg.... [OK in 41.98s]
2018-07-30 15:17:37,469: 15:17:37 | 21 of 23 START table model template.segment_stats_buyers_view........ [RUN]
2018-07-30 15:17:37,469: Compiling model.shopify_cohort_analysis.segment_stats_buyers_view
2018-07-30 15:17:37,500: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_view"
2018-07-30 15:17:37,505: Acquiring new bigquery connection "segment_stats_buyers_view".
2018-07-30 15:17:37,506: Re-using an available connection from the pool.
2018-07-30 15:17:37,664: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_view"
2018-07-30 15:17:37,665: Fetching data for query segment_stats_buyers_view:
create or replace table `template`.`segment_stats_buyers_view`
  
  as (
    SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Total' as segment_type,
'Total' as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Total' as segment_type,
'Total' as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Total' as segment_type,
'Total' as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type
  );

    
2018-07-30 15:17:41,733: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a6a6a0>]}
2018-07-30 15:17:42,375: 15:17:42 | 21 of 23 OK created table model template.segment_stats_buyers_view... [OK in 4.26s]
2018-07-30 15:17:42,376: 15:17:42 | 22 of 23 START table model template.buyer_segment_stats.............. [RUN]
2018-07-30 15:17:42,376: Compiling model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 15:17:42,383: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 15:17:42,385: Acquiring new bigquery connection "buyer_segment_stats".
2018-07-30 15:17:42,385: Re-using an available connection from the pool.
2018-07-30 15:17:42,513: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 15:17:42,514: Fetching data for query buyer_segment_stats:
create or replace table `template`.`buyer_segment_stats`
  
  as (
    SELECT
store,
period,
date,
view,
view_segment,
segment_type,
segment,
buyers,
total_view_buyers,
case when ( total_segment_buyers / total_buyers ) > 0 
	then ( buyers / total_view_buyers ) / ( total_segment_buyers / total_buyers ) 
	else null end as segment_buyer_index,
recency,
frequency,
revenue,
total_view_revenue,
case when ( total_segment_revenue / total_revenue ) > 0 
	then ( revenue / total_view_revenue ) / ( total_segment_revenue / total_revenue ) 
	else null end as segment_revenue_index,
aov,
recency_growth,
frequency_growth,
revenue_growth,
aov_growth,
retention_rate
FROM (

	SELECT
	store,
	period,
	date,
	view,
	view_segment,
	segment_type,
	segment,
	buyers,
	sum(buyers) over w1 as total_view_buyers,
	sum(buyers) over w2 as total_segment_buyers,
	sum(buyers) over w3 as total_buyers,
	recency,
	frequency,
	revenue,
	sum(revenue) over w1 as total_view_revenue,
	sum(revenue) over w2 as total_segment_revenue,
	sum(revenue) over w3 as total_revenue,
	aov,
	case when recency_prev > 0 then ( recency_prev - recency ) / recency_prev else null end as recency_growth,
	case when frequency_prev > 0 then ( frequency - frequency_prev ) / frequency_prev else null end as frequency_growth,
	case when revenue_prev > 0 then ( revenue - revenue_prev ) / revenue_prev else null end as revenue_growth,
	case when aov_prev > 0 then ( aov - aov_prev ) / aov_prev else null end as aov_growth,
	retention_rate
	FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_view`
	WINDOW w1 as (PARTITION BY store, period, date, segment_type, view, view_segment),
	w2 as (PARTITION BY store, period, date, segment_type, view, segment),
	w3 as (PARTITION BY store, period, date, segment_type, view)
)
  );

    
2018-07-30 15:17:44,344: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a6a320>]}
2018-07-30 15:17:44,637: 15:17:44 | 22 of 23 OK created table model template.buyer_segment_stats......... [OK in 1.97s]
2018-07-30 15:17:44,637: 15:17:44 | 23 of 23 START table model template.buyer_segment_lists.............. [RUN]
2018-07-30 15:17:44,637: Compiling model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 15:17:44,645: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 15:17:44,647: Acquiring new bigquery connection "buyer_segment_lists".
2018-07-30 15:17:44,647: Re-using an available connection from the pool.
2018-07-30 15:17:44,762: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 15:17:44,762: Fetching data for query buyer_segment_lists:
create or replace table `template`.`buyer_segment_lists`
  
  as (
    SELECT
a.store,
period,
date,
customer_id,
b.first_name,
b.last_name,
b.email,
recency,
frequency,
revenue,
aov,
revenue_segment,
frequency_segment
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg` a
LEFT JOIN `growth-engines-pipeline`.`template`.`agg_customers` b
ON (
	a.store = b.store AND
	a.customer_id = b.id
)
where ( revenue_segment != '' or frequency_segment != '' )
  );

    
2018-07-30 15:18:23,270: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c210d2f-527f-433f-a069-1c6a1c4f2dee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a3e8d0>]}
2018-07-30 15:18:24,055: 15:18:24 | 23 of 23 OK created table model template.buyer_segment_lists......... [OK in 38.63s]
2018-07-30 15:18:24,162: 15:18:24 | 
2018-07-30 15:18:24,163: 15:18:24 | Finished running 23 table models in 240.18s.
2018-07-30 15:18:24,163: Connection 'master' was left open.
2018-07-30 15:18:24,163: 
2018-07-30 15:18:24,164: Completed successfully
2018-07-30 15:18:24,164: 
Done. PASS=23 ERROR=0 SKIP=0 TOTAL=23
2018-07-30 15:18:24,165: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1135235c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113523a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113523390>]}
2018-07-30 15:18:24,529: Flushing usage events
2018-07-30 15:18:24,716: sys:1: ResourceWarning: unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 56926), raddr=('172.217.12.10', 443)>

2018-07-30 15:18:24,717: sys:1: ResourceWarning: unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 56925), raddr=('172.217.2.13', 443)>

2018-07-30 15:18:24,717: sys:1: ResourceWarning: unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 56927), raddr=('172.217.2.13', 443)>

2018-07-30 15:18:24,717: sys:1: ResourceWarning: unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 56932), raddr=('172.217.12.10', 443)>

2018-07-30 15:18:24,718: sys:1: ResourceWarning: unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 56934), raddr=('172.217.12.10', 443)>

2018-07-30 15:18:24,718: sys:1: ResourceWarning: unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 56931), raddr=('172.217.12.10', 443)>

2018-07-30 15:18:24,718: sys:1: ResourceWarning: unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 56933), raddr=('172.217.12.10', 443)>

2018-07-30 15:18:24,719: sys:1: ResourceWarning: unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 56928), raddr=('172.217.2.13', 443)>

2018-07-30 15:18:24,719: sys:1: ResourceWarning: unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 56929), raddr=('172.217.2.13', 443)>

2018-07-30 15:18:24,720: sys:1: ResourceWarning: unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 56930), raddr=('172.217.2.13', 443)>

2018-07-30 15:35:17,310: Tracking: tracking
2018-07-30 15:35:17,311: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ef2e208>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ef2e978>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ef2ed30>]}
2018-07-30 15:35:19,219: Loading dependency project from /usr/local/Cellar/dbt/0.10.1/libexec/lib/python3.6/site-packages/dbt/include
2018-07-30 15:35:19,251: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/shopify-cohort-analysis/dbt_modules
2018-07-30 15:35:19,258: Parsing get_column_values.sql
2018-07-30 15:35:19,277: Parsing get_url_parameter.sql
2018-07-30 15:35:19,284: Parsing split_part.sql
2018-07-30 15:35:19,296: Parsing table_exists.sql
2018-07-30 15:35:19,315: Parsing core.sql
2018-07-30 15:35:19,342: Parsing adapters/bigquery.sql
2018-07-30 15:35:19,357: Parsing adapters/common.sql
2018-07-30 15:35:19,387: Parsing adapters/redshift.sql
2018-07-30 15:35:19,409: Parsing adapters/snowflake.sql
2018-07-30 15:35:19,415: Parsing etc/bigquery.sql
2018-07-30 15:35:19,421: Parsing etc/datetime.sql
2018-07-30 15:35:19,450: Parsing etc/get_custom_schema.sql
2018-07-30 15:35:19,460: Parsing materializations/helpers.sql
2018-07-30 15:35:19,481: Parsing materializations/archive/archive.sql
2018-07-30 15:35:19,521: Parsing materializations/incremental/incremental.sql
2018-07-30 15:35:19,563: Parsing materializations/seed/bigquery.sql
2018-07-30 15:35:19,572: Parsing materializations/seed/seed.sql
2018-07-30 15:35:19,630: Parsing materializations/table/bigquery_table.sql
2018-07-30 15:35:19,666: Parsing materializations/table/table.sql
2018-07-30 15:35:19,693: Parsing materializations/view/bigquery_view.sql
2018-07-30 15:35:19,709: Parsing materializations/view/view.sql
2018-07-30 15:35:19,738: Parsing schema_tests/accepted_values.sql
2018-07-30 15:35:19,747: Parsing schema_tests/not_null.sql
2018-07-30 15:35:19,752: Parsing schema_tests/relationships.sql
2018-07-30 15:35:19,758: Parsing schema_tests/unique.sql
2018-07-30 15:35:19,785: Parsing model.shopify_cohort_analysis.all_dates
2018-07-30 15:35:19,788: Parsing model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 15:35:19,790: Parsing model.shopify_cohort_analysis.monthend_dates
2018-07-30 15:35:19,792: Parsing model.shopify_cohort_analysis.stores_proc
2018-07-30 15:35:19,794: Parsing model.shopify_cohort_analysis.ga_transactions
2018-07-30 15:35:19,804: Parsing model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 15:35:19,817: Parsing model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 15:35:19,824: Parsing model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 15:35:19,834: Parsing model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 15:35:19,843: Parsing model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 15:35:19,850: Parsing model.shopify_cohort_analysis.agg_customers
2018-07-30 15:35:19,852: Parsing model.shopify_cohort_analysis.agg_transactions
2018-07-30 15:35:19,856: Parsing model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 15:35:19,859: Parsing model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 15:35:19,863: Parsing model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 15:35:19,867: Parsing model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 15:35:19,871: Parsing model.shopify_cohort_analysis.customers_proc
2018-07-30 15:35:19,879: Parsing model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 15:35:19,887: Parsing model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 15:35:19,901: Parsing model.shopify_cohort_analysis.segment_proc_buyers
2018-07-30 15:35:19,906: Parsing model.shopify_cohort_analysis.segment_stats_buyers_agg
2018-07-30 15:35:19,912: Parsing model.shopify_cohort_analysis.segment_stats_buyers_view
2018-07-30 15:35:19,928: Parsing model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 15:35:19,948: Found 23 models, 0 tests, 0 archives, 0 analyses, 62 macros, 0 operations, 0 seed files
2018-07-30 15:35:19,956: 
2018-07-30 15:35:19,963: Acquiring new bigquery connection "master".
2018-07-30 15:35:19,963: Opening a new connection (0 currently allocated)
2018-07-30 15:35:21,380: 15:35:21 | Concurrency: 4 threads (target='template')
2018-07-30 15:35:21,381: 15:35:21 | 
2018-07-30 15:35:21,466: 15:35:21 | 1 of 23 START table model template.mappings_ga_proc.................. [RUN]
2018-07-30 15:35:21,466: Compiling model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 15:35:21,474: Writing injected SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 15:35:21,472: 15:35:21 | 2 of 23 START table model template.stores_proc....................... [RUN]
2018-07-30 15:35:21,472: 15:35:21 | 3 of 23 START table model template.monthend_dates.................... [RUN]
2018-07-30 15:35:21,475: Compiling model.shopify_cohort_analysis.stores_proc
2018-07-30 15:35:21,473: 15:35:21 | 4 of 23 START table model template.all_dates......................... [RUN]
2018-07-30 15:35:21,475: Compiling model.shopify_cohort_analysis.monthend_dates
2018-07-30 15:35:21,480: Writing injected SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 15:35:21,480: Compiling model.shopify_cohort_analysis.all_dates
2018-07-30 15:35:21,503: Writing injected SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 15:35:21,506: Acquiring new bigquery connection "all_dates".
2018-07-30 15:35:21,506: Opening a new connection (1 currently allocated)
2018-07-30 15:35:21,522: Writing injected SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 15:35:21,525: Acquiring new bigquery connection "stores_proc".
2018-07-30 15:35:21,525: Opening a new connection (2 currently allocated)
2018-07-30 15:35:21,530: Acquiring new bigquery connection "mappings_ga_proc".
2018-07-30 15:35:21,532: Acquiring new bigquery connection "monthend_dates".
2018-07-30 15:35:21,535: Opening a new connection (3 currently allocated)
2018-07-30 15:35:21,541: Opening a new connection (4 currently allocated)
2018-07-30 15:35:21,988: Writing runtime SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 15:35:22,000: Writing runtime SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 15:35:22,007: Fetching data for query mappings_ga_proc:
create or replace table `template`.`mappings_ga_proc`
  
  as (
    select 
store,
account,
store_name,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client store,
account,
client_name store_name,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.mappings_ga` 

) 

WHERE lv = time_of_entry
group by store, account, store_name, source, medium, platform_n, channel_n, time_of_entry
  );

    
2018-07-30 15:35:22,017: Writing runtime SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 15:35:22,024: Fetching data for query stores_proc:
create or replace table `template`.`stores_proc`
  
  as (
    select 
store,
store_name,
account,
platform,
max(time_of_entry) time_of_entry

from  ( 

SELECT  
client store,
client_name store_name,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.accounts` 
where client_name != ''

) 

WHERE lv = time_of_entry
group by store, store_name, account, platform
  );

    
2018-07-30 15:35:22,043: Writing runtime SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 15:35:22,046: Fetching data for query monthend_dates:
create or replace table `template`.`monthend_dates`
  
  as (
    SELECT
date_in_range,
date_in_range_bom,
date_in_range_bom_mom,
unix_date_in_range,
unix_date_in_range_bom,
unix_date(date_in_range_bom_mom) unix_date_in_range_bom_mom,
yyyymm,
date_in_range_yoy,
unix_date(date_in_range_yoy) unix_date_in_range_yoy

FROM
(
	SELECT 
	date_in_range,
	date_in_range_bom,
	date_sub(date_in_range_bom, INTERVAL 1 MONTH) date_in_range_bom_mom,
	date_sub(date_in_range, INTERVAL 1 YEAR) date_in_range_yoy,
	unix_date_in_range,
	unix_date(date_in_range_bom) unix_date_in_range_bom,
	yyyymm,
	first_value(date_in_range) over (partition by yyyymm order by date_in_range desc) monthend_date_in_range
	FROM
	( 
		SELECT 
		date_in_range,
		date_trunc( date_in_range, MONTH) date_in_range_bom,
		unix_date(date_in_range) unix_date_in_range,
		format_date("%Y-%m", date_in_range) AS yyyymm
		FROM UNNEST(
		    GENERATE_DATE_ARRAY(DATE('2016-01-31'), CURRENT_DATE(), INTERVAL 1 DAY)
		) AS date_in_range
	)
)
where date_in_range = monthend_date_in_range
  );

    
2018-07-30 15:35:22,046: Fetching data for query all_dates:
create or replace table `template`.`all_dates`
  
  as (
    SELECT 
date_in_range,
unix_date(date_in_range) unix_date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
  );

    
2018-07-30 15:35:23,835: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f032d30>]}
2018-07-30 15:35:23,889: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f0e1eb8>]}
2018-07-30 15:35:24,172: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc7c940>]}
2018-07-30 15:35:24,282: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f0c3e48>]}
2018-07-30 15:35:24,331: 15:35:24 | 4 of 23 OK created table model template.all_dates.................... [OK in 2.35s]
2018-07-30 15:35:27,305: 15:35:27 | 3 of 23 OK created table model template.monthend_dates............... [OK in 2.41s]
2018-07-30 15:35:28,089: 15:35:28 | 2 of 23 OK created table model template.stores_proc.................. [OK in 2.70s]
2018-07-30 15:35:28,876: 15:35:28 | 1 of 23 OK created table model template.mappings_ga_proc............. [OK in 2.82s]
2018-07-30 15:35:28,877: 15:35:28 | 5 of 23 START table model template.shopify_customers_proc............ [RUN]
2018-07-30 15:35:28,877: Compiling model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 15:35:28,877: 15:35:28 | 6 of 23 START table model template.shopify_discounts_proc............ [RUN]
2018-07-30 15:35:28,879: Compiling model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 15:35:28,888: Acquiring new bigquery connection "shopify_discounts_proc".
2018-07-30 15:35:28,877: 15:35:28 | 7 of 23 START table model template.shopify_refunds_proc.............. [RUN]
2018-07-30 15:35:28,888: Re-using an available connection from the pool.
2018-07-30 15:35:28,896: Acquiring new bigquery connection "shopify_customers_proc".
2018-07-30 15:35:28,897: Compiling model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 15:35:28,897: Fetching data for query shopify_discounts_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:35:28,897: Re-using an available connection from the pool.
2018-07-30 15:35:28,905: Acquiring new bigquery connection "shopify_refunds_proc".
2018-07-30 15:35:28,905: Fetching data for query shopify_customers_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:35:28,905: Re-using an available connection from the pool.
2018-07-30 15:35:28,909: Fetching data for query shopify_refunds_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:35:30,611: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 15:35:30,613: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 15:35:30,787: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 15:35:30,788: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 15:35:30,789: Fetching data for query shopify_customers_proc:
create or replace table `template`.`shopify_customers_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`





with customers as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	created_at,
	id,
	first_name,
	last_name,
	email,
	_sdc_sequence,
	first_value(_sdc_sequence) over (partition by id order by _sdc_sequence desc) lv
	FROM `growth-engines-pipeline.shopify_lucadanni.customers` 
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
id,
first_name,
last_name,
email
FROM customers a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence


  );

    
2018-07-30 15:35:30,795: Fetching data for query shopify_refunds_proc:
create or replace table `template`.`shopify_refunds_proc`
  
  as (
    



with refunds as (

	
	SELECT
	'lucadanni' store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal,
	line_item.variant_id variant_id,
	line_item.id refund_id,
 	_sdc_sequence
	FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
	cross join unnest(refunds), unnest(refund_line_items)
  	where financial_status like '%refund%'
	
	

)

SELECT * 
FROM 
	(
    SELECT
    store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal refund_amount,
	variant_id,
	refund_id,
 	_sdc_sequence,
    first_value(_sdc_sequence) OVER (PARTITION BY order_number, line_item_id ORDER BY _sdc_sequence DESC) lv
    FROM refunds
   	) 
WHERE lv = _sdc_sequence


  );

    
2018-07-30 15:35:30,929: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 15:35:31,253: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 15:35:31,253: Fetching data for query shopify_discounts_proc:
create or replace table `template`.`shopify_discounts_proc`
  
  as (
    



with orders as (

	
		SELECT
		'lucadanni' store_name,
		created_at,
		order_number,
		code discount_code,
		type discount_type,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(discount_codes)
		where source_name != 'shopify_draft_order'
	
	
	

)

SELECT
store_name,
order_number,
discount_code,
discount_type
FROM orders
where lv = _sdc_sequence


  );

    
2018-07-30 15:35:33,299: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eff90f0>]}
2018-07-30 15:35:33,515: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc9a9e8>]}
2018-07-30 15:35:33,618: 15:35:33 | 7 of 23 OK created table model template.shopify_refunds_proc......... [OK in 4.40s]
2018-07-30 15:35:34,334: 15:35:34 | 6 of 23 OK created table model template.shopify_discounts_proc....... [OK in 4.64s]
2018-07-30 15:35:35,861: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f06f080>]}
2018-07-30 15:35:36,390: 15:35:36 | 5 of 23 OK created table model template.shopify_customers_proc....... [OK in 6.98s]
2018-07-30 15:35:36,391: 15:35:36 | 8 of 23 START table model template.shopify_products_proc............. [RUN]
2018-07-30 15:35:36,392: Compiling model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 15:35:36,391: 15:35:36 | 9 of 23 START table model template.ga_transactions................... [RUN]
2018-07-30 15:35:36,391: 15:35:36 | 10 of 23 START table model template.agg_customers.................... [RUN]
2018-07-30 15:35:36,404: Compiling model.shopify_cohort_analysis.ga_transactions
2018-07-30 15:35:36,405: Compiling model.shopify_cohort_analysis.agg_customers
2018-07-30 15:35:36,435: Writing injected SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 15:35:36,440: Acquiring new bigquery connection "shopify_products_proc".
2018-07-30 15:35:36,440: Re-using an available connection from the pool.
2018-07-30 15:35:36,441: Acquiring new bigquery connection "ga_transactions".
2018-07-30 15:35:36,441: Fetching data for query shopify_products_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:35:36,443: Acquiring new bigquery connection "agg_customers".
2018-07-30 15:35:36,443: Re-using an available connection from the pool.
2018-07-30 15:35:36,444: Fetching data for query ga_transactions:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Google Analytics'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:35:36,444: Re-using an available connection from the pool.
2018-07-30 15:35:36,752: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 15:35:36,760: Fetching data for query agg_customers:
create or replace table `template`.`agg_customers`
  
  as (
    SELECT 
account,
store,
id,
created_at,
first_name,
last_name,
email,
split(email,'@')[SAFE_ORDINAL(2)] email_domain
FROM
`growth-engines-pipeline`.`template`.`shopify_customers_proc`
  );

    
2018-07-30 15:35:37,523: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 15:35:37,764: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 15:35:37,765: Fetching data for query shopify_products_proc:
create or replace table `template`.`shopify_products_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`





with products as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	product_name,
	lower(product_type) product_type,
	product_id,
	sku,
	id variant_id,
	cast(created_at as date) created_at,
	_sdc_sequence,
	first_value(_sdc_sequence) OVER (PARTITION BY product_id ORDER BY _sdc_sequence DESC) lv
	FROM (
		SELECT
		variants,
		product_type,
		title product_name,
		_sdc_sequence
		FROM `growth-engines-pipeline.shopify_lucadanni.products` 
		)
	cross join unnest(variants)
	
	

)

SELECT
b.account,
b.store,
b.platform,
max(product_type) product_type,
product_id,
variant_id,
sku,
created_at,
product_name
FROM products a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence
group by product_id, account, store, platform, sku, variant_id, created_at, product_name


  );

    
2018-07-30 15:35:38,144: Writing injected SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 15:35:38,337: Writing runtime SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 15:35:38,338: Fetching data for query ga_transactions:
create or replace table `template`.`ga_transactions`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`,`growth-engines-pipeline`.`template`.`mappings_ga_proc`




with ga_report as (

	    
	    	
		   	SELECT
		   	'yandy' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_yandy.report` 

		     UNION ALL 
	   
	    	
		   	SELECT
		   	'lucadanni' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_lucadanni.report` 

		    
	   

)


SELECT  
date,
b.store store,
c.source source,
c.medium medium,
a.campaign campaign,
concat(a.source, ' / ', a.medium) source_medium,  
case when c.platform is null then "Unmapped" else c.platform end as platform,
case when c.channel is null then "Unmapped" else c.channel end as channel,
url,
transactionid
FROM (

	SELECT 
	store_name,
	lookup_platform,
	date,
	transactionid,
	max(url) url,
	max(source) source,
	max(medium) medium,
	max(campaign) campaign
	FROM ga_report
	where lv = _sdc_sequence
	group by store_name, lookup_platform, date, transactionid

) a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name 
	AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`mappings_ga_proc` c
ON ( a.source = c.source
  AND a.medium = c.medium 
  AND a.store_name = c.store_name )


  );

    
2018-07-30 15:35:40,090: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f0c3e48>]}
2018-07-30 15:35:40,787: 15:35:40 | 8 of 23 OK created table model template.shopify_products_proc........ [OK in 3.70s]
2018-07-30 15:35:41,680: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc9a8d0>]}
2018-07-30 15:35:42,126: 15:35:42 | 10 of 23 OK created table model template.agg_customers............... [OK in 5.28s]
2018-07-30 15:36:03,132: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f0b7160>]}
2018-07-30 15:36:03,461: 15:36:03 | 9 of 23 OK created table model template.ga_transactions.............. [OK in 26.73s]
2018-07-30 15:36:03,463: 15:36:03 | 11 of 23 START table model template.shopify_orders_proc.............. [RUN]
2018-07-30 15:36:03,463: Compiling model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 15:36:03,488: Acquiring new bigquery connection "shopify_orders_proc".
2018-07-30 15:36:03,488: Re-using an available connection from the pool.
2018-07-30 15:36:03,488: Fetching data for query shopify_orders_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:36:04,499: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 15:36:04,708: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 15:36:04,709: Fetching data for query shopify_orders_proc:
create or replace table `template`.`shopify_orders_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`, `growth-engines-pipeline`.`template`.`shopify_discounts_proc`





with orders as (

	
	SELECT 
	store_name,
	lookup_platform,
	created_at,
	order_number,
	quantity,
	price, 
	total_order_price_undiscounted,
	total_discounts,
	total_order_shipping_price,
	total_order_price_incl_shipping,
	checkout_id,
	product_id, 
	landing_site,
	sku, 
	variant_title, 
	variant_id,
	line_item_id,
	customer_id,
	_sdc_sequence,
	lv
	FROM (

		SELECT
		'lucadanni' store_name,
		'Shopify' as lookup_platform,
		created_at,
		order_number,
		quantity,
		cast(pre_tax_price as float64) price, 
		total_line_items_price total_order_price_undiscounted,
		total_discounts,
		cast(discounted_price as float64) total_order_shipping_price,
		total_price_usd total_order_price_incl_shipping,
		checkout_id,
		product_id, 
		landing_site,
		sku, 
		variant_title, 
		variant_id,
		_id line_item_id,
		customer.id customer_id,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(line_items), unnest(shipping_lines)
		where source_name != 'shopify_draft_order'
	)
	
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
a.order_number,
a.quantity prelim_quantity,
c.quantity refund_quantity,
case when c.quantity is not null then a.quantity - c.quantity else a.quantity end as quantity,
price prelim_revenue, 
total_order_price_undiscounted,
total_discounts,
trim(lower(d.discount_code)) discount_code,
d.discount_type,
total_order_shipping_price,
total_order_price_incl_shipping,
refund_amount,
case when refund_amount is not null then price - refund_amount else price end as revenue,
a.checkout_id,
a.product_id, 
landing_site,
sku, 
variant_title, 
a.variant_id,
a.line_item_id,	
customer_id
FROM orders a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_refunds_proc` c
ON ( a.order_number = c.order_number
	AND a.line_item_id = c.line_item_id
	AND a.store_name = c.store_name )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_discounts_proc` d
ON ( a.order_number = d.order_number 
    AND a.store_name = d.store_name )  	
where a.lv = a._sdc_sequence


  );

    
2018-07-30 15:36:13,753: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f06f080>]}
2018-07-30 15:36:14,434: 15:36:14 | 11 of 23 OK created table model template.shopify_orders_proc......... [OK in 10.29s]
2018-07-30 15:36:14,435: 15:36:14 | 12 of 23 START table model template.transaction_by_order_number...... [RUN]
2018-07-30 15:36:14,436: Compiling model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 15:36:14,449: Writing injected SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 15:36:14,452: Acquiring new bigquery connection "transaction_by_order_number".
2018-07-30 15:36:14,452: Re-using an available connection from the pool.
2018-07-30 15:36:14,635: Writing runtime SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 15:36:14,635: Fetching data for query transaction_by_order_number:
create or replace table `template`.`transaction_by_order_number`
  
  as (
    SELECT
store,
cast(created_at as date) order_date,
order_number,
customer_id,
sum(quantity) quantity,
sum(revenue) revenue,
max(total_order_shipping_price) shipping_price
FROM
`growth-engines-pipeline`.`template`.`shopify_orders_proc`
GROUP BY store, order_date, order_number, customer_id
  );

    
2018-07-30 15:36:19,038: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd21fd0>]}
2018-07-30 15:36:19,896: 15:36:19 | 12 of 23 OK created table model template.transaction_by_order_number. [OK in 4.60s]
2018-07-30 15:36:19,900: 15:36:19 | 13 of 23 START table model template.customers_by_transaction......... [RUN]
2018-07-30 15:36:19,900: Compiling model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 15:36:19,911: Writing injected SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 15:36:19,913: Acquiring new bigquery connection "customers_by_transaction".
2018-07-30 15:36:19,913: Re-using an available connection from the pool.
2018-07-30 15:36:20,068: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 15:36:20,069: Fetching data for query customers_by_transaction:
create or replace table `template`.`customers_by_transaction`
  
  as (
    SELECT
store,
customer_id,
order_number,
order_date,
recent_order_date,
first_order_date,
case when first_order_number = order_number then 'New'
	when date_diff(order_date, recent_order_date, DAY) <= 365 then 'Repeat'
	when date_diff(order_date, recent_order_date, DAY) > 365 then 'Reactivated'
 else '' end as order_type,
quantity,
revenue,
1 as orders,
first_order_revenue,
lifetime_revenue
FROM

(

	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	quantity,
	revenue,
	lag(order_date) over w1 recent_order_date,
	first_value(order_date) over w1 first_order_date,
	first_value(order_number) over w1 first_order_number,
	first_value(revenue) over w1 first_order_revenue,
	sum(revenue) over w2 lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`transaction_by_order_number`
	WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc),
	w2 as (PARTITION BY store, customer_id)
)
  );

    
2018-07-30 15:36:25,189: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f06f080>]}
2018-07-30 15:36:25,977: 15:36:25 | 13 of 23 OK created table model template.customers_by_transaction.... [OK in 5.29s]
2018-07-30 15:36:25,978: 15:36:25 | 14 of 23 START table model template.agg_transactions................. [RUN]
2018-07-30 15:36:25,978: Compiling model.shopify_cohort_analysis.agg_transactions
2018-07-30 15:36:25,988: Writing injected SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 15:36:25,990: Acquiring new bigquery connection "agg_transactions".
2018-07-30 15:36:25,990: Re-using an available connection from the pool.
2018-07-30 15:36:26,170: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 15:36:26,171: Fetching data for query agg_transactions:
create or replace table `template`.`agg_transactions`
  
  as (
    with ga_transaction as (

	SELECT
	date, 
	store,
	transactionid,
	channel,
	platform,
	url,
	campaign
	FROM `growth-engines-pipeline`.`template`.`ga_transactions`
),

customers_by_transaction as (
	
	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	first_order_date,
	recent_order_date,
	order_type,
	quantity,
	revenue,
	orders,
	first_order_revenue,
	lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`customers_by_transaction`
)

SELECT
store,
customer_id,
order_number,
transactionid,
order_date,
first_order_date,
format_date("%Y-%m", first_order_date) AS first_order_month,
order_type,
first_order_revenue,
lifetime_revenue,
first_value(channel) over w1 as first_order_channel,
first_value(platform) over w1 as first_order_platform,
channel,
platform,
url,
campaign,
quantity,
revenue,
orders
FROM (

	SELECT
	a.store,
	a.customer_id,
	a.order_number,
	b.transactionid,
	a.order_date, 
	a.first_order_date, 
	a.order_type,
	a.first_order_revenue,
	a.lifetime_revenue,
	b.channel,
	b.platform,
	b.url,
	b.campaign,
	a.quantity,
	a.revenue,
	a.orders
	FROM customers_by_transaction a
	LEFT JOIN ga_transaction b
	ON (
	    a.store = b.store AND
	    a.order_number = b.transactionid
	)	
)
WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc)
  );

    
2018-07-30 15:36:34,816: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bbf7748>]}
2018-07-30 15:36:35,606: 15:36:35 | 14 of 23 OK created table model template.agg_transactions............ [OK in 8.84s]
2018-07-30 15:36:35,607: 15:36:35 | 15 of 23 START table model template.monthly_cohort_stats............. [RUN]
2018-07-30 15:36:35,608: Compiling model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 15:36:35,614: 15:36:35 | 16 of 23 START table model template.customers_proc_yoy............... [RUN]
2018-07-30 15:36:35,618: Compiling model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 15:36:35,618: 15:36:35 | 17 of 23 START table model template.customers_proc_qoq............... [RUN]
2018-07-30 15:36:35,618: Writing injected SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 15:36:35,625: Compiling model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 15:36:35,626: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 15:36:35,633: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 15:36:35,637: Acquiring new bigquery connection "monthly_cohort_stats".
2018-07-30 15:36:35,637: Re-using an available connection from the pool.
2018-07-30 15:36:35,639: Acquiring new bigquery connection "customers_proc_yoy".
2018-07-30 15:36:35,640: Re-using an available connection from the pool.
2018-07-30 15:36:35,642: Acquiring new bigquery connection "customers_proc_qoq".
2018-07-30 15:36:35,642: Re-using an available connection from the pool.
2018-07-30 15:36:35,917: Writing runtime SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 15:36:35,950: Fetching data for query monthly_cohort_stats:
create or replace table `template`.`monthly_cohort_stats`
  
  as (
    WITH transactions AS (

  SELECT 
  store, 
  order_number,
  order_date,
  order_type,
  first_order_month,
  unix_date(order_date) d, 
  customer_id, 
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (

  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT 
date_in_range date,
store, 
order_type,
first_order_channel,
first_order_platform,
first_order_month,
channel,
platform,
url,
campaign,
count(distinct(customer_id)) buyers,
sum(orders) orders,
sum(quantity) quantity,
sum(revenue) revenue
FROM daterange
JOIN transactions
ON transactions.d >= daterange.unix_date_in_range_bom 
AND transactions.d <= daterange.unix_date_in_range
GROUP BY date, store, order_type, 
first_order_channel, first_order_platform, first_order_month, channel, platform, url, campaign
  );

    
2018-07-30 15:36:35,965: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 15:36:35,979: Fetching data for query customers_proc_yoy:
create or replace table `template`.`customers_proc_yoy`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 365 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 365 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 365 window_end_unix_date, 
    unix_date_in_range - 730 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 730 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 365 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 15:36:35,991: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 15:36:35,993: Fetching data for query customers_proc_qoq:
create or replace table `template`.`customers_proc_qoq`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 90 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 90 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 90 window_end_unix_date, 
    unix_date_in_range - 180 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 180 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 90 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 15:36:41,519: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f06f080>]}
2018-07-30 15:36:41,806: 15:36:41 | 15 of 23 OK created table model template.monthly_cohort_stats........ [OK in 5.91s]
2018-07-30 15:36:49,524: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bcb2470>]}
2018-07-30 15:36:49,825: 15:36:49 | 17 of 23 OK created table model template.customers_proc_qoq.......... [OK in 13.90s]
2018-07-30 15:37:00,370: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bcb2240>]}
2018-07-30 15:37:01,013: 15:37:01 | 16 of 23 OK created table model template.customers_proc_yoy.......... [OK in 24.75s]
2018-07-30 15:37:01,014: 15:37:01 | 18 of 23 START table model template.customers_proc................... [RUN]
2018-07-30 15:37:01,014: Compiling model.shopify_cohort_analysis.customers_proc
2018-07-30 15:37:01,026: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 15:37:01,031: Acquiring new bigquery connection "customers_proc".
2018-07-30 15:37:01,031: Re-using an available connection from the pool.
2018-07-30 15:37:01,393: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 15:37:01,393: Fetching data for query customers_proc:
create or replace table `template`.`customers_proc`
  
  as (
    SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_qoq`

UNION ALL

SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_yoy`
  );

    
2018-07-30 15:37:27,860: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bbf7748>]}
2018-07-30 15:37:29,205: 15:37:29 | 18 of 23 OK created table model template.customers_proc.............. [OK in 26.85s]
2018-07-30 15:37:29,208: 15:37:29 | 19 of 23 START table model template.segment_proc_buyers.............. [RUN]
2018-07-30 15:37:29,208: Compiling model.shopify_cohort_analysis.segment_proc_buyers
2018-07-30 15:37:29,290: Writing injected SQL for node "model.shopify_cohort_analysis.segment_proc_buyers"
2018-07-30 15:37:29,298: Acquiring new bigquery connection "segment_proc_buyers".
2018-07-30 15:37:29,298: Re-using an available connection from the pool.
2018-07-30 15:37:29,684: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_proc_buyers"
2018-07-30 15:37:29,684: Fetching data for query segment_proc_buyers:
create or replace table `template`.`segment_proc_buyers`
  
  as (
    SELECT
store,
period,
customer_id,
date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct,
case when first_order_unix_date >= window_start_unix_date then 'New'
	else 'Existing' end as newness_segment,
case when revenue >= revenue_90pct then 'Top 10%'
	when revenue <= revenue_10pct then 'Bottom 10%'
	else 'Middle 80%' end as revenue_segment,
case when frequency = 1 then '1'
	when frequency = 2 then '2'
	when frequency > 2 then '3+'
	else null end as frequency_segment
FROM `growth-engines-pipeline`.`template`.`customers_proc`
  );

    
2018-07-30 15:37:58,154: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd560f0>]}
2018-07-30 15:37:59,593: 15:37:59 | 19 of 23 OK created table model template.segment_proc_buyers......... [OK in 28.95s]
2018-07-30 15:37:59,599: 15:37:59 | 20 of 23 START table model template.segment_stats_buyers_agg......... [RUN]
2018-07-30 15:37:59,599: Compiling model.shopify_cohort_analysis.segment_stats_buyers_agg
2018-07-30 15:37:59,635: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_agg"
2018-07-30 15:37:59,639: Acquiring new bigquery connection "segment_stats_buyers_agg".
2018-07-30 15:37:59,640: Re-using an available connection from the pool.
2018-07-30 15:37:59,912: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_agg"
2018-07-30 15:37:59,913: Fetching data for query segment_stats_buyers_agg:
create or replace table `template`.`segment_stats_buyers_agg`
  
  as (
    WITH ty as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev,
	0 as retention_eligible,
	case when newness_segment = 'Existing' then 1 else 0 end as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Year'

),

this_month_1yr as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment,
	frequency_segment,
	newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	recency_days as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev,
	1 as retention_eligible,
	0 as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Previous Year'

),

this_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,	
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment,
	frequency_segment,
	newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev,
	0 as retention_eligible,
	case when newness_segment = 'Existing' then 1 else 0 end as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Quarter'

),

last_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	recency_days as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev,
	1 as retention_eligible,
	0 as retention_success
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Previous Quarter'

)

SELECT
store,
period,
date, 
customer_id,
case when sum(revenue) > 0 then 1 else 0 end as buyers,
first_order_channel,
first_order_platform,	
revenue_segment,
frequency_segment,
newness_segment,	
ifnull(sum(recency), 0) recency,
ifnull(sum(frequency), 0) frequency,
ifnull(sum(revenue), 0) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else 0 end as aov,
ifnull(sum(recency_prev), 0) recency_prev,
ifnull(sum(frequency_prev), 0) frequency_prev,
ifnull(sum(revenue_prev), 0) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else 0 end as aov_prev,
sum(retention_eligible) retention_eligible,
sum(retention_success) retention_success
FROM
(
	SELECT * FROM ty
	UNION ALL
	SELECT * FROM this_month_1yr
	UNION ALL
	SELECT * FROM this_quarter
	UNION ALL
	SELECT * FROM last_quarter

)
GROUP BY store, period, date, customer_id, first_order_channel, first_order_platform,
revenue_segment, frequency_segment, newness_segment
  );

    
2018-07-30 15:38:43,057: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bbf7748>]}
2018-07-30 15:38:44,535: 15:38:44 | 20 of 23 OK created table model template.segment_stats_buyers_agg.... [OK in 43.46s]
2018-07-30 15:38:44,572: 15:38:44 | 21 of 23 START table model template.segment_stats_buyers_view........ [RUN]
2018-07-30 15:38:44,573: Compiling model.shopify_cohort_analysis.segment_stats_buyers_view
2018-07-30 15:38:44,668: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_view"
2018-07-30 15:38:44,674: Acquiring new bigquery connection "segment_stats_buyers_view".
2018-07-30 15:38:44,674: Re-using an available connection from the pool.
2018-07-30 15:38:45,177: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_view"
2018-07-30 15:38:45,178: Fetching data for query segment_stats_buyers_view:
create or replace table `template`.`segment_stats_buyers_view`
  
  as (
    SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Total' as segment_type,
'Total' as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Total' as segment_type,
'Total' as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Total' as segment_type,
'Total' as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type
  );

    
2018-07-30 15:38:50,830: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd5ef98>]}
2018-07-30 15:38:51,178: 15:38:51 | 21 of 23 OK created table model template.segment_stats_buyers_view... [OK in 6.26s]
2018-07-30 15:38:51,181: 15:38:51 | 22 of 23 START table model template.buyer_segment_stats.............. [RUN]
2018-07-30 15:38:51,181: Compiling model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 15:38:51,229: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 15:38:51,277: Acquiring new bigquery connection "buyer_segment_stats".
2018-07-30 15:38:51,281: Re-using an available connection from the pool.
2018-07-30 15:38:51,799: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 15:38:51,800: Fetching data for query buyer_segment_stats:
create or replace table `template`.`buyer_segment_stats`
  
  as (
    SELECT
store,
period,
date,
view,
view_segment,
segment_type,
segment,
buyers,
total_view_buyers,
case when ( total_segment_buyers / total_buyers ) > 0 
	then ( buyers / total_view_buyers ) / ( total_segment_buyers / total_buyers ) 
	else null end as segment_buyer_index,
recency,
orders,
case when buyers > 0 then orders / buyers else null end as frequency,
revenue,
revenue_prev,
total_view_revenue,
case when ( total_segment_revenue / total_revenue ) > 0 
	then ( revenue / total_view_revenue ) / ( total_segment_revenue / total_revenue ) 
	else null end as segment_revenue_index,
aov,
recency_growth,
frequency_growth,
revenue_growth,
aov_growth,
retention_rate
FROM (

	SELECT
	store,
	period,
	date,
	view,
	view_segment,
	segment_type,
	segment,
	buyers,
	sum(buyers) over w1 as total_view_buyers,
	sum(buyers) over w2 as total_segment_buyers,
	sum(buyers) over w3 as total_buyers,
	recency,
	frequency orders,
	revenue,
	sum(revenue) over w1 as total_view_revenue,
	sum(revenue) over w2 as total_segment_revenue,
	sum(revenue) over w3 as total_revenue,
	aov,
	case when recency_prev > 0 then ( recency_prev - recency ) / recency_prev else null end as recency_growth,
	case when frequency_prev > 0 then ( frequency - frequency_prev ) / frequency_prev else null end as frequency_growth,
	revenue_prev,
	case when revenue_prev > 0 then ( revenue - revenue_prev ) / revenue_prev else null end as revenue_growth,
	case when aov_prev > 0 then ( aov - aov_prev ) / aov_prev else null end as aov_growth,
	retention_rate
	FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_view`
	WINDOW w1 as (PARTITION BY store, period, date, segment_type, view, view_segment),
	w2 as (PARTITION BY store, period, date, segment_type, view, segment),
	w3 as (PARTITION BY store, period, date, segment_type, view)
)
  );

    
2018-07-30 15:38:55,911: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bbf7748>]}
2018-07-30 15:38:56,537: 15:38:56 | 22 of 23 OK created table model template.buyer_segment_stats......... [OK in 4.73s]
2018-07-30 15:38:56,540: 15:38:56 | 23 of 23 START table model template.buyer_segment_lists.............. [RUN]
2018-07-30 15:38:56,540: Compiling model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 15:38:56,557: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 15:38:56,560: Acquiring new bigquery connection "buyer_segment_lists".
2018-07-30 15:38:56,560: Re-using an available connection from the pool.
2018-07-30 15:38:57,227: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 15:38:57,228: Fetching data for query buyer_segment_lists:
create or replace table `template`.`buyer_segment_lists`
  
  as (
    SELECT
a.store,
period,
date,
customer_id,
b.first_name,
b.last_name,
b.email,
recency,
frequency,
revenue,
aov,
revenue_segment,
frequency_segment
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg` a
LEFT JOIN `growth-engines-pipeline`.`template`.`agg_customers` b
ON (
	a.store = b.store AND
	a.customer_id = b.id
)
where ( revenue_segment != '' or frequency_segment != '' )
  );

    
2018-07-30 15:39:37,298: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2f94144-ba85-426b-abb1-2f727e87caf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bca6e80>]}
2018-07-30 15:39:37,629: 15:39:37 | 23 of 23 OK created table model template.buyer_segment_lists......... [OK in 40.76s]
2018-07-30 15:39:37,725: 15:39:37 | 
2018-07-30 15:39:37,726: 15:39:37 | Finished running 23 table models in 257.76s.
2018-07-30 15:39:37,726: Connection 'master' was left open.
2018-07-30 15:39:37,738: 
2018-07-30 15:39:37,738: Completed successfully
2018-07-30 15:39:37,738: 
Done. PASS=23 ERROR=0 SKIP=0 TOTAL=23
2018-07-30 15:39:37,770: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eff97b8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eff9048>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eff9160>]}
2018-07-30 15:39:38,086: Flushing usage events
2018-07-30 15:39:38,662: sys:1: ResourceWarning: unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57477), raddr=('172.217.12.10', 443)>

2018-07-30 15:39:38,664: sys:1: ResourceWarning: unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57475), raddr=('172.217.1.205', 443)>

2018-07-30 15:39:38,665: sys:1: ResourceWarning: unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57484), raddr=('172.217.11.234', 443)>

2018-07-30 15:39:38,665: sys:1: ResourceWarning: unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57483), raddr=('172.217.11.234', 443)>

2018-07-30 15:39:38,668: sys:1: ResourceWarning: unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57485), raddr=('172.217.11.234', 443)>

2018-07-30 15:39:38,670: sys:1: ResourceWarning: unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57480), raddr=('172.217.1.205', 443)>

2018-07-30 15:39:38,670: sys:1: ResourceWarning: unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57478), raddr=('172.217.1.205', 443)>

2018-07-30 15:39:38,671: sys:1: ResourceWarning: unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57486), raddr=('172.217.11.234', 443)>

2018-07-30 15:39:38,671: sys:1: ResourceWarning: unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57481), raddr=('172.217.1.205', 443)>

2018-07-30 15:39:38,672: sys:1: ResourceWarning: unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57479), raddr=('172.217.1.205', 443)>

2018-07-30 15:47:15,499: Tracking: tracking
2018-07-30 15:47:15,501: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105fb0160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105fb0438>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105fb0e48>]}
2018-07-30 15:47:17,334: Loading dependency project from /usr/local/Cellar/dbt/0.10.1/libexec/lib/python3.6/site-packages/dbt/include
2018-07-30 15:47:17,373: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/shopify-cohort-analysis/dbt_modules
2018-07-30 15:47:17,379: Parsing get_column_values.sql
2018-07-30 15:47:17,399: Parsing get_url_parameter.sql
2018-07-30 15:47:17,406: Parsing split_part.sql
2018-07-30 15:47:17,416: Parsing table_exists.sql
2018-07-30 15:47:17,428: Parsing core.sql
2018-07-30 15:47:17,443: Parsing adapters/bigquery.sql
2018-07-30 15:47:17,453: Parsing adapters/common.sql
2018-07-30 15:47:17,482: Parsing adapters/redshift.sql
2018-07-30 15:47:17,512: Parsing adapters/snowflake.sql
2018-07-30 15:47:17,517: Parsing etc/bigquery.sql
2018-07-30 15:47:17,523: Parsing etc/datetime.sql
2018-07-30 15:47:17,554: Parsing etc/get_custom_schema.sql
2018-07-30 15:47:17,565: Parsing materializations/helpers.sql
2018-07-30 15:47:17,587: Parsing materializations/archive/archive.sql
2018-07-30 15:47:17,633: Parsing materializations/incremental/incremental.sql
2018-07-30 15:47:17,672: Parsing materializations/seed/bigquery.sql
2018-07-30 15:47:17,681: Parsing materializations/seed/seed.sql
2018-07-30 15:47:17,733: Parsing materializations/table/bigquery_table.sql
2018-07-30 15:47:17,772: Parsing materializations/table/table.sql
2018-07-30 15:47:17,805: Parsing materializations/view/bigquery_view.sql
2018-07-30 15:47:17,825: Parsing materializations/view/view.sql
2018-07-30 15:47:17,853: Parsing schema_tests/accepted_values.sql
2018-07-30 15:47:17,861: Parsing schema_tests/not_null.sql
2018-07-30 15:47:17,866: Parsing schema_tests/relationships.sql
2018-07-30 15:47:17,872: Parsing schema_tests/unique.sql
2018-07-30 15:47:17,953: Parsing model.shopify_cohort_analysis.all_dates
2018-07-30 15:47:17,961: Parsing model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 15:47:17,966: Parsing model.shopify_cohort_analysis.monthend_dates
2018-07-30 15:47:17,968: Parsing model.shopify_cohort_analysis.stores_proc
2018-07-30 15:47:17,972: Parsing model.shopify_cohort_analysis.ga_transactions
2018-07-30 15:47:17,982: Parsing model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 15:47:17,990: Parsing model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 15:47:17,997: Parsing model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 15:47:18,008: Parsing model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 15:47:18,017: Parsing model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 15:47:18,024: Parsing model.shopify_cohort_analysis.agg_customers
2018-07-30 15:47:18,027: Parsing model.shopify_cohort_analysis.agg_transactions
2018-07-30 15:47:18,030: Parsing model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 15:47:18,034: Parsing model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 15:47:18,037: Parsing model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 15:47:18,040: Parsing model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 15:47:18,043: Parsing model.shopify_cohort_analysis.customers_proc
2018-07-30 15:47:18,047: Parsing model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 15:47:18,051: Parsing model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 15:47:18,056: Parsing model.shopify_cohort_analysis.segment_proc_buyers
2018-07-30 15:47:18,059: Parsing model.shopify_cohort_analysis.segment_stats_buyers_agg
2018-07-30 15:47:18,066: Parsing model.shopify_cohort_analysis.segment_stats_buyers_view
2018-07-30 15:47:18,077: Parsing model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 15:47:18,095: Found 23 models, 0 tests, 0 archives, 0 analyses, 62 macros, 0 operations, 0 seed files
2018-07-30 15:47:18,103: 
2018-07-30 15:47:18,110: Acquiring new bigquery connection "master".
2018-07-30 15:47:18,110: Opening a new connection (0 currently allocated)
2018-07-30 15:47:19,392: 15:47:19 | Concurrency: 4 threads (target='template')
2018-07-30 15:47:19,392: 15:47:19 | 
2018-07-30 15:47:19,554: 15:47:19 | 1 of 23 START table model template.mappings_ga_proc.................. [RUN]
2018-07-30 15:47:19,555: 15:47:19 | 2 of 23 START table model template.all_dates......................... [RUN]
2018-07-30 15:47:19,555: 15:47:19 | 3 of 23 START table model template.monthend_dates.................... [RUN]
2018-07-30 15:47:19,556: Compiling model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 15:47:19,555: 15:47:19 | 4 of 23 START table model template.stores_proc....................... [RUN]
2018-07-30 15:47:19,556: Compiling model.shopify_cohort_analysis.all_dates
2018-07-30 15:47:19,556: Compiling model.shopify_cohort_analysis.monthend_dates
2018-07-30 15:47:19,565: Writing injected SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 15:47:19,566: Compiling model.shopify_cohort_analysis.stores_proc
2018-07-30 15:47:19,571: Writing injected SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 15:47:19,578: Writing injected SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 15:47:19,584: Writing injected SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 15:47:19,587: Acquiring new bigquery connection "mappings_ga_proc".
2018-07-30 15:47:19,588: Opening a new connection (1 currently allocated)
2018-07-30 15:47:19,593: Acquiring new bigquery connection "stores_proc".
2018-07-30 15:47:19,596: Acquiring new bigquery connection "all_dates".
2018-07-30 15:47:19,598: Acquiring new bigquery connection "monthend_dates".
2018-07-30 15:47:19,600: Opening a new connection (2 currently allocated)
2018-07-30 15:47:19,602: Opening a new connection (3 currently allocated)
2018-07-30 15:47:19,610: Opening a new connection (4 currently allocated)
2018-07-30 15:47:20,017: Writing runtime SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 15:47:20,018: Fetching data for query mappings_ga_proc:
create or replace table `template`.`mappings_ga_proc`
  
  as (
    select 
store,
account,
store_name,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client store,
account,
client_name store_name,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.mappings_ga` 

) 

WHERE lv = time_of_entry
group by store, account, store_name, source, medium, platform_n, channel_n, time_of_entry
  );

    
2018-07-30 15:47:20,131: Writing runtime SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 15:47:20,132: Fetching data for query stores_proc:
create or replace table `template`.`stores_proc`
  
  as (
    select 
store,
store_name,
account,
platform,
max(time_of_entry) time_of_entry

from  ( 

SELECT  
client store,
client_name store_name,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.accounts` 
where client_name != ''

) 

WHERE lv = time_of_entry
group by store, store_name, account, platform
  );

    
2018-07-30 15:47:20,149: Writing runtime SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 15:47:20,151: Fetching data for query monthend_dates:
create or replace table `template`.`monthend_dates`
  
  as (
    SELECT
date_in_range,
date_in_range_bom,
date_in_range_bom_mom,
unix_date_in_range,
unix_date_in_range_bom,
unix_date(date_in_range_bom_mom) unix_date_in_range_bom_mom,
yyyymm,
date_in_range_yoy,
unix_date(date_in_range_yoy) unix_date_in_range_yoy

FROM
(
	SELECT 
	date_in_range,
	date_in_range_bom,
	date_sub(date_in_range_bom, INTERVAL 1 MONTH) date_in_range_bom_mom,
	date_sub(date_in_range, INTERVAL 1 YEAR) date_in_range_yoy,
	unix_date_in_range,
	unix_date(date_in_range_bom) unix_date_in_range_bom,
	yyyymm,
	first_value(date_in_range) over (partition by yyyymm order by date_in_range desc) monthend_date_in_range
	FROM
	( 
		SELECT 
		date_in_range,
		date_trunc( date_in_range, MONTH) date_in_range_bom,
		unix_date(date_in_range) unix_date_in_range,
		format_date("%Y-%m", date_in_range) AS yyyymm
		FROM UNNEST(
		    GENERATE_DATE_ARRAY(DATE('2016-01-31'), CURRENT_DATE(), INTERVAL 1 DAY)
		) AS date_in_range
	)
)
where date_in_range = monthend_date_in_range
  );

    
2018-07-30 15:47:20,199: Writing runtime SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 15:47:20,204: Fetching data for query all_dates:
create or replace table `template`.`all_dates`
  
  as (
    SELECT 
date_in_range,
unix_date(date_in_range) unix_date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
  );

    
2018-07-30 15:47:21,548: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106144978>]}
2018-07-30 15:47:21,580: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106144828>]}
2018-07-30 15:47:21,788: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106144630>]}
2018-07-30 15:47:21,857: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106144be0>]}
2018-07-30 15:47:21,864: 15:47:21 | 3 of 23 OK created table model template.monthend_dates............... [OK in 1.99s]
2018-07-30 15:47:22,165: 15:47:22 | 2 of 23 OK created table model template.all_dates.................... [OK in 2.02s]
2018-07-30 15:47:22,475: 15:47:22 | 4 of 23 OK created table model template.stores_proc.................. [OK in 2.22s]
2018-07-30 15:47:22,787: 15:47:22 | 1 of 23 OK created table model template.mappings_ga_proc............. [OK in 2.30s]
2018-07-30 15:47:22,788: 15:47:22 | 5 of 23 START table model template.shopify_refunds_proc.............. [RUN]
2018-07-30 15:47:22,789: Compiling model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 15:47:22,788: 15:47:22 | 6 of 23 START table model template.shopify_customers_proc............ [RUN]
2018-07-30 15:47:22,795: Compiling model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 15:47:22,788: 15:47:22 | 7 of 23 START table model template.shopify_discounts_proc............ [RUN]
2018-07-30 15:47:22,812: Acquiring new bigquery connection "shopify_customers_proc".
2018-07-30 15:47:22,814: Acquiring new bigquery connection "shopify_refunds_proc".
2018-07-30 15:47:22,814: Compiling model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 15:47:22,814: Re-using an available connection from the pool.
2018-07-30 15:47:22,820: Fetching data for query shopify_customers_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:47:22,824: Acquiring new bigquery connection "shopify_discounts_proc".
2018-07-30 15:47:22,824: Re-using an available connection from the pool.
2018-07-30 15:47:22,826: Fetching data for query shopify_refunds_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:47:22,826: Re-using an available connection from the pool.
2018-07-30 15:47:22,828: Fetching data for query shopify_discounts_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:47:24,398: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 15:47:24,402: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 15:47:24,553: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 15:47:24,554: Fetching data for query shopify_customers_proc:
create or replace table `template`.`shopify_customers_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`





with customers as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	created_at,
	id,
	first_name,
	last_name,
	email,
	_sdc_sequence,
	first_value(_sdc_sequence) over (partition by id order by _sdc_sequence desc) lv
	FROM `growth-engines-pipeline.shopify_lucadanni.customers` 
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
id,
first_name,
last_name,
email
FROM customers a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence


  );

    
2018-07-30 15:47:24,590: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 15:47:24,591: Fetching data for query shopify_refunds_proc:
create or replace table `template`.`shopify_refunds_proc`
  
  as (
    



with refunds as (

	
	SELECT
	'lucadanni' store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal,
	line_item.variant_id variant_id,
	line_item.id refund_id,
 	_sdc_sequence
	FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
	cross join unnest(refunds), unnest(refund_line_items)
  	where financial_status like '%refund%'
	
	

)

SELECT * 
FROM 
	(
    SELECT
    store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal refund_amount,
	variant_id,
	refund_id,
 	_sdc_sequence,
    first_value(_sdc_sequence) OVER (PARTITION BY order_number, line_item_id ORDER BY _sdc_sequence DESC) lv
    FROM refunds
   	) 
WHERE lv = _sdc_sequence


  );

    
2018-07-30 15:47:24,607: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 15:47:24,798: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 15:47:24,799: Fetching data for query shopify_discounts_proc:
create or replace table `template`.`shopify_discounts_proc`
  
  as (
    



with orders as (

	
		SELECT
		'lucadanni' store_name,
		created_at,
		order_number,
		code discount_code,
		type discount_type,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(discount_codes)
		where source_name != 'shopify_draft_order'
	
	
	

)

SELECT
store_name,
order_number,
discount_code,
discount_type
FROM orders
where lv = _sdc_sequence


  );

    
2018-07-30 15:47:26,808: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104142438>]}
2018-07-30 15:47:27,430: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10617ab00>]}
2018-07-30 15:47:27,622: 15:47:27 | 5 of 23 OK created table model template.shopify_refunds_proc......... [OK in 4.02s]
2018-07-30 15:47:28,159: 15:47:28 | 7 of 23 OK created table model template.shopify_discounts_proc....... [OK in 4.62s]
2018-07-30 15:47:30,101: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106152748>]}
2018-07-30 15:47:30,403: 15:47:30 | 6 of 23 OK created table model template.shopify_customers_proc....... [OK in 7.31s]
2018-07-30 15:47:30,403: 15:47:30 | 8 of 23 START table model template.agg_customers..................... [RUN]
2018-07-30 15:47:30,404: 15:47:30 | 9 of 23 START table model template.shopify_products_proc............. [RUN]
2018-07-30 15:47:30,404: Compiling model.shopify_cohort_analysis.agg_customers
2018-07-30 15:47:30,404: 15:47:30 | 10 of 23 START table model template.ga_transactions.................. [RUN]
2018-07-30 15:47:30,404: Compiling model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 15:47:30,410: Writing injected SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 15:47:30,410: Compiling model.shopify_cohort_analysis.ga_transactions
2018-07-30 15:47:30,425: Acquiring new bigquery connection "shopify_products_proc".
2018-07-30 15:47:30,471: Re-using an available connection from the pool.
2018-07-30 15:47:30,472: Fetching data for query shopify_products_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:47:30,471: Acquiring new bigquery connection "ga_transactions".
2018-07-30 15:47:30,476: Re-using an available connection from the pool.
2018-07-30 15:47:30,476: Fetching data for query ga_transactions:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Google Analytics'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:47:30,499: Acquiring new bigquery connection "agg_customers".
2018-07-30 15:47:30,500: Re-using an available connection from the pool.
2018-07-30 15:47:30,655: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 15:47:30,662: Fetching data for query agg_customers:
create or replace table `template`.`agg_customers`
  
  as (
    SELECT 
account,
store,
id,
created_at,
first_name,
last_name,
email,
split(email,'@')[SAFE_ORDINAL(2)] email_domain
FROM
`growth-engines-pipeline`.`template`.`shopify_customers_proc`
  );

    
2018-07-30 15:47:31,092: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 15:47:31,253: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 15:47:31,256: Fetching data for query shopify_products_proc:
create or replace table `template`.`shopify_products_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`





with products as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	product_name,
	lower(product_type) product_type,
	product_id,
	sku,
	id variant_id,
	cast(created_at as date) created_at,
	_sdc_sequence,
	first_value(_sdc_sequence) OVER (PARTITION BY product_id ORDER BY _sdc_sequence DESC) lv
	FROM (
		SELECT
		variants,
		product_type,
		title product_name,
		_sdc_sequence
		FROM `growth-engines-pipeline.shopify_lucadanni.products` 
		)
	cross join unnest(variants)
	
	

)

SELECT
b.account,
b.store,
b.platform,
max(product_type) product_type,
product_id,
variant_id,
sku,
created_at,
product_name
FROM products a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence
group by product_id, account, store, platform, sku, variant_id, created_at, product_name


  );

    
2018-07-30 15:47:32,165: Writing injected SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 15:47:32,363: Writing runtime SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 15:47:32,369: Fetching data for query ga_transactions:
create or replace table `template`.`ga_transactions`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`,`growth-engines-pipeline`.`template`.`mappings_ga_proc`




with ga_report as (

	    
	    	
		   	SELECT
		   	'yandy' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_yandy.report` 

		     UNION ALL 
	   
	    	
		   	SELECT
		   	'lucadanni' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_lucadanni.report` 

		    
	   

)


SELECT  
date,
b.store store,
c.source source,
c.medium medium,
a.campaign campaign,
concat(a.source, ' / ', a.medium) source_medium,  
case when c.platform is null then "Unmapped" else c.platform end as platform,
case when c.channel is null then "Unmapped" else c.channel end as channel,
url,
transactionid
FROM (

	SELECT 
	store_name,
	lookup_platform,
	date,
	transactionid,
	max(url) url,
	max(source) source,
	max(medium) medium,
	max(campaign) campaign
	FROM ga_report
	where lv = _sdc_sequence
	group by store_name, lookup_platform, date, transactionid

) a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name 
	AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`mappings_ga_proc` c
ON ( a.source = c.source
  AND a.medium = c.medium 
  AND a.store_name = c.store_name )


  );

    
2018-07-30 15:47:33,480: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10607d160>]}
2018-07-30 15:47:34,110: 15:47:34 | 9 of 23 OK created table model template.shopify_products_proc........ [OK in 3.08s]
2018-07-30 15:47:34,690: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10610c518>]}
2018-07-30 15:47:35,354: 15:47:35 | 8 of 23 OK created table model template.agg_customers................ [OK in 4.29s]
2018-07-30 15:47:57,648: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102ceb470>]}
2018-07-30 15:47:57,994: 15:47:57 | 10 of 23 OK created table model template.ga_transactions............. [OK in 27.24s]
2018-07-30 15:47:57,996: 15:47:57 | 11 of 23 START table model template.shopify_orders_proc.............. [RUN]
2018-07-30 15:47:57,997: Compiling model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 15:47:58,041: Acquiring new bigquery connection "shopify_orders_proc".
2018-07-30 15:47:58,042: Re-using an available connection from the pool.
2018-07-30 15:47:58,043: Fetching data for query shopify_orders_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:47:58,760: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 15:47:58,905: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 15:47:58,905: Fetching data for query shopify_orders_proc:
create or replace table `template`.`shopify_orders_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`, `growth-engines-pipeline`.`template`.`shopify_discounts_proc`





with orders as (

	
	SELECT 
	store_name,
	lookup_platform,
	created_at,
	order_number,
	quantity,
	price, 
	total_order_price_undiscounted,
	total_discounts,
	total_order_shipping_price,
	total_order_price_incl_shipping,
	checkout_id,
	product_id, 
	landing_site,
	sku, 
	variant_title, 
	variant_id,
	line_item_id,
	customer_id,
	_sdc_sequence,
	lv
	FROM (

		SELECT
		'lucadanni' store_name,
		'Shopify' as lookup_platform,
		created_at,
		order_number,
		quantity,
		cast(pre_tax_price as float64) price, 
		total_line_items_price total_order_price_undiscounted,
		total_discounts,
		cast(discounted_price as float64) total_order_shipping_price,
		total_price_usd total_order_price_incl_shipping,
		checkout_id,
		product_id, 
		landing_site,
		sku, 
		variant_title, 
		variant_id,
		_id line_item_id,
		customer.id customer_id,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(line_items), unnest(shipping_lines)
		where source_name != 'shopify_draft_order'
	)
	
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
a.order_number,
a.quantity prelim_quantity,
c.quantity refund_quantity,
case when c.quantity is not null then a.quantity - c.quantity else a.quantity end as quantity,
price prelim_revenue, 
total_order_price_undiscounted,
total_discounts,
trim(lower(d.discount_code)) discount_code,
d.discount_type,
total_order_shipping_price,
total_order_price_incl_shipping,
refund_amount,
case when refund_amount is not null then price - refund_amount else price end as revenue,
a.checkout_id,
a.product_id, 
landing_site,
sku, 
variant_title, 
a.variant_id,
a.line_item_id,	
customer_id
FROM orders a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_refunds_proc` c
ON ( a.order_number = c.order_number
	AND a.line_item_id = c.line_item_id
	AND a.store_name = c.store_name )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_discounts_proc` d
ON ( a.order_number = d.order_number 
    AND a.store_name = d.store_name )  	
where a.lv = a._sdc_sequence


  );

    
2018-07-30 15:48:09,661: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106152748>]}
2018-07-30 15:48:10,007: 15:48:10 | 11 of 23 OK created table model template.shopify_orders_proc......... [OK in 11.66s]
2018-07-30 15:48:10,008: 15:48:10 | 12 of 23 START table model template.transaction_by_order_number...... [RUN]
2018-07-30 15:48:10,009: Compiling model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 15:48:10,020: Writing injected SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 15:48:10,026: Acquiring new bigquery connection "transaction_by_order_number".
2018-07-30 15:48:10,026: Re-using an available connection from the pool.
2018-07-30 15:48:10,169: Writing runtime SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 15:48:10,170: Fetching data for query transaction_by_order_number:
create or replace table `template`.`transaction_by_order_number`
  
  as (
    SELECT
store,
cast(created_at as date) order_date,
order_number,
customer_id,
sum(quantity) quantity,
sum(revenue) revenue,
max(total_order_shipping_price) shipping_price
FROM
`growth-engines-pipeline`.`template`.`shopify_orders_proc`
GROUP BY store, order_date, order_number, customer_id
  );

    
2018-07-30 15:48:14,180: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106073ef0>]}
2018-07-30 15:48:14,974: 15:48:14 | 12 of 23 OK created table model template.transaction_by_order_number. [OK in 4.17s]
2018-07-30 15:48:14,974: 15:48:14 | 13 of 23 START table model template.customers_by_transaction......... [RUN]
2018-07-30 15:48:14,974: Compiling model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 15:48:14,982: Writing injected SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 15:48:14,987: Acquiring new bigquery connection "customers_by_transaction".
2018-07-30 15:48:14,987: Re-using an available connection from the pool.
2018-07-30 15:48:15,162: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 15:48:15,163: Fetching data for query customers_by_transaction:
create or replace table `template`.`customers_by_transaction`
  
  as (
    SELECT
store,
customer_id,
order_number,
order_date,
recent_order_date,
first_order_date,
case when first_order_number = order_number then 'New'
	when date_diff(order_date, recent_order_date, DAY) <= 365 then 'Repeat'
	when date_diff(order_date, recent_order_date, DAY) > 365 then 'Reactivated'
 else '' end as order_type,
quantity,
revenue,
1 as orders,
first_order_revenue,
lifetime_revenue
FROM

(

	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	quantity,
	revenue,
	lag(order_date) over w1 recent_order_date,
	first_value(order_date) over w1 first_order_date,
	first_value(order_number) over w1 first_order_number,
	first_value(revenue) over w1 first_order_revenue,
	sum(revenue) over w2 lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`transaction_by_order_number`
	WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc),
	w2 as (PARTITION BY store, customer_id)
)
  );

    
2018-07-30 15:48:18,899: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106152748>]}
2018-07-30 15:48:20,131: 15:48:20 | 13 of 23 OK created table model template.customers_by_transaction.... [OK in 3.92s]
2018-07-30 15:48:20,132: 15:48:20 | 14 of 23 START table model template.agg_transactions................. [RUN]
2018-07-30 15:48:20,132: Compiling model.shopify_cohort_analysis.agg_transactions
2018-07-30 15:48:20,145: Writing injected SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 15:48:20,152: Acquiring new bigquery connection "agg_transactions".
2018-07-30 15:48:20,152: Re-using an available connection from the pool.
2018-07-30 15:48:20,295: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 15:48:20,296: Fetching data for query agg_transactions:
create or replace table `template`.`agg_transactions`
  
  as (
    with ga_transaction as (

	SELECT
	date, 
	store,
	transactionid,
	channel,
	platform,
	url,
	campaign
	FROM `growth-engines-pipeline`.`template`.`ga_transactions`
),

customers_by_transaction as (
	
	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	first_order_date,
	recent_order_date,
	order_type,
	quantity,
	revenue,
	orders,
	first_order_revenue,
	lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`customers_by_transaction`
)

SELECT
store,
customer_id,
order_number,
transactionid,
order_date,
first_order_date,
format_date("%Y-%m", first_order_date) AS first_order_month,
order_type,
first_order_revenue,
lifetime_revenue,
first_value(channel) over w1 as first_order_channel,
first_value(platform) over w1 as first_order_platform,
channel,
platform,
url,
campaign,
quantity,
revenue,
orders
FROM (

	SELECT
	a.store,
	a.customer_id,
	a.order_number,
	b.transactionid,
	a.order_date, 
	a.first_order_date, 
	a.order_type,
	a.first_order_revenue,
	a.lifetime_revenue,
	b.channel,
	b.platform,
	b.url,
	b.campaign,
	a.quantity,
	a.revenue,
	a.orders
	FROM customers_by_transaction a
	LEFT JOIN ga_transaction b
	ON (
	    a.store = b.store AND
	    a.order_number = b.transactionid
	)	
)
WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc)
  );

    
2018-07-30 15:48:28,275: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106073ef0>]}
2018-07-30 15:48:28,588: 15:48:28 | 14 of 23 OK created table model template.agg_transactions............ [OK in 8.14s]
2018-07-30 15:48:28,592: 15:48:28 | 15 of 23 START table model template.customers_proc_qoq............... [RUN]
2018-07-30 15:48:28,593: Compiling model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 15:48:28,592: 15:48:28 | 16 of 23 START table model template.monthly_cohort_stats............. [RUN]
2018-07-30 15:48:28,599: Compiling model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 15:48:28,593: 15:48:28 | 17 of 23 START table model template.customers_proc_yoy............... [RUN]
2018-07-30 15:48:28,608: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 15:48:28,616: Writing injected SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 15:48:28,617: Compiling model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 15:48:28,625: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 15:48:28,627: Acquiring new bigquery connection "monthly_cohort_stats".
2018-07-30 15:48:28,628: Re-using an available connection from the pool.
2018-07-30 15:48:28,629: Acquiring new bigquery connection "customers_proc_yoy".
2018-07-30 15:48:28,632: Acquiring new bigquery connection "customers_proc_qoq".
2018-07-30 15:48:28,632: Re-using an available connection from the pool.
2018-07-30 15:48:28,634: Re-using an available connection from the pool.
2018-07-30 15:48:28,843: Writing runtime SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 15:48:28,864: Fetching data for query monthly_cohort_stats:
create or replace table `template`.`monthly_cohort_stats`
  
  as (
    WITH transactions AS (

  SELECT 
  store, 
  order_number,
  order_date,
  order_type,
  first_order_month,
  unix_date(order_date) d, 
  customer_id, 
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (

  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT 
date_in_range date,
store, 
order_type,
first_order_channel,
first_order_platform,
first_order_month,
channel,
platform,
url,
campaign,
count(distinct(customer_id)) buyers,
sum(orders) orders,
sum(quantity) quantity,
sum(revenue) revenue
FROM daterange
JOIN transactions
ON transactions.d >= daterange.unix_date_in_range_bom 
AND transactions.d <= daterange.unix_date_in_range
GROUP BY date, store, order_type, 
first_order_channel, first_order_platform, first_order_month, channel, platform, url, campaign
  );

    
2018-07-30 15:48:28,877: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 15:48:28,878: Fetching data for query customers_proc_yoy:
create or replace table `template`.`customers_proc_yoy`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 365 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 365 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 365 window_end_unix_date, 
    unix_date_in_range - 730 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 730 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 365 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 15:48:28,887: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 15:48:28,891: Fetching data for query customers_proc_qoq:
create or replace table `template`.`customers_proc_qoq`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 90 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 90 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 90 window_end_unix_date, 
    unix_date_in_range - 180 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 180 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 90 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 15:48:34,800: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102ccd898>]}
2018-07-30 15:48:35,178: 15:48:35 | 16 of 23 OK created table model template.monthly_cohort_stats........ [OK in 6.20s]
2018-07-30 15:48:43,142: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106152748>]}
2018-07-30 15:48:43,929: 15:48:43 | 15 of 23 OK created table model template.customers_proc_qoq.......... [OK in 14.55s]
2018-07-30 15:48:51,431: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061d36a0>]}
2018-07-30 15:48:52,216: 15:48:52 | 17 of 23 OK created table model template.customers_proc_yoy.......... [OK in 22.81s]
2018-07-30 15:48:52,217: 15:48:52 | 18 of 23 START table model template.customers_proc................... [RUN]
2018-07-30 15:48:52,218: Compiling model.shopify_cohort_analysis.customers_proc
2018-07-30 15:48:52,226: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 15:48:52,229: Acquiring new bigquery connection "customers_proc".
2018-07-30 15:48:52,229: Re-using an available connection from the pool.
2018-07-30 15:48:52,419: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 15:48:52,420: Fetching data for query customers_proc:
create or replace table `template`.`customers_proc`
  
  as (
    SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_qoq`

UNION ALL

SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_yoy`
  );

    
2018-07-30 15:49:17,820: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106073ef0>]}
2018-07-30 15:49:18,153: 15:49:18 | 18 of 23 OK created table model template.customers_proc.............. [OK in 25.60s]
2018-07-30 15:49:18,155: 15:49:18 | 19 of 23 START table model template.segment_proc_buyers.............. [RUN]
2018-07-30 15:49:18,155: Compiling model.shopify_cohort_analysis.segment_proc_buyers
2018-07-30 15:49:18,165: Writing injected SQL for node "model.shopify_cohort_analysis.segment_proc_buyers"
2018-07-30 15:49:18,166: Acquiring new bigquery connection "segment_proc_buyers".
2018-07-30 15:49:18,166: Re-using an available connection from the pool.
2018-07-30 15:49:18,296: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_proc_buyers"
2018-07-30 15:49:18,297: Fetching data for query segment_proc_buyers:
create or replace table `template`.`segment_proc_buyers`
  
  as (
    SELECT
store,
period,
customer_id,
date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct,
case when first_order_unix_date >= window_start_unix_date then 'New'
	else 'Existing' end as newness_segment,
case when revenue >= revenue_90pct then 'Top 10%'
	when revenue <= revenue_10pct then 'Bottom 10%'
	else 'Middle 80%' end as revenue_segment,
case when frequency = 1 then '1'
	when frequency = 2 then '2'
	when frequency > 2 then '3+'
	else null end as frequency_segment
FROM `growth-engines-pipeline`.`template`.`customers_proc`
  );

    
2018-07-30 15:49:46,143: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102d66630>]}
2018-07-30 15:49:47,123: 15:49:47 | 19 of 23 OK created table model template.segment_proc_buyers......... [OK in 27.99s]
2018-07-30 15:49:47,131: 15:49:47 | 20 of 23 START table model template.segment_stats_buyers_agg......... [RUN]
2018-07-30 15:49:47,136: Compiling model.shopify_cohort_analysis.segment_stats_buyers_agg
2018-07-30 15:49:47,194: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_agg"
2018-07-30 15:49:47,200: Acquiring new bigquery connection "segment_stats_buyers_agg".
2018-07-30 15:49:47,201: Re-using an available connection from the pool.
2018-07-30 15:49:47,601: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_agg"
2018-07-30 15:49:47,601: Fetching data for query segment_stats_buyers_agg:
create or replace table `template`.`segment_stats_buyers_agg`
  
  as (
    WITH ty as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev,
	0 as retention_eligible,
	case when newness_segment = 'Existing' then 1 else 0 end as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Year'

),

this_month_1yr as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment,
	frequency_segment,
	newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	recency_days as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev,
	1 as retention_eligible,
	0 as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Previous Year'

),

this_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,	
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment,
	frequency_segment,
	newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev,
	0 as retention_eligible,
	case when newness_segment = 'Existing' then 1 else 0 end as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Quarter'

),

last_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	recency_days as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev,
	1 as retention_eligible,
	0 as retention_success
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Previous Quarter'

)

SELECT
store,
period,
date, 
customer_id,
case when sum(revenue) > 0 then 1 else 0 end as buyers,
first_order_channel,
first_order_platform,	
revenue_segment,
frequency_segment,
newness_segment,	
ifnull(sum(recency), 0) recency,
ifnull(sum(frequency), 0) frequency,
ifnull(sum(revenue), 0) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else 0 end as aov,
ifnull(sum(recency_prev), 0) recency_prev,
ifnull(sum(frequency_prev), 0) frequency_prev,
ifnull(sum(revenue_prev), 0) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else 0 end as aov_prev,
sum(retention_eligible) retention_eligible,
sum(retention_success) retention_success
FROM
(
	SELECT * FROM ty
	UNION ALL
	SELECT * FROM this_month_1yr
	UNION ALL
	SELECT * FROM this_quarter
	UNION ALL
	SELECT * FROM last_quarter

)
GROUP BY store, period, date, customer_id, first_order_channel, first_order_platform,
revenue_segment, frequency_segment, newness_segment
  );

    
2018-07-30 15:50:28,415: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106073ef0>]}
2018-07-30 15:50:28,743: 15:50:28 | 20 of 23 OK created table model template.segment_stats_buyers_agg.... [OK in 41.28s]
2018-07-30 15:50:28,744: 15:50:28 | 21 of 23 START table model template.segment_stats_buyers_view........ [RUN]
2018-07-30 15:50:28,745: Compiling model.shopify_cohort_analysis.segment_stats_buyers_view
2018-07-30 15:50:28,769: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_view"
2018-07-30 15:50:28,772: Acquiring new bigquery connection "segment_stats_buyers_view".
2018-07-30 15:50:28,772: Re-using an available connection from the pool.
2018-07-30 15:50:28,932: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_view"
2018-07-30 15:50:28,933: Fetching data for query segment_stats_buyers_view:
create or replace table `template`.`segment_stats_buyers_view`
  
  as (
    SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Total' as segment_type,
'Total' as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Total' as segment_type,
'Total' as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Total' as segment_type,
'Total' as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type
  );

    
2018-07-30 15:50:33,457: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102d5ee48>]}
2018-07-30 15:50:33,754: 15:50:33 | 21 of 23 OK created table model template.segment_stats_buyers_view... [OK in 4.71s]
2018-07-30 15:50:33,755: 15:50:33 | 22 of 23 START table model template.buyer_segment_stats.............. [RUN]
2018-07-30 15:50:33,755: Compiling model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 15:50:33,762: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 15:50:33,765: Acquiring new bigquery connection "buyer_segment_stats".
2018-07-30 15:50:33,765: Re-using an available connection from the pool.
2018-07-30 15:50:33,897: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 15:50:33,898: Fetching data for query buyer_segment_stats:
create or replace table `template`.`buyer_segment_stats`
  
  as (
    SELECT
store,
period,
date,
view,
view_segment,
segment_type,
segment,
buyers,
total_view_buyers,
case when ( total_segment_buyers / total_buyers ) > 0 
	then ( buyers / total_view_buyers ) / ( total_segment_buyers / total_buyers ) 
	else null end as segment_buyer_index,
recency,
orders,
case when buyers > 0 then orders / buyers else null end as frequency,
revenue,
case when total_revenue > 0 then revenue / total_revenue else null end as pct_of_revenue,
revenue_prev,
total_view_revenue,
case when ( total_segment_revenue / total_revenue ) > 0 
	then ( revenue / total_view_revenue ) / ( total_segment_revenue / total_revenue ) 
	else null end as segment_revenue_index,
aov,
recency_growth,
frequency_growth,
revenue_growth,
aov_growth,
retention_rate
FROM (

	SELECT
	store,
	period,
	date,
	view,
	view_segment,
	segment_type,
	segment,
	buyers,
	sum(buyers) over w1 as total_view_buyers,
	sum(buyers) over w2 as total_segment_buyers,
	sum(buyers) over w3 as total_buyers,
	recency,
	frequency orders,
	revenue,
	sum(revenue) over w1 as total_view_revenue,
	sum(revenue) over w2 as total_segment_revenue,
	sum(revenue) over w3 as total_revenue,
	aov,
	case when recency_prev > 0 then ( recency_prev - recency ) / recency_prev else null end as recency_growth,
	case when frequency_prev > 0 then ( frequency - frequency_prev ) / frequency_prev else null end as frequency_growth,
	revenue_prev,
	case when revenue_prev > 0 then ( revenue - revenue_prev ) / revenue_prev else null end as revenue_growth,
	case when aov_prev > 0 then ( aov - aov_prev ) / aov_prev else null end as aov_growth,
	retention_rate
	FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_view`
	WINDOW w1 as (PARTITION BY store, period, date, segment_type, view, view_segment),
	w2 as (PARTITION BY store, period, date, segment_type, view, segment),
	w3 as (PARTITION BY store, period, date, segment_type, view)
)
  );

    
2018-07-30 15:50:35,871: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106073ef0>]}
2018-07-30 15:50:36,539: 15:50:36 | 22 of 23 OK created table model template.buyer_segment_stats......... [OK in 2.12s]
2018-07-30 15:50:36,542: 15:50:36 | 23 of 23 START table model template.buyer_segment_lists.............. [RUN]
2018-07-30 15:50:36,542: Compiling model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 15:50:36,557: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 15:50:36,562: Acquiring new bigquery connection "buyer_segment_lists".
2018-07-30 15:50:36,563: Re-using an available connection from the pool.
2018-07-30 15:50:36,873: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 15:50:36,874: Fetching data for query buyer_segment_lists:
create or replace table `template`.`buyer_segment_lists`
  
  as (
    SELECT
a.store,
period,
date,
customer_id,
b.first_name,
b.last_name,
b.email,
recency,
frequency,
revenue,
aov,
revenue_segment,
frequency_segment
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg` a
LEFT JOIN `growth-engines-pipeline`.`template`.`agg_customers` b
ON (
	a.store = b.store AND
	a.customer_id = b.id
)
where ( revenue_segment != '' or frequency_segment != '' )
  );

    
2018-07-30 15:51:09,199: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13d97428-e8b7-4d01-a1df-bc5a6ed10a98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102d20c88>]}
2018-07-30 15:51:10,264: 15:51:10 | 23 of 23 OK created table model template.buyer_segment_lists......... [OK in 32.66s]
2018-07-30 15:51:10,320: 15:51:10 | 
2018-07-30 15:51:10,320: 15:51:10 | Finished running 23 table models in 232.22s.
2018-07-30 15:51:10,321: Connection 'master' was left open.
2018-07-30 15:51:10,324: 
2018-07-30 15:51:10,324: Completed successfully
2018-07-30 15:51:10,324: 
Done. PASS=23 ERROR=0 SKIP=0 TOTAL=23
2018-07-30 15:51:10,325: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060b14a8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060eaa90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060ea320>]}
2018-07-30 15:51:10,939: Flushing usage events
2018-07-30 15:51:11,456: sys:1: ResourceWarning: unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57773), raddr=('172.217.1.202', 443)>

2018-07-30 15:51:11,458: sys:1: ResourceWarning: unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57771), raddr=('172.217.2.13', 443)>

2018-07-30 15:51:11,458: sys:1: ResourceWarning: unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57780), raddr=('172.217.3.10', 443)>

2018-07-30 15:51:11,459: sys:1: ResourceWarning: unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57779), raddr=('172.217.3.10', 443)>

2018-07-30 15:51:11,459: sys:1: ResourceWarning: unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57775), raddr=('172.217.2.13', 443)>

2018-07-30 15:51:11,460: sys:1: ResourceWarning: unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57776), raddr=('172.217.2.13', 443)>

2018-07-30 15:51:11,465: sys:1: ResourceWarning: unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57781), raddr=('172.217.3.10', 443)>

2018-07-30 15:51:11,466: sys:1: ResourceWarning: unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57782), raddr=('172.217.3.10', 443)>

2018-07-30 15:51:11,466: sys:1: ResourceWarning: unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57777), raddr=('172.217.2.13', 443)>

2018-07-30 15:51:11,468: sys:1: ResourceWarning: unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57778), raddr=('172.217.2.13', 443)>

2018-07-30 15:55:11,118: Tracking: tracking
2018-07-30 15:55:11,120: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bbbae48>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bbbaf28>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bbbaa20>]}
2018-07-30 15:55:12,106: Loading dependency project from /usr/local/Cellar/dbt/0.10.1/libexec/lib/python3.6/site-packages/dbt/include
2018-07-30 15:55:12,148: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/shopify-cohort-analysis/dbt_modules
2018-07-30 15:55:12,155: Parsing get_column_values.sql
2018-07-30 15:55:12,204: Parsing get_url_parameter.sql
2018-07-30 15:55:12,211: Parsing split_part.sql
2018-07-30 15:55:12,232: Parsing table_exists.sql
2018-07-30 15:55:12,261: Parsing core.sql
2018-07-30 15:55:12,291: Parsing adapters/bigquery.sql
2018-07-30 15:55:12,302: Parsing adapters/common.sql
2018-07-30 15:55:12,343: Parsing adapters/redshift.sql
2018-07-30 15:55:12,370: Parsing adapters/snowflake.sql
2018-07-30 15:55:12,375: Parsing etc/bigquery.sql
2018-07-30 15:55:12,379: Parsing etc/datetime.sql
2018-07-30 15:55:12,419: Parsing etc/get_custom_schema.sql
2018-07-30 15:55:12,430: Parsing materializations/helpers.sql
2018-07-30 15:55:12,473: Parsing materializations/archive/archive.sql
2018-07-30 15:55:12,574: Parsing materializations/incremental/incremental.sql
2018-07-30 15:55:12,724: Parsing materializations/seed/bigquery.sql
2018-07-30 15:55:12,739: Parsing materializations/seed/seed.sql
2018-07-30 15:55:12,935: Parsing materializations/table/bigquery_table.sql
2018-07-30 15:55:13,076: Parsing materializations/table/table.sql
2018-07-30 15:55:13,143: Parsing materializations/view/bigquery_view.sql
2018-07-30 15:55:13,173: Parsing materializations/view/view.sql
2018-07-30 15:55:13,207: Parsing schema_tests/accepted_values.sql
2018-07-30 15:55:13,213: Parsing schema_tests/not_null.sql
2018-07-30 15:55:13,218: Parsing schema_tests/relationships.sql
2018-07-30 15:55:13,225: Parsing schema_tests/unique.sql
2018-07-30 15:55:13,246: Parsing model.shopify_cohort_analysis.all_dates
2018-07-30 15:55:13,250: Parsing model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 15:55:13,252: Parsing model.shopify_cohort_analysis.monthend_dates
2018-07-30 15:55:13,254: Parsing model.shopify_cohort_analysis.stores_proc
2018-07-30 15:55:13,257: Parsing model.shopify_cohort_analysis.ga_transactions
2018-07-30 15:55:13,271: Parsing model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 15:55:13,283: Parsing model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 15:55:13,290: Parsing model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 15:55:13,301: Parsing model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 15:55:13,309: Parsing model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 15:55:13,316: Parsing model.shopify_cohort_analysis.agg_customers
2018-07-30 15:55:13,319: Parsing model.shopify_cohort_analysis.agg_transactions
2018-07-30 15:55:13,322: Parsing model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 15:55:13,327: Parsing model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 15:55:13,331: Parsing model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 15:55:13,335: Parsing model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 15:55:13,338: Parsing model.shopify_cohort_analysis.customers_proc
2018-07-30 15:55:13,342: Parsing model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 15:55:13,346: Parsing model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 15:55:13,352: Parsing model.shopify_cohort_analysis.segment_proc_buyers
2018-07-30 15:55:13,355: Parsing model.shopify_cohort_analysis.segment_stats_buyers_agg
2018-07-30 15:55:13,360: Parsing model.shopify_cohort_analysis.segment_stats_buyers_view
2018-07-30 15:55:13,372: Parsing model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 15:55:13,396: Found 23 models, 0 tests, 0 archives, 0 analyses, 62 macros, 0 operations, 0 seed files
2018-07-30 15:55:13,404: 
2018-07-30 15:55:13,410: Acquiring new bigquery connection "master".
2018-07-30 15:55:13,410: Opening a new connection (0 currently allocated)
2018-07-30 15:55:14,721: 15:55:14 | Concurrency: 4 threads (target='template')
2018-07-30 15:55:14,721: 15:55:14 | 
2018-07-30 15:55:14,834: 15:55:14 | 1 of 23 START table model template.stores_proc....................... [RUN]
2018-07-30 15:55:14,835: Compiling model.shopify_cohort_analysis.stores_proc
2018-07-30 15:55:14,834: 15:55:14 | 2 of 23 START table model template.mappings_ga_proc.................. [RUN]
2018-07-30 15:55:14,841: Writing injected SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 15:55:14,834: 15:55:14 | 3 of 23 START table model template.all_dates......................... [RUN]
2018-07-30 15:55:14,842: Compiling model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 15:55:14,835: 15:55:14 | 4 of 23 START table model template.monthend_dates.................... [RUN]
2018-07-30 15:55:14,842: Compiling model.shopify_cohort_analysis.all_dates
2018-07-30 15:55:14,852: Writing injected SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 15:55:14,852: Compiling model.shopify_cohort_analysis.monthend_dates
2018-07-30 15:55:14,854: Acquiring new bigquery connection "stores_proc".
2018-07-30 15:55:14,866: Writing injected SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 15:55:14,872: Opening a new connection (1 currently allocated)
2018-07-30 15:55:14,879: Writing injected SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 15:55:14,884: Acquiring new bigquery connection "monthend_dates".
2018-07-30 15:55:14,887: Acquiring new bigquery connection "all_dates".
2018-07-30 15:55:14,890: Opening a new connection (2 currently allocated)
2018-07-30 15:55:14,892: Acquiring new bigquery connection "mappings_ga_proc".
2018-07-30 15:55:14,895: Opening a new connection (3 currently allocated)
2018-07-30 15:55:14,908: Opening a new connection (4 currently allocated)
2018-07-30 15:55:15,726: Writing runtime SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 15:55:15,726: Fetching data for query stores_proc:
create or replace table `template`.`stores_proc`
  
  as (
    select 
store,
store_name,
account,
platform,
max(time_of_entry) time_of_entry

from  ( 

SELECT  
client store,
client_name store_name,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.accounts` 
where client_name != ''

) 

WHERE lv = time_of_entry
group by store, store_name, account, platform
  );

    
2018-07-30 15:55:15,762: Writing runtime SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 15:55:15,777: Writing runtime SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 15:55:15,784: Fetching data for query monthend_dates:
create or replace table `template`.`monthend_dates`
  
  as (
    SELECT
date_in_range,
date_in_range_bom,
date_in_range_bom_mom,
unix_date_in_range,
unix_date_in_range_bom,
unix_date(date_in_range_bom_mom) unix_date_in_range_bom_mom,
yyyymm,
date_in_range_yoy,
unix_date(date_in_range_yoy) unix_date_in_range_yoy

FROM
(
	SELECT 
	date_in_range,
	date_in_range_bom,
	date_sub(date_in_range_bom, INTERVAL 1 MONTH) date_in_range_bom_mom,
	date_sub(date_in_range, INTERVAL 1 YEAR) date_in_range_yoy,
	unix_date_in_range,
	unix_date(date_in_range_bom) unix_date_in_range_bom,
	yyyymm,
	first_value(date_in_range) over (partition by yyyymm order by date_in_range desc) monthend_date_in_range
	FROM
	( 
		SELECT 
		date_in_range,
		date_trunc( date_in_range, MONTH) date_in_range_bom,
		unix_date(date_in_range) unix_date_in_range,
		format_date("%Y-%m", date_in_range) AS yyyymm
		FROM UNNEST(
		    GENERATE_DATE_ARRAY(DATE('2016-01-31'), CURRENT_DATE(), INTERVAL 1 DAY)
		) AS date_in_range
	)
)
where date_in_range = monthend_date_in_range
  );

    
2018-07-30 15:55:15,790: Writing runtime SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 15:55:15,793: Fetching data for query mappings_ga_proc:
create or replace table `template`.`mappings_ga_proc`
  
  as (
    select 
store,
account,
store_name,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client store,
account,
client_name store_name,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.mappings_ga` 

) 

WHERE lv = time_of_entry
group by store, account, store_name, source, medium, platform_n, channel_n, time_of_entry
  );

    
2018-07-30 15:55:15,793: Fetching data for query all_dates:
create or replace table `template`.`all_dates`
  
  as (
    SELECT 
date_in_range,
unix_date(date_in_range) unix_date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
  );

    
2018-07-30 15:55:17,515: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd4a6a0>]}
2018-07-30 15:55:17,652: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd8cda0>]}
2018-07-30 15:55:17,980: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd8c5c0>]}
2018-07-30 15:55:18,150: 15:55:18 | 4 of 23 OK created table model template.monthend_dates............... [OK in 2.66s]
2018-07-30 15:55:18,151: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd12080>]}
2018-07-30 15:55:18,925: 15:55:18 | 3 of 23 OK created table model template.all_dates.................... [OK in 2.81s]
2018-07-30 15:55:19,547: 15:55:19 | 2 of 23 OK created table model template.mappings_ga_proc............. [OK in 3.14s]
2018-07-30 15:55:20,210: 15:55:20 | 1 of 23 OK created table model template.stores_proc.................. [OK in 3.32s]
2018-07-30 15:55:20,210: 15:55:20 | 5 of 23 START table model template.shopify_customers_proc............ [RUN]
2018-07-30 15:55:20,211: Compiling model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 15:55:20,211: 15:55:20 | 6 of 23 START table model template.shopify_refunds_proc.............. [RUN]
2018-07-30 15:55:20,211: 15:55:20 | 7 of 23 START table model template.shopify_discounts_proc............ [RUN]
2018-07-30 15:55:20,220: Compiling model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 15:55:20,220: Compiling model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 15:55:20,229: Acquiring new bigquery connection "shopify_customers_proc".
2018-07-30 15:55:20,233: Acquiring new bigquery connection "shopify_refunds_proc".
2018-07-30 15:55:20,240: Acquiring new bigquery connection "shopify_discounts_proc".
2018-07-30 15:55:20,240: Re-using an available connection from the pool.
2018-07-30 15:55:20,241: Fetching data for query shopify_customers_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:55:20,241: Re-using an available connection from the pool.
2018-07-30 15:55:20,241: Fetching data for query shopify_refunds_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:55:20,241: Re-using an available connection from the pool.
2018-07-30 15:55:20,243: Fetching data for query shopify_discounts_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:55:21,709: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 15:55:21,719: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 15:55:21,948: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 15:55:21,949: Fetching data for query shopify_refunds_proc:
create or replace table `template`.`shopify_refunds_proc`
  
  as (
    



with refunds as (

	
	SELECT
	'lucadanni' store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal,
	line_item.variant_id variant_id,
	line_item.id refund_id,
 	_sdc_sequence
	FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
	cross join unnest(refunds), unnest(refund_line_items)
  	where financial_status like '%refund%'
	
	

)

SELECT * 
FROM 
	(
    SELECT
    store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal refund_amount,
	variant_id,
	refund_id,
 	_sdc_sequence,
    first_value(_sdc_sequence) OVER (PARTITION BY order_number, line_item_id ORDER BY _sdc_sequence DESC) lv
    FROM refunds
   	) 
WHERE lv = _sdc_sequence


  );

    
2018-07-30 15:55:21,967: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 15:55:21,968: Fetching data for query shopify_customers_proc:
create or replace table `template`.`shopify_customers_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`





with customers as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	created_at,
	id,
	first_name,
	last_name,
	email,
	_sdc_sequence,
	first_value(_sdc_sequence) over (partition by id order by _sdc_sequence desc) lv
	FROM `growth-engines-pipeline.shopify_lucadanni.customers` 
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
id,
first_name,
last_name,
email
FROM customers a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence


  );

    
2018-07-30 15:55:22,045: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 15:55:22,186: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 15:55:22,187: Fetching data for query shopify_discounts_proc:
create or replace table `template`.`shopify_discounts_proc`
  
  as (
    



with orders as (

	
		SELECT
		'lucadanni' store_name,
		created_at,
		order_number,
		code discount_code,
		type discount_type,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(discount_codes)
		where source_name != 'shopify_draft_order'
	
	
	

)

SELECT
store_name,
order_number,
discount_code,
discount_type
FROM orders
where lv = _sdc_sequence


  );

    
2018-07-30 15:55:24,186: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a1fe048>]}
2018-07-30 15:55:24,297: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc876a0>]}
2018-07-30 15:55:24,490: 15:55:24 | 6 of 23 OK created table model template.shopify_refunds_proc......... [OK in 3.97s]
2018-07-30 15:55:24,808: 15:55:24 | 7 of 23 OK created table model template.shopify_discounts_proc....... [OK in 4.08s]
2018-07-30 15:55:26,740: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bdc8438>]}
2018-07-30 15:55:27,416: 15:55:27 | 5 of 23 OK created table model template.shopify_customers_proc....... [OK in 6.53s]
2018-07-30 15:55:27,418: 15:55:27 | 8 of 23 START table model template.agg_customers..................... [RUN]
2018-07-30 15:55:27,419: Compiling model.shopify_cohort_analysis.agg_customers
2018-07-30 15:55:27,418: 15:55:27 | 9 of 23 START table model template.shopify_products_proc............. [RUN]
2018-07-30 15:55:27,418: 15:55:27 | 10 of 23 START table model template.ga_transactions.................. [RUN]
2018-07-30 15:55:27,436: Compiling model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 15:55:27,438: Writing injected SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 15:55:27,439: Compiling model.shopify_cohort_analysis.ga_transactions
2018-07-30 15:55:27,454: Acquiring new bigquery connection "shopify_products_proc".
2018-07-30 15:55:27,462: Re-using an available connection from the pool.
2018-07-30 15:55:27,466: Fetching data for query shopify_products_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:55:27,472: Acquiring new bigquery connection "agg_customers".
2018-07-30 15:55:27,473: Re-using an available connection from the pool.
2018-07-30 15:55:27,591: Acquiring new bigquery connection "ga_transactions".
2018-07-30 15:55:27,591: Re-using an available connection from the pool.
2018-07-30 15:55:27,591: Fetching data for query ga_transactions:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Google Analytics'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:55:27,938: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 15:55:27,945: Fetching data for query agg_customers:
create or replace table `template`.`agg_customers`
  
  as (
    SELECT 
account,
store,
id,
created_at,
first_name,
last_name,
email,
split(email,'@')[SAFE_ORDINAL(2)] email_domain
FROM
`growth-engines-pipeline`.`template`.`shopify_customers_proc`
  );

    
2018-07-30 15:55:28,544: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 15:55:28,853: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 15:55:28,854: Fetching data for query shopify_products_proc:
create or replace table `template`.`shopify_products_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`





with products as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	product_name,
	lower(product_type) product_type,
	product_id,
	sku,
	id variant_id,
	cast(created_at as date) created_at,
	_sdc_sequence,
	first_value(_sdc_sequence) OVER (PARTITION BY product_id ORDER BY _sdc_sequence DESC) lv
	FROM (
		SELECT
		variants,
		product_type,
		title product_name,
		_sdc_sequence
		FROM `growth-engines-pipeline.shopify_lucadanni.products` 
		)
	cross join unnest(variants)
	
	

)

SELECT
b.account,
b.store,
b.platform,
max(product_type) product_type,
product_id,
variant_id,
sku,
created_at,
product_name
FROM products a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence
group by product_id, account, store, platform, sku, variant_id, created_at, product_name


  );

    
2018-07-30 15:55:29,157: Writing injected SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 15:55:29,350: Writing runtime SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 15:55:29,351: Fetching data for query ga_transactions:
create or replace table `template`.`ga_transactions`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`,`growth-engines-pipeline`.`template`.`mappings_ga_proc`




with ga_report as (

	    
	    	
		   	SELECT
		   	'yandy' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_yandy.report` 

		     UNION ALL 
	   
	    	
		   	SELECT
		   	'lucadanni' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_lucadanni.report` 

		    
	   

)


SELECT  
date,
b.store store,
c.source source,
c.medium medium,
a.campaign campaign,
concat(a.source, ' / ', a.medium) source_medium,  
case when c.platform is null then "Unmapped" else c.platform end as platform,
case when c.channel is null then "Unmapped" else c.channel end as channel,
url,
transactionid
FROM (

	SELECT 
	store_name,
	lookup_platform,
	date,
	transactionid,
	max(url) url,
	max(source) source,
	max(medium) medium,
	max(campaign) campaign
	FROM ga_report
	where lv = _sdc_sequence
	group by store_name, lookup_platform, date, transactionid

) a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name 
	AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`mappings_ga_proc` c
ON ( a.source = c.source
  AND a.medium = c.medium 
  AND a.store_name = c.store_name )


  );

    
2018-07-30 15:55:31,288: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd4a9b0>]}
2018-07-30 15:55:31,613: 15:55:31 | 9 of 23 OK created table model template.shopify_products_proc........ [OK in 3.85s]
2018-07-30 15:55:32,010: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088827b8>]}
2018-07-30 15:55:32,312: 15:55:32 | 8 of 23 OK created table model template.agg_customers................ [OK in 4.59s]
2018-07-30 15:55:55,292: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd9fef0>]}
2018-07-30 15:55:55,927: 15:55:55 | 10 of 23 OK created table model template.ga_transactions............. [OK in 27.85s]
2018-07-30 15:55:55,928: 15:55:55 | 11 of 23 START table model template.shopify_orders_proc.............. [RUN]
2018-07-30 15:55:55,929: Compiling model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 15:55:55,948: Acquiring new bigquery connection "shopify_orders_proc".
2018-07-30 15:55:55,949: Re-using an available connection from the pool.
2018-07-30 15:55:55,949: Fetching data for query shopify_orders_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 15:55:56,720: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 15:55:56,896: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 15:55:56,897: Fetching data for query shopify_orders_proc:
create or replace table `template`.`shopify_orders_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`, `growth-engines-pipeline`.`template`.`shopify_discounts_proc`





with orders as (

	
	SELECT 
	store_name,
	lookup_platform,
	created_at,
	order_number,
	quantity,
	price, 
	total_order_price_undiscounted,
	total_discounts,
	total_order_shipping_price,
	total_order_price_incl_shipping,
	checkout_id,
	product_id, 
	landing_site,
	sku, 
	variant_title, 
	variant_id,
	line_item_id,
	customer_id,
	_sdc_sequence,
	lv
	FROM (

		SELECT
		'lucadanni' store_name,
		'Shopify' as lookup_platform,
		created_at,
		order_number,
		quantity,
		cast(pre_tax_price as float64) price, 
		total_line_items_price total_order_price_undiscounted,
		total_discounts,
		cast(discounted_price as float64) total_order_shipping_price,
		total_price_usd total_order_price_incl_shipping,
		checkout_id,
		product_id, 
		landing_site,
		sku, 
		variant_title, 
		variant_id,
		_id line_item_id,
		customer.id customer_id,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(line_items), unnest(shipping_lines)
		where source_name != 'shopify_draft_order'
	)
	
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
a.order_number,
a.quantity prelim_quantity,
c.quantity refund_quantity,
case when c.quantity is not null then a.quantity - c.quantity else a.quantity end as quantity,
price prelim_revenue, 
total_order_price_undiscounted,
total_discounts,
trim(lower(d.discount_code)) discount_code,
d.discount_type,
total_order_shipping_price,
total_order_price_incl_shipping,
refund_amount,
case when refund_amount is not null then price - refund_amount else price end as revenue,
a.checkout_id,
a.product_id, 
landing_site,
sku, 
variant_title, 
a.variant_id,
a.line_item_id,	
customer_id
FROM orders a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_refunds_proc` c
ON ( a.order_number = c.order_number
	AND a.line_item_id = c.line_item_id
	AND a.store_name = c.store_name )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_discounts_proc` d
ON ( a.order_number = d.order_number 
    AND a.store_name = d.store_name )  	
where a.lv = a._sdc_sequence


  );

    
2018-07-30 15:56:07,846: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bca3da0>]}
2018-07-30 15:56:08,163: 15:56:08 | 11 of 23 OK created table model template.shopify_orders_proc......... [OK in 11.92s]
2018-07-30 15:56:08,164: 15:56:08 | 12 of 23 START table model template.transaction_by_order_number...... [RUN]
2018-07-30 15:56:08,165: Compiling model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 15:56:08,175: Writing injected SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 15:56:08,178: Acquiring new bigquery connection "transaction_by_order_number".
2018-07-30 15:56:08,178: Re-using an available connection from the pool.
2018-07-30 15:56:08,319: Writing runtime SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 15:56:08,323: Fetching data for query transaction_by_order_number:
create or replace table `template`.`transaction_by_order_number`
  
  as (
    SELECT
store,
cast(created_at as date) order_date,
order_number,
customer_id,
sum(quantity) quantity,
sum(revenue) revenue,
max(total_order_shipping_price) shipping_price
FROM
`growth-engines-pipeline`.`template`.`shopify_orders_proc`
GROUP BY store, order_date, order_number, customer_id
  );

    
2018-07-30 15:56:12,301: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108910748>]}
2018-07-30 15:56:13,631: 15:56:13 | 12 of 23 OK created table model template.transaction_by_order_number. [OK in 4.14s]
2018-07-30 15:56:13,632: 15:56:13 | 13 of 23 START table model template.customers_by_transaction......... [RUN]
2018-07-30 15:56:13,632: Compiling model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 15:56:13,638: Writing injected SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 15:56:13,639: Acquiring new bigquery connection "customers_by_transaction".
2018-07-30 15:56:13,639: Re-using an available connection from the pool.
2018-07-30 15:56:13,881: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 15:56:13,881: Fetching data for query customers_by_transaction:
create or replace table `template`.`customers_by_transaction`
  
  as (
    SELECT
store,
customer_id,
order_number,
order_date,
recent_order_date,
first_order_date,
case when first_order_number = order_number then 'New'
	when date_diff(order_date, recent_order_date, DAY) <= 365 then 'Repeat'
	when date_diff(order_date, recent_order_date, DAY) > 365 then 'Reactivated'
 else '' end as order_type,
quantity,
revenue,
1 as orders,
first_order_revenue,
lifetime_revenue
FROM

(

	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	quantity,
	revenue,
	lag(order_date) over w1 recent_order_date,
	first_value(order_date) over w1 first_order_date,
	first_value(order_number) over w1 first_order_number,
	first_value(revenue) over w1 first_order_revenue,
	sum(revenue) over w2 lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`transaction_by_order_number`
	WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc),
	w2 as (PARTITION BY store, customer_id)
)
  );

    
2018-07-30 15:56:17,859: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bca3da0>]}
2018-07-30 15:56:18,165: 15:56:18 | 13 of 23 OK created table model template.customers_by_transaction.... [OK in 4.23s]
2018-07-30 15:56:18,166: 15:56:18 | 14 of 23 START table model template.agg_transactions................. [RUN]
2018-07-30 15:56:18,167: Compiling model.shopify_cohort_analysis.agg_transactions
2018-07-30 15:56:18,176: Writing injected SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 15:56:18,180: Acquiring new bigquery connection "agg_transactions".
2018-07-30 15:56:18,180: Re-using an available connection from the pool.
2018-07-30 15:56:18,321: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 15:56:18,321: Fetching data for query agg_transactions:
create or replace table `template`.`agg_transactions`
  
  as (
    with ga_transaction as (

	SELECT
	date, 
	store,
	transactionid,
	channel,
	platform,
	url,
	campaign
	FROM `growth-engines-pipeline`.`template`.`ga_transactions`
),

customers_by_transaction as (
	
	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	first_order_date,
	recent_order_date,
	order_type,
	quantity,
	revenue,
	orders,
	first_order_revenue,
	lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`customers_by_transaction`
)

SELECT
store,
customer_id,
order_number,
transactionid,
order_date,
first_order_date,
format_date("%Y-%m", first_order_date) AS first_order_month,
order_type,
first_order_revenue,
lifetime_revenue,
first_value(channel) over w1 as first_order_channel,
first_value(platform) over w1 as first_order_platform,
channel,
platform,
url,
campaign,
quantity,
revenue,
orders
FROM (

	SELECT
	a.store,
	a.customer_id,
	a.order_number,
	b.transactionid,
	a.order_date, 
	a.first_order_date, 
	a.order_type,
	a.first_order_revenue,
	a.lifetime_revenue,
	b.channel,
	b.platform,
	b.url,
	b.campaign,
	a.quantity,
	a.revenue,
	a.orders
	FROM customers_by_transaction a
	LEFT JOIN ga_transaction b
	ON (
	    a.store = b.store AND
	    a.order_number = b.transactionid
	)	
)
WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc)
  );

    
2018-07-30 15:56:26,929: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bde6630>]}
2018-07-30 15:56:27,221: 15:56:27 | 14 of 23 OK created table model template.agg_transactions............ [OK in 8.76s]
2018-07-30 15:56:27,222: 15:56:27 | 15 of 23 START table model template.customers_proc_yoy............... [RUN]
2018-07-30 15:56:27,222: Compiling model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 15:56:27,232: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 15:56:27,232: 15:56:27 | 16 of 23 START table model template.monthly_cohort_stats............. [RUN]
2018-07-30 15:56:27,232: 15:56:27 | 17 of 23 START table model template.customers_proc_qoq............... [RUN]
2018-07-30 15:56:27,232: Compiling model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 15:56:27,233: Compiling model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 15:56:27,250: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 15:56:27,256: Acquiring new bigquery connection "customers_proc_qoq".
2018-07-30 15:56:27,256: Re-using an available connection from the pool.
2018-07-30 15:56:27,260: Writing injected SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 15:56:27,262: Acquiring new bigquery connection "customers_proc_yoy".
2018-07-30 15:56:27,263: Re-using an available connection from the pool.
2018-07-30 15:56:27,276: Acquiring new bigquery connection "monthly_cohort_stats".
2018-07-30 15:56:27,277: Re-using an available connection from the pool.
2018-07-30 15:56:27,434: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 15:56:27,440: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 15:56:27,454: Fetching data for query customers_proc_yoy:
create or replace table `template`.`customers_proc_yoy`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 365 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 365 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 365 window_end_unix_date, 
    unix_date_in_range - 730 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 730 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 365 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 15:56:27,463: Writing runtime SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 15:56:27,463: Fetching data for query customers_proc_qoq:
create or replace table `template`.`customers_proc_qoq`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 90 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 90 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 90 window_end_unix_date, 
    unix_date_in_range - 180 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 180 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 90 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 15:56:27,467: Fetching data for query monthly_cohort_stats:
create or replace table `template`.`monthly_cohort_stats`
  
  as (
    WITH transactions AS (

  SELECT 
  store, 
  order_number,
  order_date,
  order_type,
  first_order_month,
  unix_date(order_date) d, 
  customer_id, 
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (

  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT 
date_in_range date,
store, 
order_type,
first_order_channel,
first_order_platform,
first_order_month,
channel,
platform,
url,
campaign,
count(distinct(customer_id)) buyers,
sum(orders) orders,
sum(quantity) quantity,
sum(revenue) revenue
FROM daterange
JOIN transactions
ON transactions.d >= daterange.unix_date_in_range_bom 
AND transactions.d <= daterange.unix_date_in_range
GROUP BY date, store, order_type, 
first_order_channel, first_order_platform, first_order_month, channel, platform, url, campaign
  );

    
2018-07-30 15:56:32,225: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd128d0>]}
2018-07-30 15:56:32,901: 15:56:32 | 16 of 23 OK created table model template.monthly_cohort_stats........ [OK in 4.99s]
2018-07-30 15:56:38,978: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd22208>]}
2018-07-30 15:56:39,329: 15:56:39 | 17 of 23 OK created table model template.customers_proc_qoq.......... [OK in 11.75s]
2018-07-30 15:56:49,194: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bca3da0>]}
2018-07-30 15:56:49,489: 15:56:49 | 15 of 23 OK created table model template.customers_proc_yoy.......... [OK in 21.97s]
2018-07-30 15:56:49,491: 15:56:49 | 18 of 23 START table model template.customers_proc................... [RUN]
2018-07-30 15:56:49,491: Compiling model.shopify_cohort_analysis.customers_proc
2018-07-30 15:56:49,508: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 15:56:49,512: Acquiring new bigquery connection "customers_proc".
2018-07-30 15:56:49,513: Re-using an available connection from the pool.
2018-07-30 15:56:49,646: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 15:56:49,646: Fetching data for query customers_proc:
create or replace table `template`.`customers_proc`
  
  as (
    SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_qoq`

UNION ALL

SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_yoy`
  );

    
2018-07-30 15:57:18,354: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089210b8>]}
2018-07-30 15:57:19,238: 15:57:19 | 18 of 23 OK created table model template.customers_proc.............. [OK in 28.86s]
2018-07-30 15:57:19,240: 15:57:19 | 19 of 23 START table model template.segment_proc_buyers.............. [RUN]
2018-07-30 15:57:19,241: Compiling model.shopify_cohort_analysis.segment_proc_buyers
2018-07-30 15:57:19,254: Writing injected SQL for node "model.shopify_cohort_analysis.segment_proc_buyers"
2018-07-30 15:57:19,257: Acquiring new bigquery connection "segment_proc_buyers".
2018-07-30 15:57:19,257: Re-using an available connection from the pool.
2018-07-30 15:57:19,408: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_proc_buyers"
2018-07-30 15:57:19,409: Fetching data for query segment_proc_buyers:
create or replace table `template`.`segment_proc_buyers`
  
  as (
    SELECT
store,
period,
customer_id,
date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct,
case when first_order_unix_date >= window_start_unix_date then 'New'
	else 'Existing' end as newness_segment,
case when revenue >= revenue_90pct then 'Top 10%'
	when revenue <= revenue_10pct then 'Bottom 10%'
	else 'Middle 80%' end as revenue_segment,
case when frequency = 1 then '1'
	when frequency = 2 then '2'
	when frequency > 2 then '3+'
	else null end as frequency_segment
FROM `growth-engines-pipeline`.`template`.`customers_proc`
  );

    
2018-07-30 15:57:52,797: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bca3da0>]}
2018-07-30 15:57:53,162: 15:57:53 | 19 of 23 OK created table model template.segment_proc_buyers......... [OK in 33.55s]
2018-07-30 15:57:53,164: 15:57:53 | 20 of 23 START table model template.segment_stats_buyers_agg......... [RUN]
2018-07-30 15:57:53,165: Compiling model.shopify_cohort_analysis.segment_stats_buyers_agg
2018-07-30 15:57:53,190: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_agg"
2018-07-30 15:57:53,193: Acquiring new bigquery connection "segment_stats_buyers_agg".
2018-07-30 15:57:53,194: Re-using an available connection from the pool.
2018-07-30 15:57:53,344: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_agg"
2018-07-30 15:57:53,345: Fetching data for query segment_stats_buyers_agg:
create or replace table `template`.`segment_stats_buyers_agg`
  
  as (
    WITH ty as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev,
	0 as retention_eligible,
	case when newness_segment = 'Existing' then 1 else 0 end as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Year'

),

this_month_1yr as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment,
	frequency_segment,
	newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	recency_days as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev,
	1 as retention_eligible,
	0 as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Previous Year'

),

this_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,	
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment,
	frequency_segment,
	newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev,
	0 as retention_eligible,
	case when newness_segment = 'Existing' then 1 else 0 end as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Quarter'

),

last_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	recency_days as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev,
	1 as retention_eligible,
	0 as retention_success
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Previous Quarter'

)

SELECT
store,
period,
date, 
customer_id,
case when sum(revenue) > 0 then 1 else 0 end as buyers,
first_order_channel,
first_order_platform,	
revenue_segment,
frequency_segment,
newness_segment,	
ifnull(sum(recency), 0) recency,
ifnull(sum(frequency), 0) frequency,
ifnull(sum(revenue), 0) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else 0 end as aov,
ifnull(sum(recency_prev), 0) recency_prev,
ifnull(sum(frequency_prev), 0) frequency_prev,
ifnull(sum(revenue_prev), 0) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else 0 end as aov_prev,
sum(retention_eligible) retention_eligible,
sum(retention_success) retention_success
FROM
(
	SELECT * FROM ty
	UNION ALL
	SELECT * FROM this_month_1yr
	UNION ALL
	SELECT * FROM this_quarter
	UNION ALL
	SELECT * FROM last_quarter

)
GROUP BY store, period, date, customer_id, first_order_channel, first_order_platform,
revenue_segment, frequency_segment, newness_segment
  );

    
2018-07-30 15:58:34,979: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a1fe048>]}
2018-07-30 15:58:37,167: 15:58:37 | 20 of 23 OK created table model template.segment_stats_buyers_agg.... [OK in 41.81s]
2018-07-30 15:58:37,169: 15:58:37 | 21 of 23 START table model template.segment_stats_buyers_view........ [RUN]
2018-07-30 15:58:37,170: Compiling model.shopify_cohort_analysis.segment_stats_buyers_view
2018-07-30 15:58:37,198: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_view"
2018-07-30 15:58:37,205: Acquiring new bigquery connection "segment_stats_buyers_view".
2018-07-30 15:58:37,206: Re-using an available connection from the pool.
2018-07-30 15:58:37,829: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_view"
2018-07-30 15:58:37,830: Fetching data for query segment_stats_buyers_view:
create or replace table `template`.`segment_stats_buyers_view`
  
  as (
    SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Total' as segment_type,
'Total' as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Total' as segment_type,
'Total' as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Total' as segment_type,
'Total' as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type
  );

    
2018-07-30 15:58:43,127: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bca3da0>]}
2018-07-30 15:58:43,436: 15:58:43 | 21 of 23 OK created table model template.segment_stats_buyers_view... [OK in 5.96s]
2018-07-30 15:58:43,439: 15:58:43 | 22 of 23 START table model template.buyer_segment_stats.............. [RUN]
2018-07-30 15:58:43,439: Compiling model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 15:58:43,451: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 15:58:43,453: Acquiring new bigquery connection "buyer_segment_stats".
2018-07-30 15:58:43,453: Re-using an available connection from the pool.
2018-07-30 15:58:44,007: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 15:58:44,008: Fetching data for query buyer_segment_stats:
create or replace table `template`.`buyer_segment_stats`
  
  as (
    SELECT
store,
period,
date,
view,
view_segment,
segment_type,
segment,
buyers,
total_view_buyers,
case when ( total_segment_buyers / total_buyers ) > 0 
	then ( buyers / total_view_buyers ) / ( total_segment_buyers / total_buyers ) 
	else null end as segment_buyer_index,
recency,
orders,
case when buyers > 0 then orders / buyers else null end as frequency,
revenue,
case when total_revenue > 0 then revenue / total_revenue else null end as pct_of_revenue,
revenue_prev,
total_view_revenue,
case when ( total_segment_revenue / total_revenue ) > 0 
	then ( revenue / total_view_revenue ) / ( total_segment_revenue / total_revenue ) 
	else null end as segment_revenue_index,
aov,
recency_growth,
frequency_growth,
revenue_growth,
aov_growth,
retention_rate
FROM (

	SELECT
	store,
	period,
	date,
	view,
	view_segment,
	segment_type,
	segment,
	buyers,
	sum(buyers) over w1 as total_view_buyers,
	sum(buyers) over w2 as total_segment_buyers,
	sum(buyers) over w3 as total_buyers,
	recency,
	frequency orders,
	revenue,
	sum(revenue) over w1 as total_view_revenue,
	sum(revenue) over w2 as total_segment_revenue,
	sum(revenue) over w3 as total_revenue,
	aov,
	case when recency_prev > 0 then ( recency_prev - recency ) / recency_prev else null end as recency_growth,
	case when frequency_prev > 0 then ( frequency - frequency_prev ) / frequency_prev else null end as frequency_growth,
	revenue_prev,
	case when revenue_prev > 0 then ( revenue - revenue_prev ) / revenue_prev else null end as revenue_growth,
	case when aov_prev > 0 then ( aov - aov_prev ) / aov_prev else null end as aov_growth,
	retention_rate
	FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_view`
	WINDOW w1 as (PARTITION BY store, period, date, segment_type, view, view_segment),
	w2 as (PARTITION BY store, period, date, segment_type, view, segment),
	w3 as (PARTITION BY store, period, date, segment_type, view)
)
  );

    
2018-07-30 15:58:46,680: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a1fe048>]}
2018-07-30 15:58:47,623: 15:58:47 | 22 of 23 OK created table model template.buyer_segment_stats......... [OK in 3.24s]
2018-07-30 15:58:47,623: 15:58:47 | 23 of 23 START table model template.buyer_segment_lists.............. [RUN]
2018-07-30 15:58:47,624: Compiling model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 15:58:47,635: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 15:58:47,638: Acquiring new bigquery connection "buyer_segment_lists".
2018-07-30 15:58:47,638: Re-using an available connection from the pool.
2018-07-30 15:58:48,132: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 15:58:48,133: Fetching data for query buyer_segment_lists:
create or replace table `template`.`buyer_segment_lists`
  
  as (
    with buyer_lists as (

	SELECT
	a.store,
	period,
	date,
	customer_id,
	b.first_name,
	b.last_name,
	b.email,
	recency,
	frequency,
	revenue,
	aov,
	revenue_segment,
	frequency_segment
	FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg` a
	LEFT JOIN `growth-engines-pipeline`.`template`.`agg_customers` b
	ON (
		a.store = b.store AND
		a.customer_id = b.id
	)
	where ( revenue_segment != '' or frequency_segment != '' )
)

SELECT
store,
period,
date,
'Revenue' as segment_type,
revenue_segment as segment,
customer_id,
first_name,
last_name,
email,
recency,
frequency,
revenue,
aov
FROM buyer_lists

UNION ALL

SELECT
store,
period,
date,
'Frequency' as segment_type,
frequency_segment as segment,
customer_id,
first_name,
last_name,
email,
recency,
frequency,
revenue,
aov
FROM buyer_lists
  );

    
2018-07-30 15:59:27,394: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5208af38-e9af-4807-ba68-54ee5f9df44b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bca3da0>]}
2018-07-30 15:59:27,718: 15:59:27 | 23 of 23 OK created table model template.buyer_segment_lists......... [OK in 39.77s]
2018-07-30 15:59:27,818: 15:59:27 | 
2018-07-30 15:59:27,818: 15:59:27 | Finished running 23 table models in 254.41s.
2018-07-30 15:59:27,818: Connection 'master' was left open.
2018-07-30 15:59:27,818: 
2018-07-30 15:59:27,819: Completed successfully
2018-07-30 15:59:27,819: 
Done. PASS=23 ERROR=0 SKIP=0 TOTAL=23
2018-07-30 15:59:27,822: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c6f470>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bcbb4a8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bcfe518>]}
2018-07-30 15:59:28,121: Flushing usage events
2018-07-30 15:59:28,392: sys:1: ResourceWarning: unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57980), raddr=('172.217.1.202', 443)>

2018-07-30 15:59:28,394: sys:1: ResourceWarning: unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57979), raddr=('172.217.2.13', 443)>

2018-07-30 15:59:28,395: sys:1: ResourceWarning: unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57987), raddr=('172.217.11.234', 443)>

2018-07-30 15:59:28,397: sys:1: ResourceWarning: unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57985), raddr=('172.217.11.234', 443)>

2018-07-30 15:59:28,400: sys:1: ResourceWarning: unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57981), raddr=('172.217.2.13', 443)>

2018-07-30 15:59:28,401: sys:1: ResourceWarning: unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57982), raddr=('172.217.2.13', 443)>

2018-07-30 15:59:28,402: sys:1: ResourceWarning: unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57986), raddr=('172.217.11.234', 443)>

2018-07-30 15:59:28,403: sys:1: ResourceWarning: unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57988), raddr=('172.217.11.234', 443)>

2018-07-30 15:59:28,406: sys:1: ResourceWarning: unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57983), raddr=('172.217.2.13', 443)>

2018-07-30 15:59:28,406: sys:1: ResourceWarning: unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 57984), raddr=('172.217.2.13', 443)>

2018-07-30 16:06:42,246: Tracking: tracking
2018-07-30 16:06:42,251: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113ed4198>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113ed4a20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113ed4f60>]}
2018-07-30 16:06:43,161: Loading dependency project from /usr/local/Cellar/dbt/0.10.1/libexec/lib/python3.6/site-packages/dbt/include
2018-07-30 16:06:43,201: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/shopify-cohort-analysis/dbt_modules
2018-07-30 16:06:43,210: Parsing get_column_values.sql
2018-07-30 16:06:43,230: Parsing get_url_parameter.sql
2018-07-30 16:06:43,240: Parsing split_part.sql
2018-07-30 16:06:43,252: Parsing table_exists.sql
2018-07-30 16:06:43,264: Parsing core.sql
2018-07-30 16:06:43,284: Parsing adapters/bigquery.sql
2018-07-30 16:06:43,297: Parsing adapters/common.sql
2018-07-30 16:06:43,324: Parsing adapters/redshift.sql
2018-07-30 16:06:43,353: Parsing adapters/snowflake.sql
2018-07-30 16:06:43,362: Parsing etc/bigquery.sql
2018-07-30 16:06:43,367: Parsing etc/datetime.sql
2018-07-30 16:06:43,396: Parsing etc/get_custom_schema.sql
2018-07-30 16:06:43,410: Parsing materializations/helpers.sql
2018-07-30 16:06:43,440: Parsing materializations/archive/archive.sql
2018-07-30 16:06:43,486: Parsing materializations/incremental/incremental.sql
2018-07-30 16:06:43,531: Parsing materializations/seed/bigquery.sql
2018-07-30 16:06:43,541: Parsing materializations/seed/seed.sql
2018-07-30 16:06:43,598: Parsing materializations/table/bigquery_table.sql
2018-07-30 16:06:43,630: Parsing materializations/table/table.sql
2018-07-30 16:06:43,658: Parsing materializations/view/bigquery_view.sql
2018-07-30 16:06:43,674: Parsing materializations/view/view.sql
2018-07-30 16:06:43,699: Parsing schema_tests/accepted_values.sql
2018-07-30 16:06:43,706: Parsing schema_tests/not_null.sql
2018-07-30 16:06:43,711: Parsing schema_tests/relationships.sql
2018-07-30 16:06:43,718: Parsing schema_tests/unique.sql
2018-07-30 16:06:43,757: Parsing model.shopify_cohort_analysis.all_dates
2018-07-30 16:06:43,759: Parsing model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 16:06:43,762: Parsing model.shopify_cohort_analysis.monthend_dates
2018-07-30 16:06:43,765: Parsing model.shopify_cohort_analysis.stores_proc
2018-07-30 16:06:43,769: Parsing model.shopify_cohort_analysis.ga_transactions
2018-07-30 16:06:43,782: Parsing model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 16:06:43,795: Parsing model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 16:06:43,802: Parsing model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 16:06:43,813: Parsing model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 16:06:43,822: Parsing model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 16:06:43,830: Parsing model.shopify_cohort_analysis.agg_customers
2018-07-30 16:06:43,833: Parsing model.shopify_cohort_analysis.agg_transactions
2018-07-30 16:06:43,837: Parsing model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 16:06:43,841: Parsing model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 16:06:43,844: Parsing model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 16:06:43,848: Parsing model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 16:06:43,854: Parsing model.shopify_cohort_analysis.customers_proc
2018-07-30 16:06:43,858: Parsing model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 16:06:43,862: Parsing model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 16:06:43,870: Parsing model.shopify_cohort_analysis.segment_proc_buyers
2018-07-30 16:06:43,873: Parsing model.shopify_cohort_analysis.segment_stats_buyers_agg
2018-07-30 16:06:43,878: Parsing model.shopify_cohort_analysis.segment_stats_buyers_view
2018-07-30 16:06:43,890: Parsing model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 16:06:43,909: Found 23 models, 0 tests, 0 archives, 0 analyses, 62 macros, 0 operations, 0 seed files
2018-07-30 16:06:43,919: 
2018-07-30 16:06:43,927: Acquiring new bigquery connection "master".
2018-07-30 16:06:43,928: Opening a new connection (0 currently allocated)
2018-07-30 16:06:45,240: 16:06:45 | Concurrency: 4 threads (target='template')
2018-07-30 16:06:45,240: 16:06:45 | 
2018-07-30 16:06:45,324: 16:06:45 | 1 of 23 START table model template.monthend_dates.................... [RUN]
2018-07-30 16:06:45,324: 16:06:45 | 2 of 23 START table model template.stores_proc....................... [RUN]
2018-07-30 16:06:45,324: Compiling model.shopify_cohort_analysis.monthend_dates
2018-07-30 16:06:45,324: 16:06:45 | 3 of 23 START table model template.all_dates......................... [RUN]
2018-07-30 16:06:45,325: Compiling model.shopify_cohort_analysis.stores_proc
2018-07-30 16:06:45,324: 16:06:45 | 4 of 23 START table model template.mappings_ga_proc.................. [RUN]
2018-07-30 16:06:45,330: Writing injected SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 16:06:45,330: Compiling model.shopify_cohort_analysis.all_dates
2018-07-30 16:06:45,336: Compiling model.shopify_cohort_analysis.mappings_ga_proc
2018-07-30 16:06:45,337: Writing injected SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 16:06:45,342: Writing injected SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 16:06:45,347: Writing injected SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 16:06:45,352: Acquiring new bigquery connection "monthend_dates".
2018-07-30 16:06:45,352: Opening a new connection (1 currently allocated)
2018-07-30 16:06:45,354: Acquiring new bigquery connection "mappings_ga_proc".
2018-07-30 16:06:45,357: Acquiring new bigquery connection "stores_proc".
2018-07-30 16:06:45,359: Acquiring new bigquery connection "all_dates".
2018-07-30 16:06:45,361: Opening a new connection (2 currently allocated)
2018-07-30 16:06:45,375: Opening a new connection (3 currently allocated)
2018-07-30 16:06:45,381: Opening a new connection (4 currently allocated)
2018-07-30 16:06:45,831: Writing runtime SQL for node "model.shopify_cohort_analysis.monthend_dates"
2018-07-30 16:06:45,841: Writing runtime SQL for node "model.shopify_cohort_analysis.mappings_ga_proc"
2018-07-30 16:06:45,848: Fetching data for query monthend_dates:
create or replace table `template`.`monthend_dates`
  
  as (
    SELECT
date_in_range,
date_in_range_bom,
date_in_range_bom_mom,
unix_date_in_range,
unix_date_in_range_bom,
unix_date(date_in_range_bom_mom) unix_date_in_range_bom_mom,
yyyymm,
date_in_range_yoy,
unix_date(date_in_range_yoy) unix_date_in_range_yoy

FROM
(
	SELECT 
	date_in_range,
	date_in_range_bom,
	date_sub(date_in_range_bom, INTERVAL 1 MONTH) date_in_range_bom_mom,
	date_sub(date_in_range, INTERVAL 1 YEAR) date_in_range_yoy,
	unix_date_in_range,
	unix_date(date_in_range_bom) unix_date_in_range_bom,
	yyyymm,
	first_value(date_in_range) over (partition by yyyymm order by date_in_range desc) monthend_date_in_range
	FROM
	( 
		SELECT 
		date_in_range,
		date_trunc( date_in_range, MONTH) date_in_range_bom,
		unix_date(date_in_range) unix_date_in_range,
		format_date("%Y-%m", date_in_range) AS yyyymm
		FROM UNNEST(
		    GENERATE_DATE_ARRAY(DATE('2016-01-31'), CURRENT_DATE(), INTERVAL 1 DAY)
		) AS date_in_range
	)
)
where date_in_range = monthend_date_in_range
  );

    
2018-07-30 16:06:45,851: Writing runtime SQL for node "model.shopify_cohort_analysis.all_dates"
2018-07-30 16:06:45,852: Fetching data for query mappings_ga_proc:
create or replace table `template`.`mappings_ga_proc`
  
  as (
    select 
store,
account,
store_name,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client store,
account,
client_name store_name,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.mappings_ga` 

) 

WHERE lv = time_of_entry
group by store, account, store_name, source, medium, platform_n, channel_n, time_of_entry
  );

    
2018-07-30 16:06:45,864: Writing runtime SQL for node "model.shopify_cohort_analysis.stores_proc"
2018-07-30 16:06:45,867: Fetching data for query all_dates:
create or replace table `template`.`all_dates`
  
  as (
    SELECT 
date_in_range,
unix_date(date_in_range) unix_date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
  );

    
2018-07-30 16:06:45,872: Fetching data for query stores_proc:
create or replace table `template`.`stores_proc`
  
  as (
    select 
store,
store_name,
account,
platform,
max(time_of_entry) time_of_entry

from  ( 

SELECT  
client store,
client_name store_name,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client ORDER BY time_of_entry DESC) lv
FROM `growth-engines-pipeline.agency_data_pipeline.accounts` 
where client_name != ''

) 

WHERE lv = time_of_entry
group by store, store_name, account, platform
  );

    
2018-07-30 16:06:47,339: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140620b8>]}
2018-07-30 16:06:47,502: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114062e48>]}
2018-07-30 16:06:47,521: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114062470>]}
2018-07-30 16:06:48,128: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113fd7588>]}
2018-07-30 16:06:48,129: 16:06:48 | 3 of 23 OK created table model template.all_dates.................... [OK in 2.01s]
2018-07-30 16:06:48,914: 16:06:48 | 1 of 23 OK created table model template.monthend_dates............... [OK in 2.18s]
2018-07-30 16:06:49,580: 16:06:49 | 4 of 23 OK created table model template.mappings_ga_proc............. [OK in 2.19s]
2018-07-30 16:06:49,959: 16:06:49 | 2 of 23 OK created table model template.stores_proc.................. [OK in 2.80s]
2018-07-30 16:06:49,960: 16:06:49 | 5 of 23 START table model template.shopify_customers_proc............ [RUN]
2018-07-30 16:06:49,961: Compiling model.shopify_cohort_analysis.shopify_customers_proc
2018-07-30 16:06:49,961: 16:06:49 | 6 of 23 START table model template.shopify_discounts_proc............ [RUN]
2018-07-30 16:06:49,961: 16:06:49 | 7 of 23 START table model template.shopify_refunds_proc.............. [RUN]
2018-07-30 16:06:49,968: Compiling model.shopify_cohort_analysis.shopify_discounts_proc
2018-07-30 16:06:49,968: Compiling model.shopify_cohort_analysis.shopify_refunds_proc
2018-07-30 16:06:49,979: Acquiring new bigquery connection "shopify_customers_proc".
2018-07-30 16:06:49,982: Acquiring new bigquery connection "shopify_discounts_proc".
2018-07-30 16:06:49,992: Acquiring new bigquery connection "shopify_refunds_proc".
2018-07-30 16:06:49,992: Re-using an available connection from the pool.
2018-07-30 16:06:49,992: Fetching data for query shopify_customers_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 16:06:49,992: Re-using an available connection from the pool.
2018-07-30 16:06:49,993: Fetching data for query shopify_discounts_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 16:06:49,993: Re-using an available connection from the pool.
2018-07-30 16:06:49,994: Fetching data for query shopify_refunds_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 16:06:51,619: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 16:06:51,623: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 16:06:51,781: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_refunds_proc"
2018-07-30 16:06:51,782: Fetching data for query shopify_refunds_proc:
create or replace table `template`.`shopify_refunds_proc`
  
  as (
    



with refunds as (

	
	SELECT
	'lucadanni' store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal,
	line_item.variant_id variant_id,
	line_item.id refund_id,
 	_sdc_sequence
	FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
	cross join unnest(refunds), unnest(refund_line_items)
  	where financial_status like '%refund%'
	
	

)

SELECT * 
FROM 
	(
    SELECT
    store_name,
	order_number,
	checkout_id,
	financial_status,
	line_item_id,
	quantity,
	subtotal refund_amount,
	variant_id,
	refund_id,
 	_sdc_sequence,
    first_value(_sdc_sequence) OVER (PARTITION BY order_number, line_item_id ORDER BY _sdc_sequence DESC) lv
    FROM refunds
   	) 
WHERE lv = _sdc_sequence


  );

    
2018-07-30 16:06:51,835: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_customers_proc"
2018-07-30 16:06:51,835: Fetching data for query shopify_customers_proc:
create or replace table `template`.`shopify_customers_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`





with customers as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	created_at,
	id,
	first_name,
	last_name,
	email,
	_sdc_sequence,
	first_value(_sdc_sequence) over (partition by id order by _sdc_sequence desc) lv
	FROM `growth-engines-pipeline.shopify_lucadanni.customers` 
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
id,
first_name,
last_name,
email
FROM customers a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence


  );

    
2018-07-30 16:06:51,912: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 16:06:52,069: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_discounts_proc"
2018-07-30 16:06:52,069: Fetching data for query shopify_discounts_proc:
create or replace table `template`.`shopify_discounts_proc`
  
  as (
    



with orders as (

	
		SELECT
		'lucadanni' store_name,
		created_at,
		order_number,
		code discount_code,
		type discount_type,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(discount_codes)
		where source_name != 'shopify_draft_order'
	
	
	

)

SELECT
store_name,
order_number,
discount_code,
discount_type
FROM orders
where lv = _sdc_sequence


  );

    
2018-07-30 16:06:54,030: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127f8390>]}
2018-07-30 16:06:54,180: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110ca57b8>]}
2018-07-30 16:06:54,327: 16:06:54 | 7 of 23 OK created table model template.shopify_refunds_proc......... [OK in 4.06s]
2018-07-30 16:06:54,632: 16:06:54 | 6 of 23 OK created table model template.shopify_discounts_proc....... [OK in 4.21s]
2018-07-30 16:06:56,901: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140ea588>]}
2018-07-30 16:06:57,675: 16:06:57 | 5 of 23 OK created table model template.shopify_customers_proc....... [OK in 6.94s]
2018-07-30 16:06:57,676: 16:06:57 | 8 of 23 START table model template.agg_customers..................... [RUN]
2018-07-30 16:06:57,676: 16:06:57 | 9 of 23 START table model template.shopify_products_proc............. [RUN]
2018-07-30 16:06:57,677: Compiling model.shopify_cohort_analysis.agg_customers
2018-07-30 16:06:57,676: 16:06:57 | 10 of 23 START table model template.ga_transactions.................. [RUN]
2018-07-30 16:06:57,677: Compiling model.shopify_cohort_analysis.shopify_products_proc
2018-07-30 16:06:57,687: Writing injected SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 16:06:57,688: Compiling model.shopify_cohort_analysis.ga_transactions
2018-07-30 16:06:57,724: Acquiring new bigquery connection "shopify_products_proc".
2018-07-30 16:06:57,725: Re-using an available connection from the pool.
2018-07-30 16:06:57,725: Fetching data for query shopify_products_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 16:06:57,728: Acquiring new bigquery connection "ga_transactions".
2018-07-30 16:06:57,729: Re-using an available connection from the pool.
2018-07-30 16:06:57,729: Fetching data for query ga_transactions:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Google Analytics'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 16:06:57,750: Acquiring new bigquery connection "agg_customers".
2018-07-30 16:06:57,751: Re-using an available connection from the pool.
2018-07-30 16:06:58,021: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_customers"
2018-07-30 16:06:58,024: Fetching data for query agg_customers:
create or replace table `template`.`agg_customers`
  
  as (
    SELECT 
account,
store,
id,
created_at,
first_name,
last_name,
email,
split(email,'@')[SAFE_ORDINAL(2)] email_domain
FROM
`growth-engines-pipeline`.`template`.`shopify_customers_proc`
  );

    
2018-07-30 16:06:58,794: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 16:06:58,983: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_products_proc"
2018-07-30 16:06:58,984: Fetching data for query shopify_products_proc:
create or replace table `template`.`shopify_products_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`





with products as (

	
	SELECT
	'lucadanni' store_name,
	'Shopify' as lookup_platform,
	product_name,
	lower(product_type) product_type,
	product_id,
	sku,
	id variant_id,
	cast(created_at as date) created_at,
	_sdc_sequence,
	first_value(_sdc_sequence) OVER (PARTITION BY product_id ORDER BY _sdc_sequence DESC) lv
	FROM (
		SELECT
		variants,
		product_type,
		title product_name,
		_sdc_sequence
		FROM `growth-engines-pipeline.shopify_lucadanni.products` 
		)
	cross join unnest(variants)
	
	

)

SELECT
b.account,
b.store,
b.platform,
max(product_type) product_type,
product_id,
variant_id,
sku,
created_at,
product_name
FROM products a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
where a.lv = a._sdc_sequence
group by product_id, account, store, platform, sku, variant_id, created_at, product_name


  );

    
2018-07-30 16:06:59,342: Writing injected SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 16:06:59,457: Writing runtime SQL for node "model.shopify_cohort_analysis.ga_transactions"
2018-07-30 16:06:59,457: Fetching data for query ga_transactions:
create or replace table `template`.`ga_transactions`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`,`growth-engines-pipeline`.`template`.`mappings_ga_proc`




with ga_report as (

	    
	    	
		   	SELECT
		   	'yandy' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_yandy.report` 

		     UNION ALL 
	   
	    	
		   	SELECT
		   	'lucadanni' as store_name,
		   	'Google Analytics' as lookup_platform,
			lower(trim(regexp_replace(replace(replace(replace(replace(CONCAT(hostname,landingpagepath),'www.',''),'http://',''),'https://',''),'.html',''),r'\?.*$',''),'/')) as url,
			cast(date as date) date,
			lower(source) source,
			lower(medium) medium,
			lower(replace(replace(replace(campaign,' ', ''),'-',''),'_','')) campaign,
			cast(regexp_replace(transactionid, r'#|B', '') as int64) transactionid,
			_sdc_sequence,
			first_value(_sdc_sequence) OVER (PARTITION BY hostname, landingpagepath, date, source, medium, transactionid ORDER BY _sdc_sequence DESC) lv
			FROM `growth-engines-pipeline.ga_lucadanni.report` 

		    
	   

)


SELECT  
date,
b.store store,
c.source source,
c.medium medium,
a.campaign campaign,
concat(a.source, ' / ', a.medium) source_medium,  
case when c.platform is null then "Unmapped" else c.platform end as platform,
case when c.channel is null then "Unmapped" else c.channel end as channel,
url,
transactionid
FROM (

	SELECT 
	store_name,
	lookup_platform,
	date,
	transactionid,
	max(url) url,
	max(source) source,
	max(medium) medium,
	max(campaign) campaign
	FROM ga_report
	where lv = _sdc_sequence
	group by store_name, lookup_platform, date, transactionid

) a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name 
	AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`mappings_ga_proc` c
ON ( a.source = c.source
  AND a.medium = c.medium 
  AND a.store_name = c.store_name )


  );

    
2018-07-30 16:07:01,114: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140ead30>]}
2018-07-30 16:07:01,423: 16:07:01 | 9 of 23 OK created table model template.shopify_products_proc........ [OK in 3.44s]
2018-07-30 16:07:02,125: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113fd7588>]}
2018-07-30 16:07:02,423: 16:07:02 | 8 of 23 OK created table model template.agg_customers................ [OK in 4.45s]
2018-07-30 16:07:24,348: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113fa16a0>]}
2018-07-30 16:07:25,265: 16:07:25 | 10 of 23 OK created table model template.ga_transactions............. [OK in 26.66s]
2018-07-30 16:07:25,267: 16:07:25 | 11 of 23 START table model template.shopify_orders_proc.............. [RUN]
2018-07-30 16:07:25,267: Compiling model.shopify_cohort_analysis.shopify_orders_proc
2018-07-30 16:07:25,288: Acquiring new bigquery connection "shopify_orders_proc".
2018-07-30 16:07:25,288: Re-using an available connection from the pool.
2018-07-30 16:07:25,291: Fetching data for query shopify_orders_proc:


        select
            store_name as value

        from `growth-engines-pipeline`.`template`.`stores_proc`

        
        ##where 1 = 1
        where platform = 'Shopify'
        
        
        

        group by 1
        order by count(*) desc

        
        limit 50
        
2018-07-30 16:07:26,242: Writing injected SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 16:07:26,406: Writing runtime SQL for node "model.shopify_cohort_analysis.shopify_orders_proc"
2018-07-30 16:07:26,406: Fetching data for query shopify_orders_proc:
create or replace table `template`.`shopify_orders_proc`
  
  as (
    -- depends_on: `growth-engines-pipeline`.`template`.`stores_proc`, `growth-engines-pipeline`.`template`.`shopify_refunds_proc`, `growth-engines-pipeline`.`template`.`shopify_discounts_proc`





with orders as (

	
	SELECT 
	store_name,
	lookup_platform,
	created_at,
	order_number,
	quantity,
	price, 
	total_order_price_undiscounted,
	total_discounts,
	total_order_shipping_price,
	total_order_price_incl_shipping,
	checkout_id,
	product_id, 
	landing_site,
	sku, 
	variant_title, 
	variant_id,
	line_item_id,
	customer_id,
	_sdc_sequence,
	lv
	FROM (

		SELECT
		'lucadanni' store_name,
		'Shopify' as lookup_platform,
		created_at,
		order_number,
		quantity,
		cast(pre_tax_price as float64) price, 
		total_line_items_price total_order_price_undiscounted,
		total_discounts,
		cast(discounted_price as float64) total_order_shipping_price,
		total_price_usd total_order_price_incl_shipping,
		checkout_id,
		product_id, 
		landing_site,
		sku, 
		variant_title, 
		variant_id,
		_id line_item_id,
		customer.id customer_id,
		_sdc_sequence,
		first_value(_sdc_sequence) OVER (PARTITION BY order_number, _id ORDER BY _sdc_sequence DESC) lv
		FROM `growth-engines-pipeline.shopify_lucadanni.orders` 
		cross join unnest(line_items), unnest(shipping_lines)
		where source_name != 'shopify_draft_order'
	)
	
	
	

)

SELECT
b.account,
b.store,
b.platform,
created_at,
a.order_number,
a.quantity prelim_quantity,
c.quantity refund_quantity,
case when c.quantity is not null then a.quantity - c.quantity else a.quantity end as quantity,
price prelim_revenue, 
total_order_price_undiscounted,
total_discounts,
trim(lower(d.discount_code)) discount_code,
d.discount_type,
total_order_shipping_price,
total_order_price_incl_shipping,
refund_amount,
case when refund_amount is not null then price - refund_amount else price end as revenue,
a.checkout_id,
a.product_id, 
landing_site,
sku, 
variant_title, 
a.variant_id,
a.line_item_id,	
customer_id
FROM orders a
LEFT JOIN `growth-engines-pipeline`.`template`.`stores_proc` b 
ON ( a.store_name = b.store_name
  AND a.lookup_platform = b.platform )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_refunds_proc` c
ON ( a.order_number = c.order_number
	AND a.line_item_id = c.line_item_id
	AND a.store_name = c.store_name )
LEFT JOIN `growth-engines-pipeline`.`template`.`shopify_discounts_proc` d
ON ( a.order_number = d.order_number 
    AND a.store_name = d.store_name )  	
where a.lv = a._sdc_sequence


  );

    
2018-07-30 16:07:37,810: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140420f0>]}
2018-07-30 16:07:38,150: 16:07:38 | 11 of 23 OK created table model template.shopify_orders_proc......... [OK in 12.54s]
2018-07-30 16:07:38,152: 16:07:38 | 12 of 23 START table model template.transaction_by_order_number...... [RUN]
2018-07-30 16:07:38,152: Compiling model.shopify_cohort_analysis.transaction_by_order_number
2018-07-30 16:07:38,162: Writing injected SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 16:07:38,164: Acquiring new bigquery connection "transaction_by_order_number".
2018-07-30 16:07:38,164: Re-using an available connection from the pool.
2018-07-30 16:07:38,290: Writing runtime SQL for node "model.shopify_cohort_analysis.transaction_by_order_number"
2018-07-30 16:07:38,293: Fetching data for query transaction_by_order_number:
create or replace table `template`.`transaction_by_order_number`
  
  as (
    SELECT
store,
cast(created_at as date) order_date,
order_number,
customer_id,
sum(quantity) quantity,
sum(revenue) revenue,
max(total_order_shipping_price) shipping_price
FROM
`growth-engines-pipeline`.`template`.`shopify_orders_proc`
GROUP BY store, order_date, order_number, customer_id
  );

    
2018-07-30 16:07:42,298: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d0dac8>]}
2018-07-30 16:07:42,752: 16:07:42 | 12 of 23 OK created table model template.transaction_by_order_number. [OK in 4.15s]
2018-07-30 16:07:42,754: 16:07:42 | 13 of 23 START table model template.customers_by_transaction......... [RUN]
2018-07-30 16:07:42,754: Compiling model.shopify_cohort_analysis.customers_by_transaction
2018-07-30 16:07:42,764: Writing injected SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 16:07:42,766: Acquiring new bigquery connection "customers_by_transaction".
2018-07-30 16:07:42,766: Re-using an available connection from the pool.
2018-07-30 16:07:42,939: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_by_transaction"
2018-07-30 16:07:42,942: Fetching data for query customers_by_transaction:
create or replace table `template`.`customers_by_transaction`
  
  as (
    SELECT
store,
customer_id,
order_number,
order_date,
recent_order_date,
first_order_date,
case when first_order_number = order_number then 'New'
	when date_diff(order_date, recent_order_date, DAY) <= 365 then 'Repeat'
	when date_diff(order_date, recent_order_date, DAY) > 365 then 'Reactivated'
 else '' end as order_type,
quantity,
revenue,
1 as orders,
first_order_revenue,
lifetime_revenue
FROM

(

	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	quantity,
	revenue,
	lag(order_date) over w1 recent_order_date,
	first_value(order_date) over w1 first_order_date,
	first_value(order_number) over w1 first_order_number,
	first_value(revenue) over w1 first_order_revenue,
	sum(revenue) over w2 lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`transaction_by_order_number`
	WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc),
	w2 as (PARTITION BY store, customer_id)
)
  );

    
2018-07-30 16:07:46,794: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140ac2e8>]}
2018-07-30 16:07:48,061: 16:07:48 | 13 of 23 OK created table model template.customers_by_transaction.... [OK in 4.04s]
2018-07-30 16:07:48,062: 16:07:48 | 14 of 23 START table model template.agg_transactions................. [RUN]
2018-07-30 16:07:48,062: Compiling model.shopify_cohort_analysis.agg_transactions
2018-07-30 16:07:48,080: Writing injected SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 16:07:48,083: Acquiring new bigquery connection "agg_transactions".
2018-07-30 16:07:48,084: Re-using an available connection from the pool.
2018-07-30 16:07:48,257: Writing runtime SQL for node "model.shopify_cohort_analysis.agg_transactions"
2018-07-30 16:07:48,258: Fetching data for query agg_transactions:
create or replace table `template`.`agg_transactions`
  
  as (
    with ga_transaction as (

	SELECT
	date, 
	store,
	transactionid,
	channel,
	platform,
	url,
	campaign
	FROM `growth-engines-pipeline`.`template`.`ga_transactions`
),

customers_by_transaction as (
	
	SELECT
	store,
	customer_id,
	order_number,
	order_date,
	first_order_date,
	recent_order_date,
	order_type,
	quantity,
	revenue,
	orders,
	first_order_revenue,
	lifetime_revenue
	FROM `growth-engines-pipeline`.`template`.`customers_by_transaction`
)

SELECT
store,
customer_id,
order_number,
transactionid,
order_date,
first_order_date,
format_date("%Y-%m", first_order_date) AS first_order_month,
order_type,
first_order_revenue,
lifetime_revenue,
first_value(channel) over w1 as first_order_channel,
first_value(platform) over w1 as first_order_platform,
channel,
platform,
url,
campaign,
quantity,
revenue,
orders
FROM (

	SELECT
	a.store,
	a.customer_id,
	a.order_number,
	b.transactionid,
	a.order_date, 
	a.first_order_date, 
	a.order_type,
	a.first_order_revenue,
	a.lifetime_revenue,
	b.channel,
	b.platform,
	b.url,
	b.campaign,
	a.quantity,
	a.revenue,
	a.orders
	FROM customers_by_transaction a
	LEFT JOIN ga_transaction b
	ON (
	    a.store = b.store AND
	    a.order_number = b.transactionid
	)	
)
WINDOW w1 as (PARTITION BY store, customer_id ORDER BY order_date asc)
  );

    
2018-07-30 16:07:56,602: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140ac710>]}
2018-07-30 16:07:57,256: 16:07:57 | 14 of 23 OK created table model template.agg_transactions............ [OK in 8.54s]
2018-07-30 16:07:57,258: 16:07:57 | 15 of 23 START table model template.customers_proc_qoq............... [RUN]
2018-07-30 16:07:57,258: 16:07:57 | 16 of 23 START table model template.monthly_cohort_stats............. [RUN]
2018-07-30 16:07:57,259: Compiling model.shopify_cohort_analysis.customers_proc_qoq
2018-07-30 16:07:57,259: 16:07:57 | 17 of 23 START table model template.customers_proc_yoy............... [RUN]
2018-07-30 16:07:57,259: Compiling model.shopify_cohort_analysis.monthly_cohort_stats
2018-07-30 16:07:57,272: Compiling model.shopify_cohort_analysis.customers_proc_yoy
2018-07-30 16:07:57,278: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 16:07:57,301: Writing injected SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 16:07:57,305: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 16:07:57,312: Acquiring new bigquery connection "monthly_cohort_stats".
2018-07-30 16:07:57,313: Acquiring new bigquery connection "customers_proc_qoq".
2018-07-30 16:07:57,313: Re-using an available connection from the pool.
2018-07-30 16:07:57,315: Acquiring new bigquery connection "customers_proc_yoy".
2018-07-30 16:07:57,316: Re-using an available connection from the pool.
2018-07-30 16:07:57,318: Re-using an available connection from the pool.
2018-07-30 16:07:57,476: Writing runtime SQL for node "model.shopify_cohort_analysis.monthly_cohort_stats"
2018-07-30 16:07:57,509: Fetching data for query monthly_cohort_stats:
create or replace table `template`.`monthly_cohort_stats`
  
  as (
    WITH transactions AS (

  SELECT 
  store, 
  order_number,
  order_date,
  order_type,
  first_order_month,
  unix_date(order_date) d, 
  customer_id, 
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (

  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT 
date_in_range date,
store, 
order_type,
first_order_channel,
first_order_platform,
first_order_month,
channel,
platform,
url,
campaign,
count(distinct(customer_id)) buyers,
sum(orders) orders,
sum(quantity) quantity,
sum(revenue) revenue
FROM daterange
JOIN transactions
ON transactions.d >= daterange.unix_date_in_range_bom 
AND transactions.d <= daterange.unix_date_in_range
GROUP BY date, store, order_type, 
first_order_channel, first_order_platform, first_order_month, channel, platform, url, campaign
  );

    
2018-07-30 16:07:57,529: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_yoy"
2018-07-30 16:07:57,544: Fetching data for query customers_proc_yoy:
create or replace table `template`.`customers_proc_yoy`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 365 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 365 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Year' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 365 window_end_unix_date, 
    unix_date_in_range - 730 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 730 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 365 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 16:07:57,647: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc_qoq"
2018-07-30 16:07:57,681: Fetching data for query customers_proc_qoq:
create or replace table `template`.`customers_proc_qoq`
  
  as (
    WITH customers AS (

  SELECT 
  store,
  customer_id,
  order_date,
  unix_date(order_date) unix_order_date, 
  first_order_date,
  unix_date(first_order_date) first_order_unix_date,
  first_order_revenue,
  first_order_channel,
  first_order_platform,
  channel,
  platform,
  url,
  campaign,
  quantity,
  revenue,
  orders
  FROM `growth-engines-pipeline`.`template`.`agg_transactions`
),

daterange AS (
  SELECT * FROM `growth-engines-pipeline`.`template`.`monthend_dates`    
)

SELECT
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
PERCENTILE_CONT(revenue, 0.90) OVER w1 AS revenue_90pct,
PERCENTILE_CONT(revenue, 0.10) OVER w1 AS revenue_10pct
FROM (
   
  SELECT 
  store,
  period,
  customer_id,
  date,
  window_end_unix_date,
  window_start_unix_date,
  first_order_unix_date,
  window_end_unix_date - unix_date(recent_order) recency_days,
  first_order_channel,
  first_order_platform,
  quantity,
  revenue, 
  frequency
  FROM 
  (  

    SELECT 
    store,
    'Rolling Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range window_end_unix_date, 
    unix_date_in_range - 90 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 90 )
    AND customers.unix_order_date <= daterange.unix_date_in_range
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

    UNION ALL

    SELECT 
    store,
    'Rolling Previous Quarter' as period,
    customer_id,
    date_in_range date,
    unix_date_in_range, 
    unix_date_in_range - 90 window_end_unix_date, 
    unix_date_in_range - 180 window_start_unix_date, 
    first_order_unix_date,
    first_order_channel,
    first_order_platform,
    max(order_date) recent_order,
    sum(quantity) as quantity,
    sum(revenue) as revenue,
    sum(orders) as frequency
    FROM daterange
    JOIN customers
    ON customers.unix_order_date > ( daterange.unix_date_in_range - 180 )
    AND customers.unix_order_date <= ( daterange.unix_date_in_range - 90 )
    GROUP BY store, customer_id, date, unix_date_in_range, window_end_unix_date, 
    window_start_unix_date, first_order_unix_date, first_order_channel, first_order_platform

  )
)
WINDOW w1 as (PARTITION BY store, period, date)
  );

    
2018-07-30 16:08:04,991: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d27908>]}
2018-07-30 16:08:05,661: 16:08:05 | 16 of 23 OK created table model template.monthly_cohort_stats........ [OK in 7.73s]
2018-07-30 16:08:10,119: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140ac2e8>]}
2018-07-30 16:08:10,409: 16:08:10 | 15 of 23 OK created table model template.customers_proc_qoq.......... [OK in 12.86s]
2018-07-30 16:08:19,454: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114020a58>]}
2018-07-30 16:08:19,811: 16:08:19 | 17 of 23 OK created table model template.customers_proc_yoy.......... [OK in 22.18s]
2018-07-30 16:08:19,812: 16:08:19 | 18 of 23 START table model template.customers_proc................... [RUN]
2018-07-30 16:08:19,812: Compiling model.shopify_cohort_analysis.customers_proc
2018-07-30 16:08:19,836: Writing injected SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 16:08:19,847: Acquiring new bigquery connection "customers_proc".
2018-07-30 16:08:19,847: Re-using an available connection from the pool.
2018-07-30 16:08:20,130: Writing runtime SQL for node "model.shopify_cohort_analysis.customers_proc"
2018-07-30 16:08:20,131: Fetching data for query customers_proc:
create or replace table `template`.`customers_proc`
  
  as (
    SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_qoq`

UNION ALL

SELECT 
store,
period,
customer_id,
date,
window_end_unix_date,
window_start_unix_date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct
FROM 
`growth-engines-pipeline`.`template`.`customers_proc_yoy`
  );

    
2018-07-30 16:08:47,685: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140a9ba8>]}
2018-07-30 16:08:48,949: 16:08:48 | 18 of 23 OK created table model template.customers_proc.............. [OK in 27.87s]
2018-07-30 16:08:48,952: 16:08:48 | 19 of 23 START table model template.segment_proc_buyers.............. [RUN]
2018-07-30 16:08:48,953: Compiling model.shopify_cohort_analysis.segment_proc_buyers
2018-07-30 16:08:48,964: Writing injected SQL for node "model.shopify_cohort_analysis.segment_proc_buyers"
2018-07-30 16:08:48,966: Acquiring new bigquery connection "segment_proc_buyers".
2018-07-30 16:08:48,966: Re-using an available connection from the pool.
2018-07-30 16:08:49,469: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_proc_buyers"
2018-07-30 16:08:49,469: Fetching data for query segment_proc_buyers:
create or replace table `template`.`segment_proc_buyers`
  
  as (
    SELECT
store,
period,
customer_id,
date,
first_order_unix_date,
first_order_channel,
first_order_platform,
recency_days,
frequency,
quantity,
revenue, 
revenue_90pct,
revenue_10pct,
case when first_order_unix_date >= window_start_unix_date then 'New'
	else 'Existing' end as newness_segment,
case when revenue >= revenue_90pct then 'Top 10%'
	when revenue <= revenue_10pct then 'Bottom 10%'
	else 'Middle 80%' end as revenue_segment,
case when frequency = 1 then '1'
	when frequency = 2 then '2'
	when frequency > 2 then '3+'
	else null end as frequency_segment
FROM `growth-engines-pipeline`.`template`.`customers_proc`
  );

    
2018-07-30 16:09:20,902: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140a9978>]}
2018-07-30 16:09:21,859: 16:09:21 | 19 of 23 OK created table model template.segment_proc_buyers......... [OK in 31.95s]
2018-07-30 16:09:21,861: 16:09:21 | 20 of 23 START table model template.segment_stats_buyers_agg......... [RUN]
2018-07-30 16:09:21,862: Compiling model.shopify_cohort_analysis.segment_stats_buyers_agg
2018-07-30 16:09:21,886: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_agg"
2018-07-30 16:09:21,889: Acquiring new bigquery connection "segment_stats_buyers_agg".
2018-07-30 16:09:21,889: Re-using an available connection from the pool.
2018-07-30 16:09:22,271: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_agg"
2018-07-30 16:09:22,271: Fetching data for query segment_stats_buyers_agg:
create or replace table `template`.`segment_stats_buyers_agg`
  
  as (
    WITH ty as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev,
	0 as retention_eligible,
	case when newness_segment = 'Existing' then 1 else 0 end as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Year'

),

this_month_1yr as (

	SELECT
	store,
	'Rolling YoY' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment,
	frequency_segment,
	newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	recency_days as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev,
	1 as retention_eligible,
	0 as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Previous Year'

),

this_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,	
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment,
	frequency_segment,
	newness_segment,
	recency_days as recency,
	frequency as frequency,
	revenue as revenue,
	0 as recency_prev,
	0 as frequency_prev,
	0 as revenue_prev,
	0 as retention_eligible,
	case when newness_segment = 'Existing' then 1 else 0 end as retention_success	
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Quarter'

),

last_quarter as (

	SELECT
	store,
	'Rolling QoQ' as period,
	date,
	customer_id,
	first_order_channel,
	first_order_platform,	
	revenue_segment as revenue_segment,
	frequency_segment as frequency_segment,
	newness_segment as newness_segment,
	0 as recency,
	0 as frequency,
	0 as revenue,
	recency_days as recency_prev,
	frequency as frequency_prev,
	revenue as revenue_prev,
	1 as retention_eligible,
	0 as retention_success
	FROM `growth-engines-pipeline`.`template`.`segment_proc_buyers`
	WHERE period = 'Rolling Previous Quarter'

)

SELECT
store,
period,
date, 
customer_id,
case when sum(revenue) > 0 then 1 else 0 end as buyers,
first_order_channel,
first_order_platform,	
revenue_segment,
frequency_segment,
newness_segment,	
ifnull(sum(recency), 0) recency,
ifnull(sum(frequency), 0) frequency,
ifnull(sum(revenue), 0) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else 0 end as aov,
ifnull(sum(recency_prev), 0) recency_prev,
ifnull(sum(frequency_prev), 0) frequency_prev,
ifnull(sum(revenue_prev), 0) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else 0 end as aov_prev,
sum(retention_eligible) retention_eligible,
sum(retention_success) retention_success
FROM
(
	SELECT * FROM ty
	UNION ALL
	SELECT * FROM this_month_1yr
	UNION ALL
	SELECT * FROM this_quarter
	UNION ALL
	SELECT * FROM last_quarter

)
GROUP BY store, period, date, customer_id, first_order_channel, first_order_platform,
revenue_segment, frequency_segment, newness_segment
  );

    
2018-07-30 16:10:01,257: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114132278>]}
2018-07-30 16:10:02,117: 16:10:02 | 20 of 23 OK created table model template.segment_stats_buyers_agg.... [OK in 39.39s]
2018-07-30 16:10:02,119: 16:10:02 | 21 of 23 START table model template.segment_stats_buyers_view........ [RUN]
2018-07-30 16:10:02,119: Compiling model.shopify_cohort_analysis.segment_stats_buyers_view
2018-07-30 16:10:02,169: Writing injected SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_view"
2018-07-30 16:10:02,176: Acquiring new bigquery connection "segment_stats_buyers_view".
2018-07-30 16:10:02,176: Re-using an available connection from the pool.
2018-07-30 16:10:02,336: Writing runtime SQL for node "model.shopify_cohort_analysis.segment_stats_buyers_view"
2018-07-30 16:10:02,382: Fetching data for query segment_stats_buyers_view:
create or replace table `template`.`segment_stats_buyers_view`
  
  as (
    SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Revenue' as segment_type,
revenue_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Frequency' as segment_type,
frequency_segment as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'Overall' as view,
'Overall' as view_segment,
'Total' as segment_type,
'Total' as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Channel' as view,
first_order_channel as view_segment,
'Total' as segment_type,
'Total' as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type

UNION ALL

SELECT
store,
period,
date,
'First Order Platform' as view,
first_order_platform as view_segment,
'Total' as segment_type,
'Total' as segment,
sum(buyers) buyers,
case when sum(buyers) > 0 then sum(recency)/sum(buyers) else null end as  recency,
sum(frequency) frequency,
sum(revenue) revenue,
case when sum(frequency) > 0 then sum(revenue)/sum(frequency) else null end as aov,
case when sum(buyers) > 0 then sum(recency_prev)/sum(buyers) else null end as  recency_prev,
sum(frequency_prev) frequency_prev,
sum(revenue_prev) revenue_prev,
case when sum(frequency_prev) > 0 then sum(revenue_prev)/sum(frequency_prev) else null end as aov_prev,
case when sum(retention_eligible) > 0 then sum(retention_success)/sum(retention_eligible) else null end as retention_rate
FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg`
GROUP BY store, period, date, segment, view, view_segment, segment_type
  );

    
2018-07-30 16:10:06,796: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140a9978>]}
2018-07-30 16:10:07,616: 16:10:07 | 21 of 23 OK created table model template.segment_stats_buyers_view... [OK in 4.68s]
2018-07-30 16:10:07,618: 16:10:07 | 22 of 23 START table model template.buyer_segment_stats.............. [RUN]
2018-07-30 16:10:07,618: Compiling model.shopify_cohort_analysis.buyer_segment_stats
2018-07-30 16:10:07,639: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 16:10:07,642: Acquiring new bigquery connection "buyer_segment_stats".
2018-07-30 16:10:07,643: Re-using an available connection from the pool.
2018-07-30 16:10:07,893: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_stats"
2018-07-30 16:10:07,895: Fetching data for query buyer_segment_stats:
create or replace table `template`.`buyer_segment_stats`
  
  as (
    SELECT
store,
period,
date,
view,
view_segment,
segment_type,
segment,
buyers,
total_view_buyers,
case when ( total_segment_buyers / total_buyers ) > 0 
	then ( buyers / total_view_buyers ) / ( total_segment_buyers / total_buyers ) 
	else null end as segment_buyer_index,
recency,
orders,
case when buyers > 0 then orders / buyers else null end as frequency,
revenue,
case when total_revenue > 0 then revenue / total_revenue else null end as pct_of_revenue,
revenue_prev,
total_view_revenue,
case when ( total_segment_revenue / total_revenue ) > 0 
	then ( revenue / total_view_revenue ) / ( total_segment_revenue / total_revenue ) 
	else null end as segment_revenue_index,
aov,
recency_growth,
frequency_growth,
revenue_growth,
aov_growth,
retention_rate
FROM (

	SELECT
	store,
	period,
	date,
	view,
	view_segment,
	segment_type,
	segment,
	buyers,
	sum(buyers) over w1 as total_view_buyers,
	sum(buyers) over w2 as total_segment_buyers,
	sum(buyers) over w3 as total_buyers,
	recency,
	frequency orders,
	revenue,
	sum(revenue) over w1 as total_view_revenue,
	sum(revenue) over w2 as total_segment_revenue,
	sum(revenue) over w3 as total_revenue,
	aov,
	case when recency_prev > 0 then ( recency_prev - recency ) / recency_prev else null end as recency_growth,
	case when frequency_prev > 0 then ( frequency - frequency_prev ) / frequency_prev else null end as frequency_growth,
	revenue_prev,
	case when revenue_prev > 0 then ( revenue - revenue_prev ) / revenue_prev else null end as revenue_growth,
	case when aov_prev > 0 then ( aov - aov_prev ) / aov_prev else null end as aov_growth,
	retention_rate
	FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_view`
	WINDOW w1 as (PARTITION BY store, period, date, segment_type, view, view_segment),
	w2 as (PARTITION BY store, period, date, segment_type, view, segment),
	w3 as (PARTITION BY store, period, date, segment_type, view)
)
  );

    
2018-07-30 16:10:09,847: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114132278>]}
2018-07-30 16:10:10,251: 16:10:10 | 22 of 23 OK created table model template.buyer_segment_stats......... [OK in 2.23s]
2018-07-30 16:10:10,252: 16:10:10 | 23 of 23 START table model template.buyer_segment_lists.............. [RUN]
2018-07-30 16:10:10,253: Compiling model.shopify_cohort_analysis.buyer_segment_lists
2018-07-30 16:10:10,278: Writing injected SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 16:10:10,283: Acquiring new bigquery connection "buyer_segment_lists".
2018-07-30 16:10:10,283: Re-using an available connection from the pool.
2018-07-30 16:10:10,676: Writing runtime SQL for node "model.shopify_cohort_analysis.buyer_segment_lists"
2018-07-30 16:10:10,677: Fetching data for query buyer_segment_lists:
create or replace table `template`.`buyer_segment_lists`
  
  as (
    with buyer_lists as (

	SELECT
	a.store,
	period,
	date,
	customer_id,
	b.first_name,
	b.last_name,
	b.email,
	recency,
	frequency,
	revenue,
	aov,
	revenue_segment,
	frequency_segment
	FROM `growth-engines-pipeline`.`template`.`segment_stats_buyers_agg` a
	LEFT JOIN `growth-engines-pipeline`.`template`.`agg_customers` b
	ON (
		a.store = b.store AND
		a.customer_id = b.id
	)
	where revenue > 0
)

SELECT
store,
period,
date,
'Revenue' as segment_type,
revenue_segment as segment,
customer_id,
first_name,
last_name,
email,
recency,
frequency,
revenue,
aov
FROM buyer_lists

UNION ALL

SELECT
store,
period,
date,
'Frequency' as segment_type,
frequency_segment as segment,
customer_id,
first_name,
last_name,
email,
recency,
frequency,
revenue,
aov
FROM buyer_lists
  );

    
2018-07-30 16:10:59,047: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c823523e-9c61-42bb-a5ff-b4a6493d7ea9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140b4d30>]}
2018-07-30 16:10:59,400: 16:10:59 | 23 of 23 OK created table model template.buyer_segment_lists......... [OK in 48.79s]
2018-07-30 16:10:59,499: 16:10:59 | 
2018-07-30 16:10:59,499: 16:10:59 | Finished running 23 table models in 255.58s.
2018-07-30 16:10:59,499: Connection 'master' was left open.
2018-07-30 16:10:59,500: 
2018-07-30 16:10:59,500: Completed successfully
2018-07-30 16:10:59,500: 
Done. PASS=23 ERROR=0 SKIP=0 TOTAL=23
2018-07-30 16:10:59,501: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113fd44e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140acfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114062860>]}
2018-07-30 16:10:59,826: Flushing usage events
2018-07-30 16:10:59,996: sys:1: ResourceWarning: unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 58289), raddr=('172.217.2.13', 443)>

2018-07-30 16:10:59,998: sys:1: ResourceWarning: unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 58288), raddr=('172.217.2.10', 443)>

2018-07-30 16:10:59,998: sys:1: ResourceWarning: unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 58287), raddr=('172.217.2.13', 443)>

2018-07-30 16:10:59,999: sys:1: ResourceWarning: unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 58296), raddr=('172.217.12.10', 443)>

2018-07-30 16:10:59,999: sys:1: ResourceWarning: unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 58293), raddr=('172.217.12.10', 443)>

2018-07-30 16:11:00,000: sys:1: ResourceWarning: unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 58295), raddr=('172.217.12.10', 443)>

2018-07-30 16:11:00,001: sys:1: ResourceWarning: unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 58294), raddr=('172.217.12.10', 443)>

2018-07-30 16:11:00,002: sys:1: ResourceWarning: unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 58290), raddr=('172.217.2.13', 443)>

2018-07-30 16:11:00,002: sys:1: ResourceWarning: unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 58291), raddr=('172.217.2.13', 443)>

2018-07-30 16:11:00,002: sys:1: ResourceWarning: unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.217', 58292), raddr=('172.217.2.13', 443)>

